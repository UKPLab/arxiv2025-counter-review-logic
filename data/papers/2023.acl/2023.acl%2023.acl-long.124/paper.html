<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>[2305.14652] Denoising Bottleneck with Mutual Information Maximization for Video Multimodal Fusion</title><meta content="Video multimodal fusion aims to integrate multimodal signals in videos, such as visual, audio and text, to make a complementary prediction with multiple modalities contents.
However, unlike other image-text multimodal …" property="og:description"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="summary" name="twitter:card"/>
<meta content="Denoising Bottleneck with Mutual Information Maximization for Video Multimodal Fusion" name="twitter:title"/>
<meta content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png" name="twitter:image:src"/>
<meta content="ar5iv logo" name="twitter:image:alt"/>
<meta content="Denoising Bottleneck with Mutual Information Maximization for Video Multimodal Fusion" property="og:title"/>
<meta content="ar5iv" property="og:site_name"/>
<meta content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png" property="og:image"/>
<meta content="article" property="og:type"/>
<meta content="https://ar5iv.labs.arxiv.org/html/2305.14652" property="og:url"/>
<link href="https://ar5iv.labs.arxiv.org/html/2305.14652" rel="canonical" target="_blank"/>
<!--Generated on Thu Feb 29 05:36:49 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link href="/assets/ar5iv-fonts.0.8.0.min.css" media="all" rel="stylesheet"/><link href="/assets/ar5iv.0.8.0.min.css" media="all" rel="stylesheet"/><link href="/assets/ar5iv-site.0.2.2.css" media="all" rel="stylesheet"/>
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Denoising Bottleneck with Mutual Information Maximization 
<br class="ltx_break"/>for Video Multimodal Fusion</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id7.id1">Video multimodal fusion aims to integrate multimodal signals in videos, such as visual, audio and text, to make a complementary prediction with multiple modalities contents.
However, unlike other image-text multimodal tasks, video has longer multimodal sequences with more redundancy and noise in both visual and audio modalities.
Prior denoising methods like forget gate are coarse in the granularity of noise filtering.
They often suppress the redundant and noisy information at the risk of losing critical information.
Therefore, we propose a denoising bottleneck fusion (DBF) model for fine-grained video multimodal fusion.
On the one hand, we employ a bottleneck mechanism to filter out noise and redundancy with a restrained receptive field.
On the other hand, we use a mutual information maximization module to regulate the filter-out module to preserve key information within different modalities.
Our DBF model achieves significant improvement over current state-of-the-art baselines on multiple benchmarks covering multimodal sentiment analysis and multimodal summarization tasks.
It proves that our model can effectively capture salient features from noisy and redundant video, audio, and text inputs.
The code for this paper is publicly available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/WSXRHFG/DBF" target="_blank" title="">https://github.com/WSXRHFG/DBF</a>.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="236" id="S1.F1.g1" src="./media/x1.png" width="461"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>
An example of redundancy and noise in a video.
As illustrated, consecutive frames have high cosine similarity, which results in a problem of <span class="ltx_text ltx_font_bold" id="S1.F1.3.1">redundancy</span>.
In addition, useless information like distracting background and weak alignment between frames and transcripts compose <span class="ltx_text ltx_font_bold" id="S1.F1.4.2">noises</span> in videos.
</figcaption>
</figure>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">With the rapid development of social platforms and digital devices, more and more videos are flooding our lives, which leads video multimodal fusion an increasingly popular focus of NLP research.
Video multimodal fusion aims to integrate the information from two or more modalities (e.g., visual and audio signals) into text for a more comprehensive reasoning.
For example, multimodal sentiment analysis <cite class="ltx_cite ltx_citemacro_citep">(Poria et al., <a class="ltx_ref" href="#bib.bib22" title="">2020</a>)</cite> utilizes contrast between transcript and expression to detect sarcam, multimodal summarization <cite class="ltx_cite ltx_citemacro_citep">(Sanabria et al., <a class="ltx_ref" href="#bib.bib23" title="">2018</a>)</cite> complete summary with information only exists in visual signal.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">However, as shown in the Figure <a class="ltx_ref" href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Denoising Bottleneck with Mutual Information Maximization for Video Multimodal Fusion"><span class="ltx_text ltx_ref_tag">1</span></a>, there exist plenty of redundancy and noise in video multimodal fusion:
1) high similarity across consecutive frames brings <em class="ltx_emph ltx_font_italic" id="S1.p2.1.1">video redundancy</em>;
2) useless information, such as the distracting background, introduces <em class="ltx_emph ltx_font_italic" id="S1.p2.1.2">frame noise</em>;
3) weak alignment between visual stream and text also introduces <em class="ltx_emph ltx_font_italic" id="S1.p2.1.3">misalignment noise</em>.
To alleviate the problem of redundancy and noise in video multimodal fusion, <cite class="ltx_cite ltx_citemacro_citet">Liu et al. (<a class="ltx_ref" href="#bib.bib13" title="">2020</a>)</cite> control the flow of redundant and noisy information between multimodal sequences by a fusion forget gate.
The fusion forget gate impairs the impact of noise and redundancy in a coarse grain of the whole modality, so it will also filter out some representative information in the filtered modality.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">In order to remove noise and redundancy while preserving critical information in video multimodal fusion, we propose a denoising fusion bottleneck (DBF) model with mutual information maximization (MI-Max).
Firstly, inspired by <cite class="ltx_cite ltx_citemacro_citet">Nagrani et al. (<a class="ltx_ref" href="#bib.bib17" title="">2021</a>)</cite>, we introduce a bottleneck module to restrict the redundant and noisy information across different modalities.
With the bottleneck module, inputs can only attend to low-capacity bottleneck embeddings to exchange information across different modalities, which urges redundant and noisy information to be discarded.
Secondly, in order to prevent key information from being filtered out, we adopt the idea of contrastive learning to supervise the learning of our bottleneck module.
Specifically, under the noise-contrastive estimation framework <cite class="ltx_cite ltx_citemacro_citep">(Gutmann and Hyvärinen, <a class="ltx_ref" href="#bib.bib5" title="">2010</a>)</cite>, for each sample, we treat all the other samples in the same batch as negative ones.
Then, we aim to maximize the mutual information between fusion results and each unimodal inputs by distinguishing their similarity scores from negative samples.
Two aforementioned modules complement each other, the MI-Max module supervises the fusion bottleneck not to filter out key information, and in turn, the bottleneck reduces irrelevant information in fusion results to facilitate the maximization of mutual information.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">We conduct extensive experiments on three benchmarks spanning two tasks.
MOSI <cite class="ltx_cite ltx_citemacro_citep">(Zadeh et al., <a class="ltx_ref" href="#bib.bib36" title="">2016</a>)</cite> and MOSEI <cite class="ltx_cite ltx_citemacro_citep">(Zadeh et al., <a class="ltx_ref" href="#bib.bib37" title="">2018b</a>)</cite> are two datasets for multimodal sentiment analysis.
How2 <cite class="ltx_cite ltx_citemacro_citep">(Sanabria et al., <a class="ltx_ref" href="#bib.bib23" title="">2018</a>)</cite> is a benchmark for multimodal summarization.
Experimental results show that our model achieves consistent improvements compared with current state-of-the-art methods.
Meanwhile, we perform comprehensive ablation experiments to demonstrate the effectiveness of each module.
In addition, we visualize the attention regions and tensity to multiple frames to intuitively show the behavior of our model to reduce noise while retaining key information implicitly.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Concretely, we make the following contributions:
(i) We propose a denoising bottleneck fusion model for video multimodal fusion, which reduces redundancy and noise while retaining key information.
(ii) We achieve new state-of-the-art performance on three benchmarks spanning two video multimodal fusion tasks.
(iii) We provide comprehensive ablation studies and qualitative visualization examples to demonstrate the effectiveness of both bottleneck and MI-Max modules.
</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">We briefly overview related work about multimodal fusion and specific multimodal fusion tasks including multimodal summarization and multimodal sentiment analysis.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Video Multimodal Fusion</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Video multimodal fusion aims to join and comprehend information from two or more modalities in videos to make a comprehensive prediction.
Early fusion model adopted simple network architectures. <cite class="ltx_cite ltx_citemacro_citet">Zadeh et al. (<a class="ltx_ref" href="#bib.bib34" title="">2017</a>); Liu et al. (<a class="ltx_ref" href="#bib.bib14" title="">2018a</a>)</cite> fuse features by matrix operations;
and <cite class="ltx_cite ltx_citemacro_citet">Zadeh et al. (<a class="ltx_ref" href="#bib.bib35" title="">2018a</a>)</cite> designed a LSTM-based model to capture both temporal and inter-modal interactions for better fusion.
More recently, models influenced by prevalence of Transformer <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al., <a class="ltx_ref" href="#bib.bib29" title="">2017</a>)</cite> have emerged constantly: <cite class="ltx_cite ltx_citemacro_citet">Zhang et al. (<a class="ltx_ref" href="#bib.bib38" title="">2019</a>)</cite> injected visual information in the decoder of Transformer by cross attention mechanism to do multimodal translation task;
<cite class="ltx_cite ltx_citemacro_citet">Wu et al. (<a class="ltx_ref" href="#bib.bib31" title="">2021</a>)</cite> proposed a text-centric multimodal fusion shared private framework for multimodal fusion, which consists of the cross-modal prediction and sentiment regression parts.
And now vision-and-language pre-training has become a promising practice to tackle video multimodal fusion tasks.
<cite class="ltx_cite ltx_citemacro_citep">(Sun et al., <a class="ltx_ref" href="#bib.bib25" title="">2019</a>)</cite> firstly extend the Transformer structure to video-language pretraining and used three pre-training tasks: masked language prediction, video text matching, masked video prediction.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">In contrast to existing works, we focus on the fundamental characteristic of video: audio and visual inputs in video are redundant and noisy <cite class="ltx_cite ltx_citemacro_citep">(Nagrani et al., <a class="ltx_ref" href="#bib.bib17" title="">2021</a>)</cite> so we aim to remove noise and redundancy while preserving critical information.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Video Multimodal Summarization</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Video multimodal summarization aims to generate summaries from visual features and corresponding transcripts in videos.
In contrast to unimodal summarization, some information (e.g., guitar) only exists in the visual modality.
Thus, for videos, utilization of both visual and text features is necessary to generate a more comprehensive summary.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">For datasets, <cite class="ltx_cite ltx_citemacro_citet">Li et al. (<a class="ltx_ref" href="#bib.bib11" title="">2017</a>)</cite> introduced a multimodal summarization dataset consisting of 500 videos of news articles in Chinese and English. <cite class="ltx_cite ltx_citemacro_citet">Sanabria et al. (<a class="ltx_ref" href="#bib.bib23" title="">2018</a>)</cite> proposed the How2 dataset consists of 2,000 hours of short instructional videos, each coming with a summary of two to three sentences.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">For models, <cite class="ltx_cite ltx_citemacro_citet">Liu et al. (<a class="ltx_ref" href="#bib.bib13" title="">2020</a>)</cite> proposed a multistage fusion network with a fusion forget gate module, which controls the flow of redundant information between multimodal long sequences. Meanwhile, <cite class="ltx_cite ltx_citemacro_citet">Yu et al. (<a class="ltx_ref" href="#bib.bib32" title="">2021a</a>)</cite> firstly introduced pre-trained language models into multimodal summarization task and experimented with the optimal injection layer of visual features.</p>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1">We also reduce redundancy in video like in <cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a class="ltx_ref" href="#bib.bib32" title="">2021a</a>)</cite>.
However, we do not impair the impact of noise and redundancy in a coarse grain with forget gate.
Instead, we combine fusion bottleneck and MI-Max modules to filter out noise while preserving key information.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Multimodal Sentiment Analysis</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">Multimodal sentiment analysis (MSA) aims to integrate multimodal resources, such as textual, visual, and acoustic information in videos to predict varied human emotions.
In contrast to unimodal sentiment analysis, utterance in the real situation sometimes contains sarcasm, which makes it hard to make accurate prediction by a single modality.
In addition, information such as expression in vision and tone in acoustic help assist sentiment prediction.
<cite class="ltx_cite ltx_citemacro_citet">Yu et al. (<a class="ltx_ref" href="#bib.bib33" title="">2021b</a>)</cite> introduced a multi-label training scheme that generates extra unimodal labels for each modality and concurrently trained with the main task.
<cite class="ltx_cite ltx_citemacro_citet">Han et al. (<a class="ltx_ref" href="#bib.bib6" title="">2021</a>)</cite> build up a hierarchical mutual information maximization guided model to improve the fusion outcome as well as the performance in the downstream multimodal sentiment analysis task.
<cite class="ltx_cite ltx_citemacro_citet">Luo et al. (<a class="ltx_ref" href="#bib.bib16" title="">2021</a>)</cite> propose a multi-scale fusion method to align different granularity information from multiple modalities in multimodal sentiment analysis.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1">Our work is fundamentally different from the above work.
We do not focus on complex fusion mechanisms, but take the perspective of information in videos, and stress the importance of validity of information within fusion results.</p>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="215" id="S2.F2.g1" src="./media/x2.png" width="461"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Overview of our denoising fusion bottleneck (DBF) model. It consists of <math alttext="N" class="ltx_Math" display="inline" id="S2.F2.3.m1.1"><semantics id="S2.F2.3.m1.1b"><mi id="S2.F2.3.m1.1.1" xref="S2.F2.3.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.F2.3.m1.1c"><ci id="S2.F2.3.m1.1.1.cmml" xref="S2.F2.3.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.3.m1.1d">N</annotation></semantics></math> Transformer layers to encode videos and texts, and <math alttext="M" class="ltx_Math" display="inline" id="S2.F2.4.m2.1"><semantics id="S2.F2.4.m2.1b"><mi id="S2.F2.4.m2.1.1" xref="S2.F2.4.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.F2.4.m2.1c"><ci id="S2.F2.4.m2.1.1.cmml" xref="S2.F2.4.m2.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.4.m2.1d">M</annotation></semantics></math> Transformer layers with fusion bottlenecks for multimodal fusion. We incorporate a mutual information maximization (MI-Max) InfoNCE loss to regulate the bottleneck module, aiming to preserve key information in both modalities from being filtered.
</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methodology</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Our denoising fusion bottleneck (DBF) model aims to fuse multimodal inputs from videos to make a comprehensive prediction.
The overall architecture of DBF is shown in Figure <a class="ltx_ref" href="#S2.F2" title="Figure 2 ‣ 2.3 Multimodal Sentiment Analysis ‣ 2 Related Work ‣ Denoising Bottleneck with Mutual Information Maximization for Video Multimodal Fusion"><span class="ltx_text ltx_ref_tag">2</span></a>.
It first employs a fusion bottleneck module with a restrained receptive field to filter out noise and redundancy when fusing different modalities in videos.
Then, DBF maximizes mutual information between fusion results and unimodal inputs to supervise the learning of the fusion bottleneck, aiming to preserve more representative information in fusion results.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Problem Definition</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.10">In video multimodal fusion tasks, for each video, the input comprises three sequences of encoded features from textual (<math alttext="t" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">t</annotation></semantics></math>), visual (<math alttext="v" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">v</annotation></semantics></math>), and acoustic (<math alttext="a" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">a</annotation></semantics></math>) modalities.
These input features are represented as <math alttext="X_{m}\in\mathbb{R}^{l_{m}\times d_{m}}" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m4.1"><semantics id="S3.SS1.p1.4.m4.1a"><mrow id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><msub id="S3.SS1.p1.4.m4.1.1.2" xref="S3.SS1.p1.4.m4.1.1.2.cmml"><mi id="S3.SS1.p1.4.m4.1.1.2.2" xref="S3.SS1.p1.4.m4.1.1.2.2.cmml">X</mi><mi id="S3.SS1.p1.4.m4.1.1.2.3" xref="S3.SS1.p1.4.m4.1.1.2.3.cmml">m</mi></msub><mo id="S3.SS1.p1.4.m4.1.1.1" xref="S3.SS1.p1.4.m4.1.1.1.cmml">∈</mo><msup id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml"><mi id="S3.SS1.p1.4.m4.1.1.3.2" xref="S3.SS1.p1.4.m4.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS1.p1.4.m4.1.1.3.3" xref="S3.SS1.p1.4.m4.1.1.3.3.cmml"><msub id="S3.SS1.p1.4.m4.1.1.3.3.2" xref="S3.SS1.p1.4.m4.1.1.3.3.2.cmml"><mi id="S3.SS1.p1.4.m4.1.1.3.3.2.2" xref="S3.SS1.p1.4.m4.1.1.3.3.2.2.cmml">l</mi><mi id="S3.SS1.p1.4.m4.1.1.3.3.2.3" xref="S3.SS1.p1.4.m4.1.1.3.3.2.3.cmml">m</mi></msub><mo id="S3.SS1.p1.4.m4.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p1.4.m4.1.1.3.3.1.cmml">×</mo><msub id="S3.SS1.p1.4.m4.1.1.3.3.3" xref="S3.SS1.p1.4.m4.1.1.3.3.3.cmml"><mi id="S3.SS1.p1.4.m4.1.1.3.3.3.2" xref="S3.SS1.p1.4.m4.1.1.3.3.3.2.cmml">d</mi><mi id="S3.SS1.p1.4.m4.1.1.3.3.3.3" xref="S3.SS1.p1.4.m4.1.1.3.3.3.3.cmml">m</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><in id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1.1"></in><apply id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.2.1.cmml" xref="S3.SS1.p1.4.m4.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.2.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2.2">𝑋</ci><ci id="S3.SS1.p1.4.m4.1.1.2.3.cmml" xref="S3.SS1.p1.4.m4.1.1.2.3">𝑚</ci></apply><apply id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.3.1.cmml" xref="S3.SS1.p1.4.m4.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.3.2.cmml" xref="S3.SS1.p1.4.m4.1.1.3.2">ℝ</ci><apply id="S3.SS1.p1.4.m4.1.1.3.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3.3"><times id="S3.SS1.p1.4.m4.1.1.3.3.1.cmml" xref="S3.SS1.p1.4.m4.1.1.3.3.1"></times><apply id="S3.SS1.p1.4.m4.1.1.3.3.2.cmml" xref="S3.SS1.p1.4.m4.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.3.3.2.1.cmml" xref="S3.SS1.p1.4.m4.1.1.3.3.2">subscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.3.3.2.2.cmml" xref="S3.SS1.p1.4.m4.1.1.3.3.2.2">𝑙</ci><ci id="S3.SS1.p1.4.m4.1.1.3.3.2.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3.3.2.3">𝑚</ci></apply><apply id="S3.SS1.p1.4.m4.1.1.3.3.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.3.3.3.1.cmml" xref="S3.SS1.p1.4.m4.1.1.3.3.3">subscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.3.3.3.2.cmml" xref="S3.SS1.p1.4.m4.1.1.3.3.3.2">𝑑</ci><ci id="S3.SS1.p1.4.m4.1.1.3.3.3.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3.3.3.3">𝑚</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">X_{m}\in\mathbb{R}^{l_{m}\times d_{m}}</annotation></semantics></math>, where <math alttext="m\in\{t,v,a\}" class="ltx_Math" display="inline" id="S3.SS1.p1.5.m5.3"><semantics id="S3.SS1.p1.5.m5.3a"><mrow id="S3.SS1.p1.5.m5.3.4" xref="S3.SS1.p1.5.m5.3.4.cmml"><mi id="S3.SS1.p1.5.m5.3.4.2" xref="S3.SS1.p1.5.m5.3.4.2.cmml">m</mi><mo id="S3.SS1.p1.5.m5.3.4.1" xref="S3.SS1.p1.5.m5.3.4.1.cmml">∈</mo><mrow id="S3.SS1.p1.5.m5.3.4.3.2" xref="S3.SS1.p1.5.m5.3.4.3.1.cmml"><mo id="S3.SS1.p1.5.m5.3.4.3.2.1" stretchy="false" xref="S3.SS1.p1.5.m5.3.4.3.1.cmml">{</mo><mi id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml">t</mi><mo id="S3.SS1.p1.5.m5.3.4.3.2.2" xref="S3.SS1.p1.5.m5.3.4.3.1.cmml">,</mo><mi id="S3.SS1.p1.5.m5.2.2" xref="S3.SS1.p1.5.m5.2.2.cmml">v</mi><mo id="S3.SS1.p1.5.m5.3.4.3.2.3" xref="S3.SS1.p1.5.m5.3.4.3.1.cmml">,</mo><mi id="S3.SS1.p1.5.m5.3.3" xref="S3.SS1.p1.5.m5.3.3.cmml">a</mi><mo id="S3.SS1.p1.5.m5.3.4.3.2.4" stretchy="false" xref="S3.SS1.p1.5.m5.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.3b"><apply id="S3.SS1.p1.5.m5.3.4.cmml" xref="S3.SS1.p1.5.m5.3.4"><in id="S3.SS1.p1.5.m5.3.4.1.cmml" xref="S3.SS1.p1.5.m5.3.4.1"></in><ci id="S3.SS1.p1.5.m5.3.4.2.cmml" xref="S3.SS1.p1.5.m5.3.4.2">𝑚</ci><set id="S3.SS1.p1.5.m5.3.4.3.1.cmml" xref="S3.SS1.p1.5.m5.3.4.3.2"><ci id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">𝑡</ci><ci id="S3.SS1.p1.5.m5.2.2.cmml" xref="S3.SS1.p1.5.m5.2.2">𝑣</ci><ci id="S3.SS1.p1.5.m5.3.3.cmml" xref="S3.SS1.p1.5.m5.3.3">𝑎</ci></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.3c">m\in\{t,v,a\}</annotation></semantics></math>, and <math alttext="l_{m}" class="ltx_Math" display="inline" id="S3.SS1.p1.6.m6.1"><semantics id="S3.SS1.p1.6.m6.1a"><msub id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml"><mi id="S3.SS1.p1.6.m6.1.1.2" xref="S3.SS1.p1.6.m6.1.1.2.cmml">l</mi><mi id="S3.SS1.p1.6.m6.1.1.3" xref="S3.SS1.p1.6.m6.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><apply id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2">𝑙</ci><ci id="S3.SS1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">l_{m}</annotation></semantics></math> and <math alttext="d_{m}" class="ltx_Math" display="inline" id="S3.SS1.p1.7.m7.1"><semantics id="S3.SS1.p1.7.m7.1a"><msub id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml"><mi id="S3.SS1.p1.7.m7.1.1.2" xref="S3.SS1.p1.7.m7.1.1.2.cmml">d</mi><mi id="S3.SS1.p1.7.m7.1.1.3" xref="S3.SS1.p1.7.m7.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><apply id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.1.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">subscript</csymbol><ci id="S3.SS1.p1.7.m7.1.1.2.cmml" xref="S3.SS1.p1.7.m7.1.1.2">𝑑</ci><ci id="S3.SS1.p1.7.m7.1.1.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">d_{m}</annotation></semantics></math> denote the sequence length and feature dimension for modality <math alttext="m" class="ltx_Math" display="inline" id="S3.SS1.p1.8.m8.1"><semantics id="S3.SS1.p1.8.m8.1a"><mi id="S3.SS1.p1.8.m8.1.1" xref="S3.SS1.p1.8.m8.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.1b"><ci id="S3.SS1.p1.8.m8.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.1c">m</annotation></semantics></math>, respectively.
The goal of DBF is to extract and integrate task-related information from these input representations to form a unified fusion result <math alttext="Z\in\mathbb{R}^{l\times d}" class="ltx_Math" display="inline" id="S3.SS1.p1.9.m9.1"><semantics id="S3.SS1.p1.9.m9.1a"><mrow id="S3.SS1.p1.9.m9.1.1" xref="S3.SS1.p1.9.m9.1.1.cmml"><mi id="S3.SS1.p1.9.m9.1.1.2" xref="S3.SS1.p1.9.m9.1.1.2.cmml">Z</mi><mo id="S3.SS1.p1.9.m9.1.1.1" xref="S3.SS1.p1.9.m9.1.1.1.cmml">∈</mo><msup id="S3.SS1.p1.9.m9.1.1.3" xref="S3.SS1.p1.9.m9.1.1.3.cmml"><mi id="S3.SS1.p1.9.m9.1.1.3.2" xref="S3.SS1.p1.9.m9.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS1.p1.9.m9.1.1.3.3" xref="S3.SS1.p1.9.m9.1.1.3.3.cmml"><mi id="S3.SS1.p1.9.m9.1.1.3.3.2" xref="S3.SS1.p1.9.m9.1.1.3.3.2.cmml">l</mi><mo id="S3.SS1.p1.9.m9.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.p1.9.m9.1.1.3.3.1.cmml">×</mo><mi id="S3.SS1.p1.9.m9.1.1.3.3.3" xref="S3.SS1.p1.9.m9.1.1.3.3.3.cmml">d</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m9.1b"><apply id="S3.SS1.p1.9.m9.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1"><in id="S3.SS1.p1.9.m9.1.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1.1"></in><ci id="S3.SS1.p1.9.m9.1.1.2.cmml" xref="S3.SS1.p1.9.m9.1.1.2">𝑍</ci><apply id="S3.SS1.p1.9.m9.1.1.3.cmml" xref="S3.SS1.p1.9.m9.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.9.m9.1.1.3.1.cmml" xref="S3.SS1.p1.9.m9.1.1.3">superscript</csymbol><ci id="S3.SS1.p1.9.m9.1.1.3.2.cmml" xref="S3.SS1.p1.9.m9.1.1.3.2">ℝ</ci><apply id="S3.SS1.p1.9.m9.1.1.3.3.cmml" xref="S3.SS1.p1.9.m9.1.1.3.3"><times id="S3.SS1.p1.9.m9.1.1.3.3.1.cmml" xref="S3.SS1.p1.9.m9.1.1.3.3.1"></times><ci id="S3.SS1.p1.9.m9.1.1.3.3.2.cmml" xref="S3.SS1.p1.9.m9.1.1.3.3.2">𝑙</ci><ci id="S3.SS1.p1.9.m9.1.1.3.3.3.cmml" xref="S3.SS1.p1.9.m9.1.1.3.3.3">𝑑</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m9.1c">Z\in\mathbb{R}^{l\times d}</annotation></semantics></math>.
In this paper, we evaluate the quality of the fusion result <math alttext="Z" class="ltx_Math" display="inline" id="S3.SS1.p1.10.m10.1"><semantics id="S3.SS1.p1.10.m10.1a"><mi id="S3.SS1.p1.10.m10.1.1" xref="S3.SS1.p1.10.m10.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m10.1b"><ci id="S3.SS1.p1.10.m10.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1">𝑍</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m10.1c">Z</annotation></semantics></math> on two tasks: video multimodal sentiment analysis and video multimodal summarization.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.3">For sentiment analysis, we utilize <math alttext="Z" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><mi id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">𝑍</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">Z</annotation></semantics></math> to predict the emotional orientation of a video as a discrete category <math alttext="\hat{y}" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.1"><semantics id="S3.SS1.p2.2.m2.1a"><mover accent="true" id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml"><mi id="S3.SS1.p2.2.m2.1.1.2" xref="S3.SS1.p2.2.m2.1.1.2.cmml">y</mi><mo id="S3.SS1.p2.2.m2.1.1.1" xref="S3.SS1.p2.2.m2.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><apply id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1"><ci id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1.1">^</ci><ci id="S3.SS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">\hat{y}</annotation></semantics></math> from a predefined set of candidates <math alttext="\mathcal{C}" class="ltx_Math" display="inline" id="S3.SS1.p2.3.m3.1"><semantics id="S3.SS1.p2.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">𝒞</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><ci id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">𝒞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">\mathcal{C}</annotation></semantics></math></p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\hat{y}=\operatorname{argmax}_{y_{j}\in\mathcal{C}}\operatorname{P}_{\Theta}(y_{j}\mid Z)," class="ltx_Math" display="block" id="S3.E1.m1.1"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mover accent="true" id="S3.E1.m1.1.1.1.1.4" xref="S3.E1.m1.1.1.1.1.4.cmml"><mi id="S3.E1.m1.1.1.1.1.4.2" xref="S3.E1.m1.1.1.1.1.4.2.cmml">y</mi><mo id="S3.E1.m1.1.1.1.1.4.1" xref="S3.E1.m1.1.1.1.1.4.1.cmml">^</mo></mover><mo id="S3.E1.m1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.3.cmml">=</mo><mrow id="S3.E1.m1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.2.cmml"><msub id="S3.E1.m1.1.1.1.1.2.3" xref="S3.E1.m1.1.1.1.1.2.3.cmml"><mi id="S3.E1.m1.1.1.1.1.2.3.2" xref="S3.E1.m1.1.1.1.1.2.3.2.cmml">argmax</mi><mrow id="S3.E1.m1.1.1.1.1.2.3.3" xref="S3.E1.m1.1.1.1.1.2.3.3.cmml"><msub id="S3.E1.m1.1.1.1.1.2.3.3.2" xref="S3.E1.m1.1.1.1.1.2.3.3.2.cmml"><mi id="S3.E1.m1.1.1.1.1.2.3.3.2.2" xref="S3.E1.m1.1.1.1.1.2.3.3.2.2.cmml">y</mi><mi id="S3.E1.m1.1.1.1.1.2.3.3.2.3" xref="S3.E1.m1.1.1.1.1.2.3.3.2.3.cmml">j</mi></msub><mo id="S3.E1.m1.1.1.1.1.2.3.3.1" xref="S3.E1.m1.1.1.1.1.2.3.3.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.1.1.1.1.2.3.3.3" xref="S3.E1.m1.1.1.1.1.2.3.3.3.cmml">𝒞</mi></mrow></msub><mo id="S3.E1.m1.1.1.1.1.2a" lspace="0.167em" xref="S3.E1.m1.1.1.1.1.2.cmml">⁡</mo><mrow id="S3.E1.m1.1.1.1.1.2.2.2" xref="S3.E1.m1.1.1.1.1.2.2.3.cmml"><msub id="S3.E1.m1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.2" mathvariant="normal" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2.cmml">P</mi><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.3" mathvariant="normal" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.cmml">Θ</mi></msub><mo id="S3.E1.m1.1.1.1.1.2.2.2a" xref="S3.E1.m1.1.1.1.1.2.2.3.cmml">⁡</mo><mrow id="S3.E1.m1.1.1.1.1.2.2.2.2" xref="S3.E1.m1.1.1.1.1.2.2.3.cmml"><mo id="S3.E1.m1.1.1.1.1.2.2.2.2.2" stretchy="false" xref="S3.E1.m1.1.1.1.1.2.2.3.cmml">(</mo><mrow id="S3.E1.m1.1.1.1.1.2.2.2.2.1" xref="S3.E1.m1.1.1.1.1.2.2.2.2.1.cmml"><msub id="S3.E1.m1.1.1.1.1.2.2.2.2.1.2" xref="S3.E1.m1.1.1.1.1.2.2.2.2.1.2.cmml"><mi id="S3.E1.m1.1.1.1.1.2.2.2.2.1.2.2" xref="S3.E1.m1.1.1.1.1.2.2.2.2.1.2.2.cmml">y</mi><mi id="S3.E1.m1.1.1.1.1.2.2.2.2.1.2.3" xref="S3.E1.m1.1.1.1.1.2.2.2.2.1.2.3.cmml">j</mi></msub><mo id="S3.E1.m1.1.1.1.1.2.2.2.2.1.1" xref="S3.E1.m1.1.1.1.1.2.2.2.2.1.1.cmml">∣</mo><mi id="S3.E1.m1.1.1.1.1.2.2.2.2.1.3" xref="S3.E1.m1.1.1.1.1.2.2.2.2.1.3.cmml">Z</mi></mrow><mo id="S3.E1.m1.1.1.1.1.2.2.2.2.3" stretchy="false" xref="S3.E1.m1.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><eq id="S3.E1.m1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3"></eq><apply id="S3.E1.m1.1.1.1.1.4.cmml" xref="S3.E1.m1.1.1.1.1.4"><ci id="S3.E1.m1.1.1.1.1.4.1.cmml" xref="S3.E1.m1.1.1.1.1.4.1">^</ci><ci id="S3.E1.m1.1.1.1.1.4.2.cmml" xref="S3.E1.m1.1.1.1.1.4.2">𝑦</ci></apply><apply id="S3.E1.m1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.2"><apply id="S3.E1.m1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.2.3.1.cmml" xref="S3.E1.m1.1.1.1.1.2.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.2.3.2.cmml" xref="S3.E1.m1.1.1.1.1.2.3.2">argmax</ci><apply id="S3.E1.m1.1.1.1.1.2.3.3.cmml" xref="S3.E1.m1.1.1.1.1.2.3.3"><in id="S3.E1.m1.1.1.1.1.2.3.3.1.cmml" xref="S3.E1.m1.1.1.1.1.2.3.3.1"></in><apply id="S3.E1.m1.1.1.1.1.2.3.3.2.cmml" xref="S3.E1.m1.1.1.1.1.2.3.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.2.3.3.2.1.cmml" xref="S3.E1.m1.1.1.1.1.2.3.3.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.2.3.3.2.2.cmml" xref="S3.E1.m1.1.1.1.1.2.3.3.2.2">𝑦</ci><ci id="S3.E1.m1.1.1.1.1.2.3.3.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.3.3.2.3">𝑗</ci></apply><ci id="S3.E1.m1.1.1.1.1.2.3.3.3.cmml" xref="S3.E1.m1.1.1.1.1.2.3.3.3">𝒞</ci></apply></apply><apply id="S3.E1.m1.1.1.1.1.2.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2"><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2">P</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3">Θ</ci></apply><apply id="S3.E1.m1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.1"><csymbol cd="latexml" id="S3.E1.m1.1.1.1.1.2.2.2.2.1.1.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.1.1">conditional</csymbol><apply id="S3.E1.m1.1.1.1.1.2.2.2.2.1.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.2.2.2.2.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.1.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.2.2.2.2.1.2.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.1.2.2">𝑦</ci><ci id="S3.E1.m1.1.1.1.1.2.2.2.2.1.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.1.2.3">𝑗</ci></apply><ci id="S3.E1.m1.1.1.1.1.2.2.2.2.1.3.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2.2.1.3">𝑍</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">\hat{y}=\operatorname{argmax}_{y_{j}\in\mathcal{C}}\operatorname{P}_{\Theta}(y_{j}\mid Z),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p2.4">or as a continuous intensity score <math alttext="\hat{y}\in\mathbb{R}" class="ltx_Math" display="inline" id="S3.SS1.p2.4.m1.1"><semantics id="S3.SS1.p2.4.m1.1a"><mrow id="S3.SS1.p2.4.m1.1.1" xref="S3.SS1.p2.4.m1.1.1.cmml"><mover accent="true" id="S3.SS1.p2.4.m1.1.1.2" xref="S3.SS1.p2.4.m1.1.1.2.cmml"><mi id="S3.SS1.p2.4.m1.1.1.2.2" xref="S3.SS1.p2.4.m1.1.1.2.2.cmml">y</mi><mo id="S3.SS1.p2.4.m1.1.1.2.1" xref="S3.SS1.p2.4.m1.1.1.2.1.cmml">^</mo></mover><mo id="S3.SS1.p2.4.m1.1.1.1" xref="S3.SS1.p2.4.m1.1.1.1.cmml">∈</mo><mi id="S3.SS1.p2.4.m1.1.1.3" xref="S3.SS1.p2.4.m1.1.1.3.cmml">ℝ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m1.1b"><apply id="S3.SS1.p2.4.m1.1.1.cmml" xref="S3.SS1.p2.4.m1.1.1"><in id="S3.SS1.p2.4.m1.1.1.1.cmml" xref="S3.SS1.p2.4.m1.1.1.1"></in><apply id="S3.SS1.p2.4.m1.1.1.2.cmml" xref="S3.SS1.p2.4.m1.1.1.2"><ci id="S3.SS1.p2.4.m1.1.1.2.1.cmml" xref="S3.SS1.p2.4.m1.1.1.2.1">^</ci><ci id="S3.SS1.p2.4.m1.1.1.2.2.cmml" xref="S3.SS1.p2.4.m1.1.1.2.2">𝑦</ci></apply><ci id="S3.SS1.p2.4.m1.1.1.3.cmml" xref="S3.SS1.p2.4.m1.1.1.3">ℝ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m1.1c">\hat{y}\in\mathbb{R}</annotation></semantics></math></p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\hat{y}=\operatorname{P}_{\Theta}(Z)," class="ltx_Math" display="block" id="S3.E2.m1.2"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.2.1" xref="S3.E2.m1.2.2.1.1.cmml"><mrow id="S3.E2.m1.2.2.1.1" xref="S3.E2.m1.2.2.1.1.cmml"><mover accent="true" id="S3.E2.m1.2.2.1.1.3" xref="S3.E2.m1.2.2.1.1.3.cmml"><mi id="S3.E2.m1.2.2.1.1.3.2" xref="S3.E2.m1.2.2.1.1.3.2.cmml">y</mi><mo id="S3.E2.m1.2.2.1.1.3.1" xref="S3.E2.m1.2.2.1.1.3.1.cmml">^</mo></mover><mo id="S3.E2.m1.2.2.1.1.2" xref="S3.E2.m1.2.2.1.1.2.cmml">=</mo><mrow id="S3.E2.m1.2.2.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.2.cmml"><msub id="S3.E2.m1.2.2.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.2" mathvariant="normal" xref="S3.E2.m1.2.2.1.1.1.1.1.2.cmml">P</mi><mi id="S3.E2.m1.2.2.1.1.1.1.1.3" mathvariant="normal" xref="S3.E2.m1.2.2.1.1.1.1.1.3.cmml">Θ</mi></msub><mo id="S3.E2.m1.2.2.1.1.1.1a" xref="S3.E2.m1.2.2.1.1.1.2.cmml">⁡</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.2.cmml"><mo id="S3.E2.m1.2.2.1.1.1.1.2.1" stretchy="false" xref="S3.E2.m1.2.2.1.1.1.2.cmml">(</mo><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">Z</mi><mo id="S3.E2.m1.2.2.1.1.1.1.2.2" stretchy="false" xref="S3.E2.m1.2.2.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E2.m1.2.2.1.2" xref="S3.E2.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.2.1.1.cmml" xref="S3.E2.m1.2.2.1"><eq id="S3.E2.m1.2.2.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.2"></eq><apply id="S3.E2.m1.2.2.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.3"><ci id="S3.E2.m1.2.2.1.1.3.1.cmml" xref="S3.E2.m1.2.2.1.1.3.1">^</ci><ci id="S3.E2.m1.2.2.1.1.3.2.cmml" xref="S3.E2.m1.2.2.1.1.3.2">𝑦</ci></apply><apply id="S3.E2.m1.2.2.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1"><apply id="S3.E2.m1.2.2.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1">subscript</csymbol><ci id="S3.E2.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.2">P</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.3">Θ</ci></apply><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">𝑍</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">\hat{y}=\operatorname{P}_{\Theta}(Z),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.p2.5">where <math alttext="\Theta" class="ltx_Math" display="inline" id="S3.SS1.p2.5.m1.1"><semantics id="S3.SS1.p2.5.m1.1a"><mi id="S3.SS1.p2.5.m1.1.1" mathvariant="normal" xref="S3.SS1.p2.5.m1.1.1.cmml">Θ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m1.1b"><ci id="S3.SS1.p2.5.m1.1.1.cmml" xref="S3.SS1.p2.5.m1.1.1">Θ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m1.1c">\Theta</annotation></semantics></math> denotes the model parameters.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.2">For summarization, we generate a summary sequence <math alttext="\hat{S}=(s_{1},...,s_{l})" class="ltx_Math" display="inline" id="S3.SS1.p3.1.m1.3"><semantics id="S3.SS1.p3.1.m1.3a"><mrow id="S3.SS1.p3.1.m1.3.3" xref="S3.SS1.p3.1.m1.3.3.cmml"><mover accent="true" id="S3.SS1.p3.1.m1.3.3.4" xref="S3.SS1.p3.1.m1.3.3.4.cmml"><mi id="S3.SS1.p3.1.m1.3.3.4.2" xref="S3.SS1.p3.1.m1.3.3.4.2.cmml">S</mi><mo id="S3.SS1.p3.1.m1.3.3.4.1" xref="S3.SS1.p3.1.m1.3.3.4.1.cmml">^</mo></mover><mo id="S3.SS1.p3.1.m1.3.3.3" xref="S3.SS1.p3.1.m1.3.3.3.cmml">=</mo><mrow id="S3.SS1.p3.1.m1.3.3.2.2" xref="S3.SS1.p3.1.m1.3.3.2.3.cmml"><mo id="S3.SS1.p3.1.m1.3.3.2.2.3" stretchy="false" xref="S3.SS1.p3.1.m1.3.3.2.3.cmml">(</mo><msub id="S3.SS1.p3.1.m1.2.2.1.1.1" xref="S3.SS1.p3.1.m1.2.2.1.1.1.cmml"><mi id="S3.SS1.p3.1.m1.2.2.1.1.1.2" xref="S3.SS1.p3.1.m1.2.2.1.1.1.2.cmml">s</mi><mn id="S3.SS1.p3.1.m1.2.2.1.1.1.3" xref="S3.SS1.p3.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS1.p3.1.m1.3.3.2.2.4" xref="S3.SS1.p3.1.m1.3.3.2.3.cmml">,</mo><mi id="S3.SS1.p3.1.m1.1.1" mathvariant="normal" xref="S3.SS1.p3.1.m1.1.1.cmml">…</mi><mo id="S3.SS1.p3.1.m1.3.3.2.2.5" xref="S3.SS1.p3.1.m1.3.3.2.3.cmml">,</mo><msub id="S3.SS1.p3.1.m1.3.3.2.2.2" xref="S3.SS1.p3.1.m1.3.3.2.2.2.cmml"><mi id="S3.SS1.p3.1.m1.3.3.2.2.2.2" xref="S3.SS1.p3.1.m1.3.3.2.2.2.2.cmml">s</mi><mi id="S3.SS1.p3.1.m1.3.3.2.2.2.3" xref="S3.SS1.p3.1.m1.3.3.2.2.2.3.cmml">l</mi></msub><mo id="S3.SS1.p3.1.m1.3.3.2.2.6" stretchy="false" xref="S3.SS1.p3.1.m1.3.3.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.3b"><apply id="S3.SS1.p3.1.m1.3.3.cmml" xref="S3.SS1.p3.1.m1.3.3"><eq id="S3.SS1.p3.1.m1.3.3.3.cmml" xref="S3.SS1.p3.1.m1.3.3.3"></eq><apply id="S3.SS1.p3.1.m1.3.3.4.cmml" xref="S3.SS1.p3.1.m1.3.3.4"><ci id="S3.SS1.p3.1.m1.3.3.4.1.cmml" xref="S3.SS1.p3.1.m1.3.3.4.1">^</ci><ci id="S3.SS1.p3.1.m1.3.3.4.2.cmml" xref="S3.SS1.p3.1.m1.3.3.4.2">𝑆</ci></apply><vector id="S3.SS1.p3.1.m1.3.3.2.3.cmml" xref="S3.SS1.p3.1.m1.3.3.2.2"><apply id="S3.SS1.p3.1.m1.2.2.1.1.1.cmml" xref="S3.SS1.p3.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.SS1.p3.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.2.2.1.1.1.2">𝑠</ci><cn id="S3.SS1.p3.1.m1.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS1.p3.1.m1.2.2.1.1.1.3">1</cn></apply><ci id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">…</ci><apply id="S3.SS1.p3.1.m1.3.3.2.2.2.cmml" xref="S3.SS1.p3.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.p3.1.m1.3.3.2.2.2.1.cmml" xref="S3.SS1.p3.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.SS1.p3.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS1.p3.1.m1.3.3.2.2.2.2">𝑠</ci><ci id="S3.SS1.p3.1.m1.3.3.2.2.2.3.cmml" xref="S3.SS1.p3.1.m1.3.3.2.2.2.3">𝑙</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.3c">\hat{S}=(s_{1},...,s_{l})</annotation></semantics></math> based on <math alttext="Z" class="ltx_Math" display="inline" id="S3.SS1.p3.2.m2.1"><semantics id="S3.SS1.p3.2.m2.1a"><mi id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><ci id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">𝑍</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">Z</annotation></semantics></math>:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\hat{S}=\text{argmax}_{S}\operatorname{P}_{\Theta}(S\mid Z)." class="ltx_Math" display="block" id="S3.E3.m1.1"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mover accent="true" id="S3.E3.m1.1.1.1.1.4" xref="S3.E3.m1.1.1.1.1.4.cmml"><mi id="S3.E3.m1.1.1.1.1.4.2" xref="S3.E3.m1.1.1.1.1.4.2.cmml">S</mi><mo id="S3.E3.m1.1.1.1.1.4.1" xref="S3.E3.m1.1.1.1.1.4.1.cmml">^</mo></mover><mo id="S3.E3.m1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.3.cmml">=</mo><mrow id="S3.E3.m1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.2.cmml"><msub id="S3.E3.m1.1.1.1.1.2.4" xref="S3.E3.m1.1.1.1.1.2.4.cmml"><mtext id="S3.E3.m1.1.1.1.1.2.4.2" xref="S3.E3.m1.1.1.1.1.2.4.2a.cmml">argmax</mtext><mi id="S3.E3.m1.1.1.1.1.2.4.3" xref="S3.E3.m1.1.1.1.1.2.4.3.cmml">S</mi></msub><mo id="S3.E3.m1.1.1.1.1.2.3" lspace="0.167em" rspace="0em" xref="S3.E3.m1.1.1.1.1.2.3.cmml">​</mo><mrow id="S3.E3.m1.1.1.1.1.2.2.2" xref="S3.E3.m1.1.1.1.1.2.2.3.cmml"><msub id="S3.E3.m1.1.1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.2" mathvariant="normal" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2.cmml">P</mi><mi id="S3.E3.m1.1.1.1.1.1.1.1.1.3" mathvariant="normal" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3.cmml">Θ</mi></msub><mo id="S3.E3.m1.1.1.1.1.2.2.2a" xref="S3.E3.m1.1.1.1.1.2.2.3.cmml">⁡</mo><mrow id="S3.E3.m1.1.1.1.1.2.2.2.2" xref="S3.E3.m1.1.1.1.1.2.2.3.cmml"><mo id="S3.E3.m1.1.1.1.1.2.2.2.2.2" stretchy="false" xref="S3.E3.m1.1.1.1.1.2.2.3.cmml">(</mo><mrow id="S3.E3.m1.1.1.1.1.2.2.2.2.1" xref="S3.E3.m1.1.1.1.1.2.2.2.2.1.cmml"><mi id="S3.E3.m1.1.1.1.1.2.2.2.2.1.2" xref="S3.E3.m1.1.1.1.1.2.2.2.2.1.2.cmml">S</mi><mo id="S3.E3.m1.1.1.1.1.2.2.2.2.1.1" xref="S3.E3.m1.1.1.1.1.2.2.2.2.1.1.cmml">∣</mo><mi id="S3.E3.m1.1.1.1.1.2.2.2.2.1.3" xref="S3.E3.m1.1.1.1.1.2.2.2.2.1.3.cmml">Z</mi></mrow><mo id="S3.E3.m1.1.1.1.1.2.2.2.2.3" stretchy="false" xref="S3.E3.m1.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E3.m1.1.1.1.2" lspace="0em" xref="S3.E3.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"><eq id="S3.E3.m1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.3"></eq><apply id="S3.E3.m1.1.1.1.1.4.cmml" xref="S3.E3.m1.1.1.1.1.4"><ci id="S3.E3.m1.1.1.1.1.4.1.cmml" xref="S3.E3.m1.1.1.1.1.4.1">^</ci><ci id="S3.E3.m1.1.1.1.1.4.2.cmml" xref="S3.E3.m1.1.1.1.1.4.2">𝑆</ci></apply><apply id="S3.E3.m1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.2"><times id="S3.E3.m1.1.1.1.1.2.3.cmml" xref="S3.E3.m1.1.1.1.1.2.3"></times><apply id="S3.E3.m1.1.1.1.1.2.4.cmml" xref="S3.E3.m1.1.1.1.1.2.4"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.2.4.1.cmml" xref="S3.E3.m1.1.1.1.1.2.4">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.2.4.2a.cmml" xref="S3.E3.m1.1.1.1.1.2.4.2"><mtext id="S3.E3.m1.1.1.1.1.2.4.2.cmml" xref="S3.E3.m1.1.1.1.1.2.4.2">argmax</mtext></ci><ci id="S3.E3.m1.1.1.1.1.2.4.3.cmml" xref="S3.E3.m1.1.1.1.1.2.4.3">𝑆</ci></apply><apply id="S3.E3.m1.1.1.1.1.2.2.3.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2"><apply id="S3.E3.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.2">P</ci><ci id="S3.E3.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.1.1.3">Θ</ci></apply><apply id="S3.E3.m1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2.1"><csymbol cd="latexml" id="S3.E3.m1.1.1.1.1.2.2.2.2.1.1.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2.1.1">conditional</csymbol><ci id="S3.E3.m1.1.1.1.1.2.2.2.2.1.2.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2.1.2">𝑆</ci><ci id="S3.E3.m1.1.1.1.1.2.2.2.2.1.3.cmml" xref="S3.E3.m1.1.1.1.1.2.2.2.2.1.3">𝑍</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">\hat{S}=\text{argmax}_{S}\operatorname{P}_{\Theta}(S\mid Z).</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Fusion Bottleneck</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.4">As shown in Figure <a class="ltx_ref" href="#S2.F2" title="Figure 2 ‣ 2.3 Multimodal Sentiment Analysis ‣ 2 Related Work ‣ Denoising Bottleneck with Mutual Information Maximization for Video Multimodal Fusion"><span class="ltx_text ltx_ref_tag">2</span></a>, we first employ a fusion bottleneck with a restrained receptive field to perform multimodal fusion and filter out noise and redundancy in videos.
Specifically, fusion bottleneck forces cross-modal information flow passes via randomly initialized bottleneck embeddings <math alttext="B\in\mathbb{R}^{{l_{b}\times d_{m}}}" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><mrow id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">B</mi><mo id="S3.SS2.p1.1.m1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.cmml">∈</mo><msup id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml"><mi id="S3.SS2.p1.1.m1.1.1.3.2" xref="S3.SS2.p1.1.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S3.SS2.p1.1.m1.1.1.3.3" xref="S3.SS2.p1.1.m1.1.1.3.3.cmml"><msub id="S3.SS2.p1.1.m1.1.1.3.3.2" xref="S3.SS2.p1.1.m1.1.1.3.3.2.cmml"><mi id="S3.SS2.p1.1.m1.1.1.3.3.2.2" xref="S3.SS2.p1.1.m1.1.1.3.3.2.2.cmml">l</mi><mi id="S3.SS2.p1.1.m1.1.1.3.3.2.3" xref="S3.SS2.p1.1.m1.1.1.3.3.2.3.cmml">b</mi></msub><mo id="S3.SS2.p1.1.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS2.p1.1.m1.1.1.3.3.1.cmml">×</mo><msub id="S3.SS2.p1.1.m1.1.1.3.3.3" xref="S3.SS2.p1.1.m1.1.1.3.3.3.cmml"><mi id="S3.SS2.p1.1.m1.1.1.3.3.3.2" xref="S3.SS2.p1.1.m1.1.1.3.3.3.2.cmml">d</mi><mi id="S3.SS2.p1.1.m1.1.1.3.3.3.3" xref="S3.SS2.p1.1.m1.1.1.3.3.3.3.cmml">m</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><in id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1"></in><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">𝐵</ci><apply id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.3.1.cmml" xref="S3.SS2.p1.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.3.2.cmml" xref="S3.SS2.p1.1.m1.1.1.3.2">ℝ</ci><apply id="S3.SS2.p1.1.m1.1.1.3.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3"><times id="S3.SS2.p1.1.m1.1.1.3.3.1.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3.1"></times><apply id="S3.SS2.p1.1.m1.1.1.3.3.2.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.3.3.2.1.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3.2">subscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.3.3.2.2.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3.2.2">𝑙</ci><ci id="S3.SS2.p1.1.m1.1.1.3.3.2.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3.2.3">𝑏</ci></apply><apply id="S3.SS2.p1.1.m1.1.1.3.3.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.3.3.3.1.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3.3">subscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.3.3.3.2.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3.3.2">𝑑</ci><ci id="S3.SS2.p1.1.m1.1.1.3.3.3.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3.3.3">𝑚</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">B\in\mathbb{R}^{{l_{b}\times d_{m}}}</annotation></semantics></math> with a small sequence length, where <math alttext="d_{m}" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.1"><semantics id="S3.SS2.p1.2.m2.1a"><msub id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml">d</mi><mi id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2">𝑑</ci><ci id="S3.SS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">d_{m}</annotation></semantics></math> denotes dimension of features and <math alttext="l_{b}\ll l" class="ltx_Math" display="inline" id="S3.SS2.p1.3.m3.1"><semantics id="S3.SS2.p1.3.m3.1a"><mrow id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml"><msub id="S3.SS2.p1.3.m3.1.1.2" xref="S3.SS2.p1.3.m3.1.1.2.cmml"><mi id="S3.SS2.p1.3.m3.1.1.2.2" xref="S3.SS2.p1.3.m3.1.1.2.2.cmml">l</mi><mi id="S3.SS2.p1.3.m3.1.1.2.3" xref="S3.SS2.p1.3.m3.1.1.2.3.cmml">b</mi></msub><mo id="S3.SS2.p1.3.m3.1.1.1" xref="S3.SS2.p1.3.m3.1.1.1.cmml">≪</mo><mi id="S3.SS2.p1.3.m3.1.1.3" xref="S3.SS2.p1.3.m3.1.1.3.cmml">l</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><apply id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1"><csymbol cd="latexml" id="S3.SS2.p1.3.m3.1.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1.1">much-less-than</csymbol><apply id="S3.SS2.p1.3.m3.1.1.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p1.3.m3.1.1.2.1.cmml" xref="S3.SS2.p1.3.m3.1.1.2">subscript</csymbol><ci id="S3.SS2.p1.3.m3.1.1.2.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2.2">𝑙</ci><ci id="S3.SS2.p1.3.m3.1.1.2.3.cmml" xref="S3.SS2.p1.3.m3.1.1.2.3">𝑏</ci></apply><ci id="S3.SS2.p1.3.m3.1.1.3.cmml" xref="S3.SS2.p1.3.m3.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">l_{b}\ll l</annotation></semantics></math>.
The restrained receptive field of <math alttext="B" class="ltx_Math" display="inline" id="S3.SS2.p1.4.m4.1"><semantics id="S3.SS2.p1.4.m4.1a"><mi id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">B</annotation></semantics></math> forces model to collate and condense unimodal information before sharing it with the other modalities.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.3">With a small length <math alttext="l_{b}" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><msub id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.2.cmml">l</mi><mi id="S3.SS2.p2.1.m1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.3.cmml">b</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2">𝑙</ci><ci id="S3.SS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3">𝑏</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">l_{b}</annotation></semantics></math>, embedding <math alttext="B" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m2.1"><semantics id="S3.SS2.p2.2.m2.1a"><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">B</annotation></semantics></math> acts like a bottleneck in cross-modal interaction.
In the fusion bottleneck module, unimodal features cannot directly attend to each other and they can only attend to the bottleneck embeddings <math alttext="B" class="ltx_Math" display="inline" id="S3.SS2.p2.3.m3.1"><semantics id="S3.SS2.p2.3.m3.1a"><mi id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><ci id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">B</annotation></semantics></math> to exchange information in it.
Meanwhile, the bottleneck can attend to all of the modalities, which makes information flow across modalities must pass through the bottleneck with a restrained receptive field.
The fusion bottleneck module forces the model to condense and collate information and filter out noise and redundancy.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.2">Specifically, in the fusion bottleneck module, with bottleneck embeddings <math alttext="B" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">B</annotation></semantics></math> and unimodal features <math alttext="X_{m}" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><msub id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.2" xref="S3.SS2.p3.2.m2.1.1.2.cmml">X</mi><mi id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2">𝑋</ci><ci id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">X_{m}</annotation></semantics></math>, the fusion result is calculated as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="[X_{m}^{l+1}||B_{m}^{l+1}]=\text{Transformer}([X_{m}^{l}||B^{l}])," class="ltx_math_unparsed" display="block" id="S3.E4.m1.1"><semantics id="S3.E4.m1.1a"><mrow id="S3.E4.m1.1b"><mrow id="S3.E4.m1.1.1"><mo id="S3.E4.m1.1.1.1" stretchy="false">[</mo><msubsup id="S3.E4.m1.1.1.2"><mi id="S3.E4.m1.1.1.2.2.2">X</mi><mi id="S3.E4.m1.1.1.2.2.3">m</mi><mrow id="S3.E4.m1.1.1.2.3"><mi id="S3.E4.m1.1.1.2.3.2">l</mi><mo id="S3.E4.m1.1.1.2.3.1">+</mo><mn id="S3.E4.m1.1.1.2.3.3">1</mn></mrow></msubsup><mo fence="false" id="S3.E4.m1.1.1.3" rspace="0.167em" stretchy="false">|</mo><mo fence="false" id="S3.E4.m1.1.1.4" rspace="0.167em" stretchy="false">|</mo><msubsup id="S3.E4.m1.1.1.5"><mi id="S3.E4.m1.1.1.5.2.2">B</mi><mi id="S3.E4.m1.1.1.5.2.3">m</mi><mrow id="S3.E4.m1.1.1.5.3"><mi id="S3.E4.m1.1.1.5.3.2">l</mi><mo id="S3.E4.m1.1.1.5.3.1">+</mo><mn id="S3.E4.m1.1.1.5.3.3">1</mn></mrow></msubsup><mo id="S3.E4.m1.1.1.6" stretchy="false">]</mo></mrow><mo id="S3.E4.m1.1.2">=</mo><mtext id="S3.E4.m1.1.3">Transformer</mtext><mrow id="S3.E4.m1.1.4"><mo id="S3.E4.m1.1.4.1" stretchy="false">(</mo><mrow id="S3.E4.m1.1.4.2"><mo id="S3.E4.m1.1.4.2.1" stretchy="false">[</mo><msubsup id="S3.E4.m1.1.4.2.2"><mi id="S3.E4.m1.1.4.2.2.2.2">X</mi><mi id="S3.E4.m1.1.4.2.2.2.3">m</mi><mi id="S3.E4.m1.1.4.2.2.3">l</mi></msubsup><mo fence="false" id="S3.E4.m1.1.4.2.3" rspace="0.167em" stretchy="false">|</mo><mo fence="false" id="S3.E4.m1.1.4.2.4" rspace="0.167em" stretchy="false">|</mo><msup id="S3.E4.m1.1.4.2.5"><mi id="S3.E4.m1.1.4.2.5.2">B</mi><mi id="S3.E4.m1.1.4.2.5.3">l</mi></msup><mo id="S3.E4.m1.1.4.2.6" stretchy="false">]</mo></mrow><mo id="S3.E4.m1.1.4.3" stretchy="false">)</mo></mrow><mo id="S3.E4.m1.1.5">,</mo></mrow><annotation encoding="application/x-tex" id="S3.E4.m1.1c">[X_{m}^{l+1}||B_{m}^{l+1}]=\text{Transformer}([X_{m}^{l}||B^{l}]),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<table class="ltx_equation ltx_eqn_table" id="S3.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="B^{l+1}=\text{Mean}(B_{m}^{l+1})," class="ltx_Math" display="block" id="S3.E5.m1.1"><semantics id="S3.E5.m1.1a"><mrow id="S3.E5.m1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml"><mrow id="S3.E5.m1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml"><msup id="S3.E5.m1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.3.cmml"><mi id="S3.E5.m1.1.1.1.1.3.2" xref="S3.E5.m1.1.1.1.1.3.2.cmml">B</mi><mrow id="S3.E5.m1.1.1.1.1.3.3" xref="S3.E5.m1.1.1.1.1.3.3.cmml"><mi id="S3.E5.m1.1.1.1.1.3.3.2" xref="S3.E5.m1.1.1.1.1.3.3.2.cmml">l</mi><mo id="S3.E5.m1.1.1.1.1.3.3.1" xref="S3.E5.m1.1.1.1.1.3.3.1.cmml">+</mo><mn id="S3.E5.m1.1.1.1.1.3.3.3" xref="S3.E5.m1.1.1.1.1.3.3.3.cmml">1</mn></mrow></msup><mo id="S3.E5.m1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E5.m1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.cmml"><mtext id="S3.E5.m1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.3a.cmml">Mean</mtext><mo id="S3.E5.m1.1.1.1.1.1.2" lspace="0em" rspace="0em" xref="S3.E5.m1.1.1.1.1.1.2.cmml">​</mo><mrow id="S3.E5.m1.1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E5.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E5.m1.1.1.1.1.1.1.1.1.cmml">(</mo><msubsup id="S3.E5.m1.1.1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E5.m1.1.1.1.1.1.1.1.1.2.2" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2.2.cmml">B</mi><mi id="S3.E5.m1.1.1.1.1.1.1.1.1.2.3" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2.3.cmml">m</mi><mrow id="S3.E5.m1.1.1.1.1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E5.m1.1.1.1.1.1.1.1.1.3.2" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.2.cmml">l</mi><mo id="S3.E5.m1.1.1.1.1.1.1.1.1.3.1" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.1.cmml">+</mo><mn id="S3.E5.m1.1.1.1.1.1.1.1.1.3.3" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.3.cmml">1</mn></mrow></msubsup><mo id="S3.E5.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E5.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E5.m1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.1b"><apply id="S3.E5.m1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1"><eq id="S3.E5.m1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.2"></eq><apply id="S3.E5.m1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.1.1.1.1.3">superscript</csymbol><ci id="S3.E5.m1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.1.1.1.1.3.2">𝐵</ci><apply id="S3.E5.m1.1.1.1.1.3.3.cmml" xref="S3.E5.m1.1.1.1.1.3.3"><plus id="S3.E5.m1.1.1.1.1.3.3.1.cmml" xref="S3.E5.m1.1.1.1.1.3.3.1"></plus><ci id="S3.E5.m1.1.1.1.1.3.3.2.cmml" xref="S3.E5.m1.1.1.1.1.3.3.2">𝑙</ci><cn id="S3.E5.m1.1.1.1.1.3.3.3.cmml" type="integer" xref="S3.E5.m1.1.1.1.1.3.3.3">1</cn></apply></apply><apply id="S3.E5.m1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1"><times id="S3.E5.m1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.2"></times><ci id="S3.E5.m1.1.1.1.1.1.3a.cmml" xref="S3.E5.m1.1.1.1.1.1.3"><mtext id="S3.E5.m1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.1.3">Mean</mtext></ci><apply id="S3.E5.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E5.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2.2">𝐵</ci><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.2.3">𝑚</ci></apply><apply id="S3.E5.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3"><plus id="S3.E5.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.1"></plus><ci id="S3.E5.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.2">𝑙</ci><cn id="S3.E5.m1.1.1.1.1.1.1.1.1.3.3.cmml" type="integer" xref="S3.E5.m1.1.1.1.1.1.1.1.1.3.3">1</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.1c">B^{l+1}=\text{Mean}(B_{m}^{l+1}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p3.8">where <math alttext="l" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m1.1"><semantics id="S3.SS2.p3.3.m1.1a"><mi id="S3.SS2.p3.3.m1.1.1" xref="S3.SS2.p3.3.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m1.1b"><ci id="S3.SS2.p3.3.m1.1.1.cmml" xref="S3.SS2.p3.3.m1.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m1.1c">l</annotation></semantics></math> denotes the layer number and <math alttext="||" class="ltx_math_unparsed" display="inline" id="S3.SS2.p3.4.m2.1"><semantics id="S3.SS2.p3.4.m2.1a"><mrow id="S3.SS2.p3.4.m2.1b"><mo fence="false" id="S3.SS2.p3.4.m2.1.1" rspace="0.167em" stretchy="false">|</mo><mo fence="false" id="S3.SS2.p3.4.m2.1.2" stretchy="false">|</mo></mrow><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m2.1c">||</annotation></semantics></math> denotes the concatenation operation.
As shown in Equation <a class="ltx_ref" href="#S3.E4" title="In 3.2 Fusion Bottleneck ‣ 3 Methodology ‣ Denoising Bottleneck with Mutual Information Maximization for Video Multimodal Fusion"><span class="ltx_text ltx_ref_tag">4</span></a> and <a class="ltx_ref" href="#S3.E5" title="In 3.2 Fusion Bottleneck ‣ 3 Methodology ‣ Denoising Bottleneck with Mutual Information Maximization for Video Multimodal Fusion"><span class="ltx_text ltx_ref_tag">5</span></a>, each time a Transformer layer is passed, bottleneck embedding <math alttext="B" class="ltx_Math" display="inline" id="S3.SS2.p3.5.m3.1"><semantics id="S3.SS2.p3.5.m3.1a"><mi id="S3.SS2.p3.5.m3.1.1" xref="S3.SS2.p3.5.m3.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m3.1b"><ci id="S3.SS2.p3.5.m3.1.1.cmml" xref="S3.SS2.p3.5.m3.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m3.1c">B</annotation></semantics></math> is updated by unimodal features.
In turn, unimodal features integrate condensed information from other modalities through bottleneck embeddings <math alttext="B" class="ltx_Math" display="inline" id="S3.SS2.p3.6.m4.1"><semantics id="S3.SS2.p3.6.m4.1a"><mi id="S3.SS2.p3.6.m4.1.1" xref="S3.SS2.p3.6.m4.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m4.1b"><ci id="S3.SS2.p3.6.m4.1.1.cmml" xref="S3.SS2.p3.6.m4.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m4.1c">B</annotation></semantics></math>.
Finally, we output the text features <math alttext="X_{t}^{L}" class="ltx_Math" display="inline" id="S3.SS2.p3.7.m5.1"><semantics id="S3.SS2.p3.7.m5.1a"><msubsup id="S3.SS2.p3.7.m5.1.1" xref="S3.SS2.p3.7.m5.1.1.cmml"><mi id="S3.SS2.p3.7.m5.1.1.2.2" xref="S3.SS2.p3.7.m5.1.1.2.2.cmml">X</mi><mi id="S3.SS2.p3.7.m5.1.1.2.3" xref="S3.SS2.p3.7.m5.1.1.2.3.cmml">t</mi><mi id="S3.SS2.p3.7.m5.1.1.3" xref="S3.SS2.p3.7.m5.1.1.3.cmml">L</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.7.m5.1b"><apply id="S3.SS2.p3.7.m5.1.1.cmml" xref="S3.SS2.p3.7.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.7.m5.1.1.1.cmml" xref="S3.SS2.p3.7.m5.1.1">superscript</csymbol><apply id="S3.SS2.p3.7.m5.1.1.2.cmml" xref="S3.SS2.p3.7.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.7.m5.1.1.2.1.cmml" xref="S3.SS2.p3.7.m5.1.1">subscript</csymbol><ci id="S3.SS2.p3.7.m5.1.1.2.2.cmml" xref="S3.SS2.p3.7.m5.1.1.2.2">𝑋</ci><ci id="S3.SS2.p3.7.m5.1.1.2.3.cmml" xref="S3.SS2.p3.7.m5.1.1.2.3">𝑡</ci></apply><ci id="S3.SS2.p3.7.m5.1.1.3.cmml" xref="S3.SS2.p3.7.m5.1.1.3">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.7.m5.1c">X_{t}^{L}</annotation></semantics></math> of the last layer <math alttext="L" class="ltx_Math" display="inline" id="S3.SS2.p3.8.m6.1"><semantics id="S3.SS2.p3.8.m6.1a"><mi id="S3.SS2.p3.8.m6.1.1" xref="S3.SS2.p3.8.m6.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.8.m6.1b"><ci id="S3.SS2.p3.8.m6.1.1.cmml" xref="S3.SS2.p3.8.m6.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.8.m6.1c">L</annotation></semantics></math>, which are injected with condensed visual and audio information, as the fusion result.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Fusion Mutual Information Maximization</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">The fusion bottleneck module constrains information flow across modalities in order to filter out noise and redundancy.
However, it may result in loss of critical information as well when fusion bottleneck selects what information to be shared.
To alleviate this issue, we employ a mutual information maximization (MI-Max) module to preserve representative and salient information from redundant modalities in fusion results.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.2">Mutual information is a concept from information theory that estimates the relationship between pairs of variables.
Through prompting the mutual information between fusion results <math alttext="Z" class="ltx_Math" display="inline" id="S3.SS3.p2.1.m1.1"><semantics id="S3.SS3.p2.1.m1.1a"><mi id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><ci id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">𝑍</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">Z</annotation></semantics></math> and multimodal inputs <math alttext="X_{m}" class="ltx_Math" display="inline" id="S3.SS3.p2.2.m2.1"><semantics id="S3.SS3.p2.2.m2.1a"><msub id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml"><mi id="S3.SS3.p2.2.m2.1.1.2" xref="S3.SS3.p2.2.m2.1.1.2.cmml">X</mi><mi id="S3.SS3.p2.2.m2.1.1.3" xref="S3.SS3.p2.2.m2.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><apply id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.1.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p2.2.m2.1.1.2.cmml" xref="S3.SS3.p2.2.m2.1.1.2">𝑋</ci><ci id="S3.SS3.p2.2.m2.1.1.3.cmml" xref="S3.SS3.p2.2.m2.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">X_{m}</annotation></semantics></math>, we can capture modality-invariant cues among modalities <cite class="ltx_cite ltx_citemacro_citep">(Han et al., <a class="ltx_ref" href="#bib.bib6" title="">2021</a>)</cite> and keep key information preserved by regulating the fusion bottleneck module.</p>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.4">Since direct maximization of mutual information for continuous and high-dimensional variables is intractable <cite class="ltx_cite ltx_citemacro_citep">(Belghazi et al., <a class="ltx_ref" href="#bib.bib1" title="">2018</a>)</cite>, we instead minimize the lower bound of mutual information as <cite class="ltx_cite ltx_citemacro_citet">Han et al. (<a class="ltx_ref" href="#bib.bib6" title="">2021</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Oord et al. (<a class="ltx_ref" href="#bib.bib18" title="">2018</a>)</cite>.
To be specific, we first construct an opposite path from <math alttext="Z" class="ltx_Math" display="inline" id="S3.SS3.p3.1.m1.1"><semantics id="S3.SS3.p3.1.m1.1a"><mi id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><ci id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">𝑍</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">Z</annotation></semantics></math> to predict <math alttext="X_{m}" class="ltx_Math" display="inline" id="S3.SS3.p3.2.m2.1"><semantics id="S3.SS3.p3.2.m2.1a"><msub id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml"><mi id="S3.SS3.p3.2.m2.1.1.2" xref="S3.SS3.p3.2.m2.1.1.2.cmml">X</mi><mi id="S3.SS3.p3.2.m2.1.1.3" xref="S3.SS3.p3.2.m2.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><apply id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.2.m2.1.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p3.2.m2.1.1.2.cmml" xref="S3.SS3.p3.2.m2.1.1.2">𝑋</ci><ci id="S3.SS3.p3.2.m2.1.1.3.cmml" xref="S3.SS3.p3.2.m2.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">X_{m}</annotation></semantics></math> by an MLP <math alttext="\mathcal{F}" class="ltx_Math" display="inline" id="S3.SS3.p3.3.m3.1"><semantics id="S3.SS3.p3.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.3.m3.1.1" xref="S3.SS3.p3.3.m3.1.1.cmml">ℱ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m3.1b"><ci id="S3.SS3.p3.3.m3.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1">ℱ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.3.m3.1c">\mathcal{F}</annotation></semantics></math>.
Then, to gauge correlation between the prediction and <math alttext="X_{m}" class="ltx_Math" display="inline" id="S3.SS3.p3.4.m4.1"><semantics id="S3.SS3.p3.4.m4.1a"><msub id="S3.SS3.p3.4.m4.1.1" xref="S3.SS3.p3.4.m4.1.1.cmml"><mi id="S3.SS3.p3.4.m4.1.1.2" xref="S3.SS3.p3.4.m4.1.1.2.cmml">X</mi><mi id="S3.SS3.p3.4.m4.1.1.3" xref="S3.SS3.p3.4.m4.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.4.m4.1b"><apply id="S3.SS3.p3.4.m4.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.4.m4.1.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.p3.4.m4.1.1.2.cmml" xref="S3.SS3.p3.4.m4.1.1.2">𝑋</ci><ci id="S3.SS3.p3.4.m4.1.1.3.cmml" xref="S3.SS3.p3.4.m4.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.4.m4.1c">X_{m}</annotation></semantics></math>, we use a normalized similarity function as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{sim}(X_{m},Z)=\text{exp}\left(\frac{X_{m}}{\left\|X_{m}\right\|^{2}}\odot\frac{\mathcal{F}(Z)}{\left\|\mathcal{F}(Z)\right\|^{2}}\right)," class="ltx_Math" display="block" id="S3.E6.m1.6"><semantics id="S3.E6.m1.6a"><mrow id="S3.E6.m1.6.6.1" xref="S3.E6.m1.6.6.1.1.cmml"><mrow id="S3.E6.m1.6.6.1.1" xref="S3.E6.m1.6.6.1.1.cmml"><mrow id="S3.E6.m1.6.6.1.1.1" xref="S3.E6.m1.6.6.1.1.1.cmml"><mtext id="S3.E6.m1.6.6.1.1.1.3" xref="S3.E6.m1.6.6.1.1.1.3a.cmml">sim</mtext><mo id="S3.E6.m1.6.6.1.1.1.2" lspace="0em" rspace="0em" xref="S3.E6.m1.6.6.1.1.1.2.cmml">​</mo><mrow id="S3.E6.m1.6.6.1.1.1.1.1" xref="S3.E6.m1.6.6.1.1.1.1.2.cmml"><mo id="S3.E6.m1.6.6.1.1.1.1.1.2" stretchy="false" xref="S3.E6.m1.6.6.1.1.1.1.2.cmml">(</mo><msub id="S3.E6.m1.6.6.1.1.1.1.1.1" xref="S3.E6.m1.6.6.1.1.1.1.1.1.cmml"><mi id="S3.E6.m1.6.6.1.1.1.1.1.1.2" xref="S3.E6.m1.6.6.1.1.1.1.1.1.2.cmml">X</mi><mi id="S3.E6.m1.6.6.1.1.1.1.1.1.3" xref="S3.E6.m1.6.6.1.1.1.1.1.1.3.cmml">m</mi></msub><mo id="S3.E6.m1.6.6.1.1.1.1.1.3" xref="S3.E6.m1.6.6.1.1.1.1.2.cmml">,</mo><mi id="S3.E6.m1.5.5" xref="S3.E6.m1.5.5.cmml">Z</mi><mo id="S3.E6.m1.6.6.1.1.1.1.1.4" stretchy="false" xref="S3.E6.m1.6.6.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E6.m1.6.6.1.1.3" xref="S3.E6.m1.6.6.1.1.3.cmml">=</mo><mrow id="S3.E6.m1.6.6.1.1.2" xref="S3.E6.m1.6.6.1.1.2.cmml"><mtext id="S3.E6.m1.6.6.1.1.2.3" xref="S3.E6.m1.6.6.1.1.2.3a.cmml">exp</mtext><mo id="S3.E6.m1.6.6.1.1.2.2" lspace="0em" rspace="0em" xref="S3.E6.m1.6.6.1.1.2.2.cmml">​</mo><mrow id="S3.E6.m1.6.6.1.1.2.1.1" xref="S3.E6.m1.6.6.1.1.2.1.1.1.cmml"><mo id="S3.E6.m1.6.6.1.1.2.1.1.2" xref="S3.E6.m1.6.6.1.1.2.1.1.1.cmml">(</mo><mrow id="S3.E6.m1.6.6.1.1.2.1.1.1" xref="S3.E6.m1.6.6.1.1.2.1.1.1.cmml"><mfrac id="S3.E6.m1.1.1" xref="S3.E6.m1.1.1.cmml"><msub id="S3.E6.m1.1.1.3" xref="S3.E6.m1.1.1.3.cmml"><mi id="S3.E6.m1.1.1.3.2" xref="S3.E6.m1.1.1.3.2.cmml">X</mi><mi id="S3.E6.m1.1.1.3.3" xref="S3.E6.m1.1.1.3.3.cmml">m</mi></msub><msup id="S3.E6.m1.1.1.1" xref="S3.E6.m1.1.1.1.cmml"><mrow id="S3.E6.m1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.2.cmml"><mo id="S3.E6.m1.1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.2.1.cmml">‖</mo><msub id="S3.E6.m1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.cmml"><mi id="S3.E6.m1.1.1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.1.1.2.cmml">X</mi><mi id="S3.E6.m1.1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.1.3.cmml">m</mi></msub><mo id="S3.E6.m1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S3.E6.m1.1.1.1.3" xref="S3.E6.m1.1.1.1.3.cmml">2</mn></msup></mfrac><mo id="S3.E6.m1.6.6.1.1.2.1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.E6.m1.6.6.1.1.2.1.1.1.1.cmml">⊙</mo><mfrac id="S3.E6.m1.4.4" xref="S3.E6.m1.4.4.cmml"><mrow id="S3.E6.m1.2.2.1" xref="S3.E6.m1.2.2.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.2.2.1.3" xref="S3.E6.m1.2.2.1.3.cmml">ℱ</mi><mo id="S3.E6.m1.2.2.1.2" lspace="0em" rspace="0em" xref="S3.E6.m1.2.2.1.2.cmml">​</mo><mrow id="S3.E6.m1.2.2.1.4.2" xref="S3.E6.m1.2.2.1.cmml"><mo id="S3.E6.m1.2.2.1.4.2.1" stretchy="false" xref="S3.E6.m1.2.2.1.cmml">(</mo><mi id="S3.E6.m1.2.2.1.1" xref="S3.E6.m1.2.2.1.1.cmml">Z</mi><mo id="S3.E6.m1.2.2.1.4.2.2" stretchy="false" xref="S3.E6.m1.2.2.1.cmml">)</mo></mrow></mrow><msup id="S3.E6.m1.4.4.3" xref="S3.E6.m1.4.4.3.cmml"><mrow id="S3.E6.m1.4.4.3.2.1" xref="S3.E6.m1.4.4.3.2.2.cmml"><mo id="S3.E6.m1.4.4.3.2.1.2" xref="S3.E6.m1.4.4.3.2.2.1.cmml">‖</mo><mrow id="S3.E6.m1.4.4.3.2.1.1" xref="S3.E6.m1.4.4.3.2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E6.m1.4.4.3.2.1.1.2" xref="S3.E6.m1.4.4.3.2.1.1.2.cmml">ℱ</mi><mo id="S3.E6.m1.4.4.3.2.1.1.1" lspace="0em" rspace="0em" xref="S3.E6.m1.4.4.3.2.1.1.1.cmml">​</mo><mrow id="S3.E6.m1.4.4.3.2.1.1.3.2" xref="S3.E6.m1.4.4.3.2.1.1.cmml"><mo id="S3.E6.m1.4.4.3.2.1.1.3.2.1" stretchy="false" xref="S3.E6.m1.4.4.3.2.1.1.cmml">(</mo><mi id="S3.E6.m1.3.3.2.1" xref="S3.E6.m1.3.3.2.1.cmml">Z</mi><mo id="S3.E6.m1.4.4.3.2.1.1.3.2.2" stretchy="false" xref="S3.E6.m1.4.4.3.2.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E6.m1.4.4.3.2.1.3" xref="S3.E6.m1.4.4.3.2.2.1.cmml">‖</mo></mrow><mn id="S3.E6.m1.4.4.3.4" xref="S3.E6.m1.4.4.3.4.cmml">2</mn></msup></mfrac></mrow><mo id="S3.E6.m1.6.6.1.1.2.1.1.3" xref="S3.E6.m1.6.6.1.1.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E6.m1.6.6.1.2" xref="S3.E6.m1.6.6.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.6b"><apply id="S3.E6.m1.6.6.1.1.cmml" xref="S3.E6.m1.6.6.1"><eq id="S3.E6.m1.6.6.1.1.3.cmml" xref="S3.E6.m1.6.6.1.1.3"></eq><apply id="S3.E6.m1.6.6.1.1.1.cmml" xref="S3.E6.m1.6.6.1.1.1"><times id="S3.E6.m1.6.6.1.1.1.2.cmml" xref="S3.E6.m1.6.6.1.1.1.2"></times><ci id="S3.E6.m1.6.6.1.1.1.3a.cmml" xref="S3.E6.m1.6.6.1.1.1.3"><mtext id="S3.E6.m1.6.6.1.1.1.3.cmml" xref="S3.E6.m1.6.6.1.1.1.3">sim</mtext></ci><interval closure="open" id="S3.E6.m1.6.6.1.1.1.1.2.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1"><apply id="S3.E6.m1.6.6.1.1.1.1.1.1.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.6.6.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E6.m1.6.6.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1.2">𝑋</ci><ci id="S3.E6.m1.6.6.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.6.6.1.1.1.1.1.1.3">𝑚</ci></apply><ci id="S3.E6.m1.5.5.cmml" xref="S3.E6.m1.5.5">𝑍</ci></interval></apply><apply id="S3.E6.m1.6.6.1.1.2.cmml" xref="S3.E6.m1.6.6.1.1.2"><times id="S3.E6.m1.6.6.1.1.2.2.cmml" xref="S3.E6.m1.6.6.1.1.2.2"></times><ci id="S3.E6.m1.6.6.1.1.2.3a.cmml" xref="S3.E6.m1.6.6.1.1.2.3"><mtext id="S3.E6.m1.6.6.1.1.2.3.cmml" xref="S3.E6.m1.6.6.1.1.2.3">exp</mtext></ci><apply id="S3.E6.m1.6.6.1.1.2.1.1.1.cmml" xref="S3.E6.m1.6.6.1.1.2.1.1"><csymbol cd="latexml" id="S3.E6.m1.6.6.1.1.2.1.1.1.1.cmml" xref="S3.E6.m1.6.6.1.1.2.1.1.1.1">direct-product</csymbol><apply id="S3.E6.m1.1.1.cmml" xref="S3.E6.m1.1.1"><divide id="S3.E6.m1.1.1.2.cmml" xref="S3.E6.m1.1.1"></divide><apply id="S3.E6.m1.1.1.3.cmml" xref="S3.E6.m1.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.3.1.cmml" xref="S3.E6.m1.1.1.3">subscript</csymbol><ci id="S3.E6.m1.1.1.3.2.cmml" xref="S3.E6.m1.1.1.3.2">𝑋</ci><ci id="S3.E6.m1.1.1.3.3.cmml" xref="S3.E6.m1.1.1.3.3">𝑚</ci></apply><apply id="S3.E6.m1.1.1.1.cmml" xref="S3.E6.m1.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1">superscript</csymbol><apply id="S3.E6.m1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E6.m1.1.1.1.1.2.1.cmml" xref="S3.E6.m1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E6.m1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E6.m1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.2">𝑋</ci><ci id="S3.E6.m1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.3">𝑚</ci></apply></apply><cn id="S3.E6.m1.1.1.1.3.cmml" type="integer" xref="S3.E6.m1.1.1.1.3">2</cn></apply></apply><apply id="S3.E6.m1.4.4.cmml" xref="S3.E6.m1.4.4"><divide id="S3.E6.m1.4.4.4.cmml" xref="S3.E6.m1.4.4"></divide><apply id="S3.E6.m1.2.2.1.cmml" xref="S3.E6.m1.2.2.1"><times id="S3.E6.m1.2.2.1.2.cmml" xref="S3.E6.m1.2.2.1.2"></times><ci id="S3.E6.m1.2.2.1.3.cmml" xref="S3.E6.m1.2.2.1.3">ℱ</ci><ci id="S3.E6.m1.2.2.1.1.cmml" xref="S3.E6.m1.2.2.1.1">𝑍</ci></apply><apply id="S3.E6.m1.4.4.3.cmml" xref="S3.E6.m1.4.4.3"><csymbol cd="ambiguous" id="S3.E6.m1.4.4.3.3.cmml" xref="S3.E6.m1.4.4.3">superscript</csymbol><apply id="S3.E6.m1.4.4.3.2.2.cmml" xref="S3.E6.m1.4.4.3.2.1"><csymbol cd="latexml" id="S3.E6.m1.4.4.3.2.2.1.cmml" xref="S3.E6.m1.4.4.3.2.1.2">norm</csymbol><apply id="S3.E6.m1.4.4.3.2.1.1.cmml" xref="S3.E6.m1.4.4.3.2.1.1"><times id="S3.E6.m1.4.4.3.2.1.1.1.cmml" xref="S3.E6.m1.4.4.3.2.1.1.1"></times><ci id="S3.E6.m1.4.4.3.2.1.1.2.cmml" xref="S3.E6.m1.4.4.3.2.1.1.2">ℱ</ci><ci id="S3.E6.m1.3.3.2.1.cmml" xref="S3.E6.m1.3.3.2.1">𝑍</ci></apply></apply><cn id="S3.E6.m1.4.4.3.4.cmml" type="integer" xref="S3.E6.m1.4.4.3.4">2</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.6c">\text{sim}(X_{m},Z)=\text{exp}\left(\frac{X_{m}}{\left\|X_{m}\right\|^{2}}\odot\frac{\mathcal{F}(Z)}{\left\|\mathcal{F}(Z)\right\|^{2}}\right),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p3.9">where <math alttext="\mathcal{F}" class="ltx_Math" display="inline" id="S3.SS3.p3.5.m1.1"><semantics id="S3.SS3.p3.5.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.5.m1.1.1" xref="S3.SS3.p3.5.m1.1.1.cmml">ℱ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.5.m1.1b"><ci id="S3.SS3.p3.5.m1.1.1.cmml" xref="S3.SS3.p3.5.m1.1.1">ℱ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.5.m1.1c">\mathcal{F}</annotation></semantics></math> generates a prediction of <math alttext="X_{m}" class="ltx_Math" display="inline" id="S3.SS3.p3.6.m2.1"><semantics id="S3.SS3.p3.6.m2.1a"><msub id="S3.SS3.p3.6.m2.1.1" xref="S3.SS3.p3.6.m2.1.1.cmml"><mi id="S3.SS3.p3.6.m2.1.1.2" xref="S3.SS3.p3.6.m2.1.1.2.cmml">X</mi><mi id="S3.SS3.p3.6.m2.1.1.3" xref="S3.SS3.p3.6.m2.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.6.m2.1b"><apply id="S3.SS3.p3.6.m2.1.1.cmml" xref="S3.SS3.p3.6.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.6.m2.1.1.1.cmml" xref="S3.SS3.p3.6.m2.1.1">subscript</csymbol><ci id="S3.SS3.p3.6.m2.1.1.2.cmml" xref="S3.SS3.p3.6.m2.1.1.2">𝑋</ci><ci id="S3.SS3.p3.6.m2.1.1.3.cmml" xref="S3.SS3.p3.6.m2.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.6.m2.1c">X_{m}</annotation></semantics></math> from <math alttext="Z" class="ltx_Math" display="inline" id="S3.SS3.p3.7.m3.1"><semantics id="S3.SS3.p3.7.m3.1a"><mi id="S3.SS3.p3.7.m3.1.1" xref="S3.SS3.p3.7.m3.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.7.m3.1b"><ci id="S3.SS3.p3.7.m3.1.1.cmml" xref="S3.SS3.p3.7.m3.1.1">𝑍</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.7.m3.1c">Z</annotation></semantics></math>, <math alttext="\|\cdot\|^{2}" class="ltx_math_unparsed" display="inline" id="S3.SS3.p3.8.m4.1"><semantics id="S3.SS3.p3.8.m4.1a"><mrow id="S3.SS3.p3.8.m4.1b"><mo id="S3.SS3.p3.8.m4.1.1" rspace="0em">∥</mo><mo id="S3.SS3.p3.8.m4.1.2" lspace="0em" rspace="0em">⋅</mo><msup id="S3.SS3.p3.8.m4.1.3"><mo id="S3.SS3.p3.8.m4.1.3.2" lspace="0em">∥</mo><mn id="S3.SS3.p3.8.m4.1.3.3">2</mn></msup></mrow><annotation encoding="application/x-tex" id="S3.SS3.p3.8.m4.1c">\|\cdot\|^{2}</annotation></semantics></math> is the Euclidean norm, and <math alttext="\odot" class="ltx_Math" display="inline" id="S3.SS3.p3.9.m5.1"><semantics id="S3.SS3.p3.9.m5.1a"><mo id="S3.SS3.p3.9.m5.1.1" xref="S3.SS3.p3.9.m5.1.1.cmml">⊙</mo><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.9.m5.1b"><csymbol cd="latexml" id="S3.SS3.p3.9.m5.1.1.cmml" xref="S3.SS3.p3.9.m5.1.1">direct-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.9.m5.1c">\odot</annotation></semantics></math> denotes element-wise product.
Then, we incorporate this similarity function into the noise-contrastive estimation framework <cite class="ltx_cite ltx_citemacro_citep">(Gutmann and Hyvärinen, <a class="ltx_ref" href="#bib.bib5" title="">2010</a>)</cite> and produce an InfoNCE loss <cite class="ltx_cite ltx_citemacro_citep">(Oord et al., <a class="ltx_ref" href="#bib.bib18" title="">2018</a>)</cite> which reflects the lower bound of the mutual information:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E7">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{\text{NCE}}^{z,m}=-\mathbb{E}_{X_{m},Z}\left[\log\frac{e^{\operatorname{sim}\left(x_{m}^{{+}},\mathcal{F}(Z)\right)}}{\sum_{k=1}^{K}e^{\operatorname{sim}\left(\tilde{x}_{m}^{k},\mathcal{F}(Z)\right)}}\right]" class="ltx_Math" display="block" id="S3.E7.m1.13"><semantics id="S3.E7.m1.13a"><mrow id="S3.E7.m1.13.13" xref="S3.E7.m1.13.13.cmml"><msubsup id="S3.E7.m1.13.13.3" xref="S3.E7.m1.13.13.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E7.m1.13.13.3.2.2" xref="S3.E7.m1.13.13.3.2.2.cmml">ℒ</mi><mtext id="S3.E7.m1.13.13.3.2.3" xref="S3.E7.m1.13.13.3.2.3a.cmml">NCE</mtext><mrow id="S3.E7.m1.2.2.2.4" xref="S3.E7.m1.2.2.2.3.cmml"><mi id="S3.E7.m1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.cmml">z</mi><mo id="S3.E7.m1.2.2.2.4.1" xref="S3.E7.m1.2.2.2.3.cmml">,</mo><mi id="S3.E7.m1.2.2.2.2" xref="S3.E7.m1.2.2.2.2.cmml">m</mi></mrow></msubsup><mo id="S3.E7.m1.13.13.2" xref="S3.E7.m1.13.13.2.cmml">=</mo><mrow id="S3.E7.m1.13.13.1" xref="S3.E7.m1.13.13.1.cmml"><mo id="S3.E7.m1.13.13.1a" xref="S3.E7.m1.13.13.1.cmml">−</mo><mrow id="S3.E7.m1.13.13.1.1" xref="S3.E7.m1.13.13.1.1.cmml"><msub id="S3.E7.m1.13.13.1.1.3" xref="S3.E7.m1.13.13.1.1.3.cmml"><mi id="S3.E7.m1.13.13.1.1.3.2" xref="S3.E7.m1.13.13.1.1.3.2.cmml">𝔼</mi><mrow id="S3.E7.m1.4.4.2.2" xref="S3.E7.m1.4.4.2.3.cmml"><msub id="S3.E7.m1.4.4.2.2.1" xref="S3.E7.m1.4.4.2.2.1.cmml"><mi id="S3.E7.m1.4.4.2.2.1.2" xref="S3.E7.m1.4.4.2.2.1.2.cmml">X</mi><mi id="S3.E7.m1.4.4.2.2.1.3" xref="S3.E7.m1.4.4.2.2.1.3.cmml">m</mi></msub><mo id="S3.E7.m1.4.4.2.2.2" xref="S3.E7.m1.4.4.2.3.cmml">,</mo><mi id="S3.E7.m1.3.3.1.1" xref="S3.E7.m1.3.3.1.1.cmml">Z</mi></mrow></msub><mo id="S3.E7.m1.13.13.1.1.2" lspace="0em" rspace="0em" xref="S3.E7.m1.13.13.1.1.2.cmml">​</mo><mrow id="S3.E7.m1.13.13.1.1.1.1" xref="S3.E7.m1.13.13.1.1.1.2.cmml"><mo id="S3.E7.m1.13.13.1.1.1.1.2" xref="S3.E7.m1.13.13.1.1.1.2.1.cmml">[</mo><mrow id="S3.E7.m1.13.13.1.1.1.1.1" xref="S3.E7.m1.13.13.1.1.1.1.1.cmml"><mi id="S3.E7.m1.13.13.1.1.1.1.1.1" xref="S3.E7.m1.13.13.1.1.1.1.1.1.cmml">log</mi><mo id="S3.E7.m1.13.13.1.1.1.1.1a" lspace="0.167em" xref="S3.E7.m1.13.13.1.1.1.1.1.cmml">⁡</mo><mfrac id="S3.E7.m1.12.12" xref="S3.E7.m1.12.12.cmml"><msup id="S3.E7.m1.8.8.4" xref="S3.E7.m1.8.8.4.cmml"><mi id="S3.E7.m1.8.8.4.6" xref="S3.E7.m1.8.8.4.6.cmml">e</mi><mrow id="S3.E7.m1.8.8.4.4.4.4" xref="S3.E7.m1.8.8.4.4.4.5.cmml"><mi id="S3.E7.m1.6.6.2.2.2.2" xref="S3.E7.m1.6.6.2.2.2.2.cmml">sim</mi><mo id="S3.E7.m1.8.8.4.4.4.4a" xref="S3.E7.m1.8.8.4.4.4.5.cmml">⁡</mo><mrow id="S3.E7.m1.8.8.4.4.4.4.2" xref="S3.E7.m1.8.8.4.4.4.5.cmml"><mo id="S3.E7.m1.8.8.4.4.4.4.2.3" xref="S3.E7.m1.8.8.4.4.4.5.cmml">(</mo><msubsup id="S3.E7.m1.7.7.3.3.3.3.1.1" xref="S3.E7.m1.7.7.3.3.3.3.1.1.cmml"><mi id="S3.E7.m1.7.7.3.3.3.3.1.1.2.2" xref="S3.E7.m1.7.7.3.3.3.3.1.1.2.2.cmml">x</mi><mi id="S3.E7.m1.7.7.3.3.3.3.1.1.2.3" xref="S3.E7.m1.7.7.3.3.3.3.1.1.2.3.cmml">m</mi><mo id="S3.E7.m1.7.7.3.3.3.3.1.1.3" xref="S3.E7.m1.7.7.3.3.3.3.1.1.3.cmml">+</mo></msubsup><mo id="S3.E7.m1.8.8.4.4.4.4.2.4" xref="S3.E7.m1.8.8.4.4.4.5.cmml">,</mo><mrow id="S3.E7.m1.8.8.4.4.4.4.2.2" xref="S3.E7.m1.8.8.4.4.4.4.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E7.m1.8.8.4.4.4.4.2.2.2" xref="S3.E7.m1.8.8.4.4.4.4.2.2.2.cmml">ℱ</mi><mo id="S3.E7.m1.8.8.4.4.4.4.2.2.1" lspace="0em" rspace="0em" xref="S3.E7.m1.8.8.4.4.4.4.2.2.1.cmml">​</mo><mrow id="S3.E7.m1.8.8.4.4.4.4.2.2.3.2" xref="S3.E7.m1.8.8.4.4.4.4.2.2.cmml"><mo id="S3.E7.m1.8.8.4.4.4.4.2.2.3.2.1" stretchy="false" xref="S3.E7.m1.8.8.4.4.4.4.2.2.cmml">(</mo><mi id="S3.E7.m1.5.5.1.1.1.1" xref="S3.E7.m1.5.5.1.1.1.1.cmml">Z</mi><mo id="S3.E7.m1.8.8.4.4.4.4.2.2.3.2.2" stretchy="false" xref="S3.E7.m1.8.8.4.4.4.4.2.2.cmml">)</mo></mrow></mrow><mo id="S3.E7.m1.8.8.4.4.4.4.2.5" xref="S3.E7.m1.8.8.4.4.4.5.cmml">)</mo></mrow></mrow></msup><mrow id="S3.E7.m1.12.12.8" xref="S3.E7.m1.12.12.8.cmml"><msubsup id="S3.E7.m1.12.12.8.5" xref="S3.E7.m1.12.12.8.5.cmml"><mo id="S3.E7.m1.12.12.8.5.2.2" xref="S3.E7.m1.12.12.8.5.2.2.cmml">∑</mo><mrow id="S3.E7.m1.12.12.8.5.2.3" xref="S3.E7.m1.12.12.8.5.2.3.cmml"><mi id="S3.E7.m1.12.12.8.5.2.3.2" xref="S3.E7.m1.12.12.8.5.2.3.2.cmml">k</mi><mo id="S3.E7.m1.12.12.8.5.2.3.1" xref="S3.E7.m1.12.12.8.5.2.3.1.cmml">=</mo><mn id="S3.E7.m1.12.12.8.5.2.3.3" xref="S3.E7.m1.12.12.8.5.2.3.3.cmml">1</mn></mrow><mi id="S3.E7.m1.12.12.8.5.3" xref="S3.E7.m1.12.12.8.5.3.cmml">K</mi></msubsup><msup id="S3.E7.m1.12.12.8.6" xref="S3.E7.m1.12.12.8.6.cmml"><mi id="S3.E7.m1.12.12.8.6.2" xref="S3.E7.m1.12.12.8.6.2.cmml">e</mi><mrow id="S3.E7.m1.12.12.8.4.4.4" xref="S3.E7.m1.12.12.8.4.4.5.cmml"><mi id="S3.E7.m1.10.10.6.2.2.2" xref="S3.E7.m1.10.10.6.2.2.2.cmml">sim</mi><mo id="S3.E7.m1.12.12.8.4.4.4a" xref="S3.E7.m1.12.12.8.4.4.5.cmml">⁡</mo><mrow id="S3.E7.m1.12.12.8.4.4.4.2" xref="S3.E7.m1.12.12.8.4.4.5.cmml"><mo id="S3.E7.m1.12.12.8.4.4.4.2.3" xref="S3.E7.m1.12.12.8.4.4.5.cmml">(</mo><msubsup id="S3.E7.m1.11.11.7.3.3.3.1.1" xref="S3.E7.m1.11.11.7.3.3.3.1.1.cmml"><mover accent="true" id="S3.E7.m1.11.11.7.3.3.3.1.1.2.2" xref="S3.E7.m1.11.11.7.3.3.3.1.1.2.2.cmml"><mi id="S3.E7.m1.11.11.7.3.3.3.1.1.2.2.2" xref="S3.E7.m1.11.11.7.3.3.3.1.1.2.2.2.cmml">x</mi><mo id="S3.E7.m1.11.11.7.3.3.3.1.1.2.2.1" xref="S3.E7.m1.11.11.7.3.3.3.1.1.2.2.1.cmml">~</mo></mover><mi id="S3.E7.m1.11.11.7.3.3.3.1.1.2.3" xref="S3.E7.m1.11.11.7.3.3.3.1.1.2.3.cmml">m</mi><mi id="S3.E7.m1.11.11.7.3.3.3.1.1.3" xref="S3.E7.m1.11.11.7.3.3.3.1.1.3.cmml">k</mi></msubsup><mo id="S3.E7.m1.12.12.8.4.4.4.2.4" xref="S3.E7.m1.12.12.8.4.4.5.cmml">,</mo><mrow id="S3.E7.m1.12.12.8.4.4.4.2.2" xref="S3.E7.m1.12.12.8.4.4.4.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E7.m1.12.12.8.4.4.4.2.2.2" xref="S3.E7.m1.12.12.8.4.4.4.2.2.2.cmml">ℱ</mi><mo id="S3.E7.m1.12.12.8.4.4.4.2.2.1" lspace="0em" rspace="0em" xref="S3.E7.m1.12.12.8.4.4.4.2.2.1.cmml">​</mo><mrow id="S3.E7.m1.12.12.8.4.4.4.2.2.3.2" xref="S3.E7.m1.12.12.8.4.4.4.2.2.cmml"><mo id="S3.E7.m1.12.12.8.4.4.4.2.2.3.2.1" stretchy="false" xref="S3.E7.m1.12.12.8.4.4.4.2.2.cmml">(</mo><mi id="S3.E7.m1.9.9.5.1.1.1" xref="S3.E7.m1.9.9.5.1.1.1.cmml">Z</mi><mo id="S3.E7.m1.12.12.8.4.4.4.2.2.3.2.2" stretchy="false" xref="S3.E7.m1.12.12.8.4.4.4.2.2.cmml">)</mo></mrow></mrow><mo id="S3.E7.m1.12.12.8.4.4.4.2.5" xref="S3.E7.m1.12.12.8.4.4.5.cmml">)</mo></mrow></mrow></msup></mrow></mfrac></mrow><mo id="S3.E7.m1.13.13.1.1.1.1.3" xref="S3.E7.m1.13.13.1.1.1.2.1.cmml">]</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.13b"><apply id="S3.E7.m1.13.13.cmml" xref="S3.E7.m1.13.13"><eq id="S3.E7.m1.13.13.2.cmml" xref="S3.E7.m1.13.13.2"></eq><apply id="S3.E7.m1.13.13.3.cmml" xref="S3.E7.m1.13.13.3"><csymbol cd="ambiguous" id="S3.E7.m1.13.13.3.1.cmml" xref="S3.E7.m1.13.13.3">superscript</csymbol><apply id="S3.E7.m1.13.13.3.2.cmml" xref="S3.E7.m1.13.13.3"><csymbol cd="ambiguous" id="S3.E7.m1.13.13.3.2.1.cmml" xref="S3.E7.m1.13.13.3">subscript</csymbol><ci id="S3.E7.m1.13.13.3.2.2.cmml" xref="S3.E7.m1.13.13.3.2.2">ℒ</ci><ci id="S3.E7.m1.13.13.3.2.3a.cmml" xref="S3.E7.m1.13.13.3.2.3"><mtext id="S3.E7.m1.13.13.3.2.3.cmml" mathsize="70%" xref="S3.E7.m1.13.13.3.2.3">NCE</mtext></ci></apply><list id="S3.E7.m1.2.2.2.3.cmml" xref="S3.E7.m1.2.2.2.4"><ci id="S3.E7.m1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1">𝑧</ci><ci id="S3.E7.m1.2.2.2.2.cmml" xref="S3.E7.m1.2.2.2.2">𝑚</ci></list></apply><apply id="S3.E7.m1.13.13.1.cmml" xref="S3.E7.m1.13.13.1"><minus id="S3.E7.m1.13.13.1.2.cmml" xref="S3.E7.m1.13.13.1"></minus><apply id="S3.E7.m1.13.13.1.1.cmml" xref="S3.E7.m1.13.13.1.1"><times id="S3.E7.m1.13.13.1.1.2.cmml" xref="S3.E7.m1.13.13.1.1.2"></times><apply id="S3.E7.m1.13.13.1.1.3.cmml" xref="S3.E7.m1.13.13.1.1.3"><csymbol cd="ambiguous" id="S3.E7.m1.13.13.1.1.3.1.cmml" xref="S3.E7.m1.13.13.1.1.3">subscript</csymbol><ci id="S3.E7.m1.13.13.1.1.3.2.cmml" xref="S3.E7.m1.13.13.1.1.3.2">𝔼</ci><list id="S3.E7.m1.4.4.2.3.cmml" xref="S3.E7.m1.4.4.2.2"><apply id="S3.E7.m1.4.4.2.2.1.cmml" xref="S3.E7.m1.4.4.2.2.1"><csymbol cd="ambiguous" id="S3.E7.m1.4.4.2.2.1.1.cmml" xref="S3.E7.m1.4.4.2.2.1">subscript</csymbol><ci id="S3.E7.m1.4.4.2.2.1.2.cmml" xref="S3.E7.m1.4.4.2.2.1.2">𝑋</ci><ci id="S3.E7.m1.4.4.2.2.1.3.cmml" xref="S3.E7.m1.4.4.2.2.1.3">𝑚</ci></apply><ci id="S3.E7.m1.3.3.1.1.cmml" xref="S3.E7.m1.3.3.1.1">𝑍</ci></list></apply><apply id="S3.E7.m1.13.13.1.1.1.2.cmml" xref="S3.E7.m1.13.13.1.1.1.1"><csymbol cd="latexml" id="S3.E7.m1.13.13.1.1.1.2.1.cmml" xref="S3.E7.m1.13.13.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.E7.m1.13.13.1.1.1.1.1.cmml" xref="S3.E7.m1.13.13.1.1.1.1.1"><log id="S3.E7.m1.13.13.1.1.1.1.1.1.cmml" xref="S3.E7.m1.13.13.1.1.1.1.1.1"></log><apply id="S3.E7.m1.12.12.cmml" xref="S3.E7.m1.12.12"><divide id="S3.E7.m1.12.12.9.cmml" xref="S3.E7.m1.12.12"></divide><apply id="S3.E7.m1.8.8.4.cmml" xref="S3.E7.m1.8.8.4"><csymbol cd="ambiguous" id="S3.E7.m1.8.8.4.5.cmml" xref="S3.E7.m1.8.8.4">superscript</csymbol><ci id="S3.E7.m1.8.8.4.6.cmml" xref="S3.E7.m1.8.8.4.6">𝑒</ci><apply id="S3.E7.m1.8.8.4.4.4.5.cmml" xref="S3.E7.m1.8.8.4.4.4.4"><ci id="S3.E7.m1.6.6.2.2.2.2.cmml" xref="S3.E7.m1.6.6.2.2.2.2">sim</ci><apply id="S3.E7.m1.7.7.3.3.3.3.1.1.cmml" xref="S3.E7.m1.7.7.3.3.3.3.1.1"><csymbol cd="ambiguous" id="S3.E7.m1.7.7.3.3.3.3.1.1.1.cmml" xref="S3.E7.m1.7.7.3.3.3.3.1.1">superscript</csymbol><apply id="S3.E7.m1.7.7.3.3.3.3.1.1.2.cmml" xref="S3.E7.m1.7.7.3.3.3.3.1.1"><csymbol cd="ambiguous" id="S3.E7.m1.7.7.3.3.3.3.1.1.2.1.cmml" xref="S3.E7.m1.7.7.3.3.3.3.1.1">subscript</csymbol><ci id="S3.E7.m1.7.7.3.3.3.3.1.1.2.2.cmml" xref="S3.E7.m1.7.7.3.3.3.3.1.1.2.2">𝑥</ci><ci id="S3.E7.m1.7.7.3.3.3.3.1.1.2.3.cmml" xref="S3.E7.m1.7.7.3.3.3.3.1.1.2.3">𝑚</ci></apply><plus id="S3.E7.m1.7.7.3.3.3.3.1.1.3.cmml" xref="S3.E7.m1.7.7.3.3.3.3.1.1.3"></plus></apply><apply id="S3.E7.m1.8.8.4.4.4.4.2.2.cmml" xref="S3.E7.m1.8.8.4.4.4.4.2.2"><times id="S3.E7.m1.8.8.4.4.4.4.2.2.1.cmml" xref="S3.E7.m1.8.8.4.4.4.4.2.2.1"></times><ci id="S3.E7.m1.8.8.4.4.4.4.2.2.2.cmml" xref="S3.E7.m1.8.8.4.4.4.4.2.2.2">ℱ</ci><ci id="S3.E7.m1.5.5.1.1.1.1.cmml" xref="S3.E7.m1.5.5.1.1.1.1">𝑍</ci></apply></apply></apply><apply id="S3.E7.m1.12.12.8.cmml" xref="S3.E7.m1.12.12.8"><apply id="S3.E7.m1.12.12.8.5.cmml" xref="S3.E7.m1.12.12.8.5"><csymbol cd="ambiguous" id="S3.E7.m1.12.12.8.5.1.cmml" xref="S3.E7.m1.12.12.8.5">superscript</csymbol><apply id="S3.E7.m1.12.12.8.5.2.cmml" xref="S3.E7.m1.12.12.8.5"><csymbol cd="ambiguous" id="S3.E7.m1.12.12.8.5.2.1.cmml" xref="S3.E7.m1.12.12.8.5">subscript</csymbol><sum id="S3.E7.m1.12.12.8.5.2.2.cmml" xref="S3.E7.m1.12.12.8.5.2.2"></sum><apply id="S3.E7.m1.12.12.8.5.2.3.cmml" xref="S3.E7.m1.12.12.8.5.2.3"><eq id="S3.E7.m1.12.12.8.5.2.3.1.cmml" xref="S3.E7.m1.12.12.8.5.2.3.1"></eq><ci id="S3.E7.m1.12.12.8.5.2.3.2.cmml" xref="S3.E7.m1.12.12.8.5.2.3.2">𝑘</ci><cn id="S3.E7.m1.12.12.8.5.2.3.3.cmml" type="integer" xref="S3.E7.m1.12.12.8.5.2.3.3">1</cn></apply></apply><ci id="S3.E7.m1.12.12.8.5.3.cmml" xref="S3.E7.m1.12.12.8.5.3">𝐾</ci></apply><apply id="S3.E7.m1.12.12.8.6.cmml" xref="S3.E7.m1.12.12.8.6"><csymbol cd="ambiguous" id="S3.E7.m1.12.12.8.6.1.cmml" xref="S3.E7.m1.12.12.8.6">superscript</csymbol><ci id="S3.E7.m1.12.12.8.6.2.cmml" xref="S3.E7.m1.12.12.8.6.2">𝑒</ci><apply id="S3.E7.m1.12.12.8.4.4.5.cmml" xref="S3.E7.m1.12.12.8.4.4.4"><ci id="S3.E7.m1.10.10.6.2.2.2.cmml" xref="S3.E7.m1.10.10.6.2.2.2">sim</ci><apply id="S3.E7.m1.11.11.7.3.3.3.1.1.cmml" xref="S3.E7.m1.11.11.7.3.3.3.1.1"><csymbol cd="ambiguous" id="S3.E7.m1.11.11.7.3.3.3.1.1.1.cmml" xref="S3.E7.m1.11.11.7.3.3.3.1.1">superscript</csymbol><apply id="S3.E7.m1.11.11.7.3.3.3.1.1.2.cmml" xref="S3.E7.m1.11.11.7.3.3.3.1.1"><csymbol cd="ambiguous" id="S3.E7.m1.11.11.7.3.3.3.1.1.2.1.cmml" xref="S3.E7.m1.11.11.7.3.3.3.1.1">subscript</csymbol><apply id="S3.E7.m1.11.11.7.3.3.3.1.1.2.2.cmml" xref="S3.E7.m1.11.11.7.3.3.3.1.1.2.2"><ci id="S3.E7.m1.11.11.7.3.3.3.1.1.2.2.1.cmml" xref="S3.E7.m1.11.11.7.3.3.3.1.1.2.2.1">~</ci><ci id="S3.E7.m1.11.11.7.3.3.3.1.1.2.2.2.cmml" xref="S3.E7.m1.11.11.7.3.3.3.1.1.2.2.2">𝑥</ci></apply><ci id="S3.E7.m1.11.11.7.3.3.3.1.1.2.3.cmml" xref="S3.E7.m1.11.11.7.3.3.3.1.1.2.3">𝑚</ci></apply><ci id="S3.E7.m1.11.11.7.3.3.3.1.1.3.cmml" xref="S3.E7.m1.11.11.7.3.3.3.1.1.3">𝑘</ci></apply><apply id="S3.E7.m1.12.12.8.4.4.4.2.2.cmml" xref="S3.E7.m1.12.12.8.4.4.4.2.2"><times id="S3.E7.m1.12.12.8.4.4.4.2.2.1.cmml" xref="S3.E7.m1.12.12.8.4.4.4.2.2.1"></times><ci id="S3.E7.m1.12.12.8.4.4.4.2.2.2.cmml" xref="S3.E7.m1.12.12.8.4.4.4.2.2.2">ℱ</ci><ci id="S3.E7.m1.9.9.5.1.1.1.cmml" xref="S3.E7.m1.9.9.5.1.1.1">𝑍</ci></apply></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.13c">\mathcal{L}_{\text{NCE}}^{z,m}=-\mathbb{E}_{X_{m},Z}\left[\log\frac{e^{\operatorname{sim}\left(x_{m}^{{+}},\mathcal{F}(Z)\right)}}{\sum_{k=1}^{K}e^{\operatorname{sim}\left(\tilde{x}_{m}^{k},\mathcal{F}(Z)\right)}}\right]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p3.11">where <math alttext="\tilde{x}_{m}=\left\{\tilde{x}^{1},\ldots,\tilde{x}^{K}\right\}" class="ltx_Math" display="inline" id="S3.SS3.p3.10.m1.3"><semantics id="S3.SS3.p3.10.m1.3a"><mrow id="S3.SS3.p3.10.m1.3.3" xref="S3.SS3.p3.10.m1.3.3.cmml"><msub id="S3.SS3.p3.10.m1.3.3.4" xref="S3.SS3.p3.10.m1.3.3.4.cmml"><mover accent="true" id="S3.SS3.p3.10.m1.3.3.4.2" xref="S3.SS3.p3.10.m1.3.3.4.2.cmml"><mi id="S3.SS3.p3.10.m1.3.3.4.2.2" xref="S3.SS3.p3.10.m1.3.3.4.2.2.cmml">x</mi><mo id="S3.SS3.p3.10.m1.3.3.4.2.1" xref="S3.SS3.p3.10.m1.3.3.4.2.1.cmml">~</mo></mover><mi id="S3.SS3.p3.10.m1.3.3.4.3" xref="S3.SS3.p3.10.m1.3.3.4.3.cmml">m</mi></msub><mo id="S3.SS3.p3.10.m1.3.3.3" xref="S3.SS3.p3.10.m1.3.3.3.cmml">=</mo><mrow id="S3.SS3.p3.10.m1.3.3.2.2" xref="S3.SS3.p3.10.m1.3.3.2.3.cmml"><mo id="S3.SS3.p3.10.m1.3.3.2.2.3" xref="S3.SS3.p3.10.m1.3.3.2.3.cmml">{</mo><msup id="S3.SS3.p3.10.m1.2.2.1.1.1" xref="S3.SS3.p3.10.m1.2.2.1.1.1.cmml"><mover accent="true" id="S3.SS3.p3.10.m1.2.2.1.1.1.2" xref="S3.SS3.p3.10.m1.2.2.1.1.1.2.cmml"><mi id="S3.SS3.p3.10.m1.2.2.1.1.1.2.2" xref="S3.SS3.p3.10.m1.2.2.1.1.1.2.2.cmml">x</mi><mo id="S3.SS3.p3.10.m1.2.2.1.1.1.2.1" xref="S3.SS3.p3.10.m1.2.2.1.1.1.2.1.cmml">~</mo></mover><mn id="S3.SS3.p3.10.m1.2.2.1.1.1.3" xref="S3.SS3.p3.10.m1.2.2.1.1.1.3.cmml">1</mn></msup><mo id="S3.SS3.p3.10.m1.3.3.2.2.4" xref="S3.SS3.p3.10.m1.3.3.2.3.cmml">,</mo><mi id="S3.SS3.p3.10.m1.1.1" mathvariant="normal" xref="S3.SS3.p3.10.m1.1.1.cmml">…</mi><mo id="S3.SS3.p3.10.m1.3.3.2.2.5" xref="S3.SS3.p3.10.m1.3.3.2.3.cmml">,</mo><msup id="S3.SS3.p3.10.m1.3.3.2.2.2" xref="S3.SS3.p3.10.m1.3.3.2.2.2.cmml"><mover accent="true" id="S3.SS3.p3.10.m1.3.3.2.2.2.2" xref="S3.SS3.p3.10.m1.3.3.2.2.2.2.cmml"><mi id="S3.SS3.p3.10.m1.3.3.2.2.2.2.2" xref="S3.SS3.p3.10.m1.3.3.2.2.2.2.2.cmml">x</mi><mo id="S3.SS3.p3.10.m1.3.3.2.2.2.2.1" xref="S3.SS3.p3.10.m1.3.3.2.2.2.2.1.cmml">~</mo></mover><mi id="S3.SS3.p3.10.m1.3.3.2.2.2.3" xref="S3.SS3.p3.10.m1.3.3.2.2.2.3.cmml">K</mi></msup><mo id="S3.SS3.p3.10.m1.3.3.2.2.6" xref="S3.SS3.p3.10.m1.3.3.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.10.m1.3b"><apply id="S3.SS3.p3.10.m1.3.3.cmml" xref="S3.SS3.p3.10.m1.3.3"><eq id="S3.SS3.p3.10.m1.3.3.3.cmml" xref="S3.SS3.p3.10.m1.3.3.3"></eq><apply id="S3.SS3.p3.10.m1.3.3.4.cmml" xref="S3.SS3.p3.10.m1.3.3.4"><csymbol cd="ambiguous" id="S3.SS3.p3.10.m1.3.3.4.1.cmml" xref="S3.SS3.p3.10.m1.3.3.4">subscript</csymbol><apply id="S3.SS3.p3.10.m1.3.3.4.2.cmml" xref="S3.SS3.p3.10.m1.3.3.4.2"><ci id="S3.SS3.p3.10.m1.3.3.4.2.1.cmml" xref="S3.SS3.p3.10.m1.3.3.4.2.1">~</ci><ci id="S3.SS3.p3.10.m1.3.3.4.2.2.cmml" xref="S3.SS3.p3.10.m1.3.3.4.2.2">𝑥</ci></apply><ci id="S3.SS3.p3.10.m1.3.3.4.3.cmml" xref="S3.SS3.p3.10.m1.3.3.4.3">𝑚</ci></apply><set id="S3.SS3.p3.10.m1.3.3.2.3.cmml" xref="S3.SS3.p3.10.m1.3.3.2.2"><apply id="S3.SS3.p3.10.m1.2.2.1.1.1.cmml" xref="S3.SS3.p3.10.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.10.m1.2.2.1.1.1.1.cmml" xref="S3.SS3.p3.10.m1.2.2.1.1.1">superscript</csymbol><apply id="S3.SS3.p3.10.m1.2.2.1.1.1.2.cmml" xref="S3.SS3.p3.10.m1.2.2.1.1.1.2"><ci id="S3.SS3.p3.10.m1.2.2.1.1.1.2.1.cmml" xref="S3.SS3.p3.10.m1.2.2.1.1.1.2.1">~</ci><ci id="S3.SS3.p3.10.m1.2.2.1.1.1.2.2.cmml" xref="S3.SS3.p3.10.m1.2.2.1.1.1.2.2">𝑥</ci></apply><cn id="S3.SS3.p3.10.m1.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS3.p3.10.m1.2.2.1.1.1.3">1</cn></apply><ci id="S3.SS3.p3.10.m1.1.1.cmml" xref="S3.SS3.p3.10.m1.1.1">…</ci><apply id="S3.SS3.p3.10.m1.3.3.2.2.2.cmml" xref="S3.SS3.p3.10.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS3.p3.10.m1.3.3.2.2.2.1.cmml" xref="S3.SS3.p3.10.m1.3.3.2.2.2">superscript</csymbol><apply id="S3.SS3.p3.10.m1.3.3.2.2.2.2.cmml" xref="S3.SS3.p3.10.m1.3.3.2.2.2.2"><ci id="S3.SS3.p3.10.m1.3.3.2.2.2.2.1.cmml" xref="S3.SS3.p3.10.m1.3.3.2.2.2.2.1">~</ci><ci id="S3.SS3.p3.10.m1.3.3.2.2.2.2.2.cmml" xref="S3.SS3.p3.10.m1.3.3.2.2.2.2.2">𝑥</ci></apply><ci id="S3.SS3.p3.10.m1.3.3.2.2.2.3.cmml" xref="S3.SS3.p3.10.m1.3.3.2.2.2.3">𝐾</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.10.m1.3c">\tilde{x}_{m}=\left\{\tilde{x}^{1},\ldots,\tilde{x}^{K}\right\}</annotation></semantics></math> is the negative unimodal inputs that are not matched to the fusion result <math alttext="Z" class="ltx_Math" display="inline" id="S3.SS3.p3.11.m2.1"><semantics id="S3.SS3.p3.11.m2.1a"><mi id="S3.SS3.p3.11.m2.1.1" xref="S3.SS3.p3.11.m2.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.11.m2.1b"><ci id="S3.SS3.p3.11.m2.1.1.cmml" xref="S3.SS3.p3.11.m2.1.1">𝑍</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.11.m2.1c">Z</annotation></semantics></math> in same batch.
Finally, we compute loss for all modalities as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E8">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{\text{NCE}}=\alpha(\mathcal{L}_{\text{NCE}}^{z,v}+\mathcal{L}_{\text{NCE}}^{z,a}+\mathcal{L}_{\text{NCE}}^{z,t})" class="ltx_Math" display="block" id="S3.E8.m1.7"><semantics id="S3.E8.m1.7a"><mrow id="S3.E8.m1.7.7" xref="S3.E8.m1.7.7.cmml"><msub id="S3.E8.m1.7.7.3" xref="S3.E8.m1.7.7.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E8.m1.7.7.3.2" xref="S3.E8.m1.7.7.3.2.cmml">ℒ</mi><mtext id="S3.E8.m1.7.7.3.3" xref="S3.E8.m1.7.7.3.3a.cmml">NCE</mtext></msub><mo id="S3.E8.m1.7.7.2" xref="S3.E8.m1.7.7.2.cmml">=</mo><mrow id="S3.E8.m1.7.7.1" xref="S3.E8.m1.7.7.1.cmml"><mi id="S3.E8.m1.7.7.1.3" xref="S3.E8.m1.7.7.1.3.cmml">α</mi><mo id="S3.E8.m1.7.7.1.2" lspace="0em" rspace="0em" xref="S3.E8.m1.7.7.1.2.cmml">​</mo><mrow id="S3.E8.m1.7.7.1.1.1" xref="S3.E8.m1.7.7.1.1.1.1.cmml"><mo id="S3.E8.m1.7.7.1.1.1.2" stretchy="false" xref="S3.E8.m1.7.7.1.1.1.1.cmml">(</mo><mrow id="S3.E8.m1.7.7.1.1.1.1" xref="S3.E8.m1.7.7.1.1.1.1.cmml"><msubsup id="S3.E8.m1.7.7.1.1.1.1.2" xref="S3.E8.m1.7.7.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E8.m1.7.7.1.1.1.1.2.2.2" xref="S3.E8.m1.7.7.1.1.1.1.2.2.2.cmml">ℒ</mi><mtext id="S3.E8.m1.7.7.1.1.1.1.2.2.3" xref="S3.E8.m1.7.7.1.1.1.1.2.2.3a.cmml">NCE</mtext><mrow id="S3.E8.m1.2.2.2.4" xref="S3.E8.m1.2.2.2.3.cmml"><mi id="S3.E8.m1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.cmml">z</mi><mo id="S3.E8.m1.2.2.2.4.1" xref="S3.E8.m1.2.2.2.3.cmml">,</mo><mi id="S3.E8.m1.2.2.2.2" xref="S3.E8.m1.2.2.2.2.cmml">v</mi></mrow></msubsup><mo id="S3.E8.m1.7.7.1.1.1.1.1" xref="S3.E8.m1.7.7.1.1.1.1.1.cmml">+</mo><msubsup id="S3.E8.m1.7.7.1.1.1.1.3" xref="S3.E8.m1.7.7.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E8.m1.7.7.1.1.1.1.3.2.2" xref="S3.E8.m1.7.7.1.1.1.1.3.2.2.cmml">ℒ</mi><mtext id="S3.E8.m1.7.7.1.1.1.1.3.2.3" xref="S3.E8.m1.7.7.1.1.1.1.3.2.3a.cmml">NCE</mtext><mrow id="S3.E8.m1.4.4.2.4" xref="S3.E8.m1.4.4.2.3.cmml"><mi id="S3.E8.m1.3.3.1.1" xref="S3.E8.m1.3.3.1.1.cmml">z</mi><mo id="S3.E8.m1.4.4.2.4.1" xref="S3.E8.m1.4.4.2.3.cmml">,</mo><mi id="S3.E8.m1.4.4.2.2" xref="S3.E8.m1.4.4.2.2.cmml">a</mi></mrow></msubsup><mo id="S3.E8.m1.7.7.1.1.1.1.1a" xref="S3.E8.m1.7.7.1.1.1.1.1.cmml">+</mo><msubsup id="S3.E8.m1.7.7.1.1.1.1.4" xref="S3.E8.m1.7.7.1.1.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E8.m1.7.7.1.1.1.1.4.2.2" xref="S3.E8.m1.7.7.1.1.1.1.4.2.2.cmml">ℒ</mi><mtext id="S3.E8.m1.7.7.1.1.1.1.4.2.3" xref="S3.E8.m1.7.7.1.1.1.1.4.2.3a.cmml">NCE</mtext><mrow id="S3.E8.m1.6.6.2.4" xref="S3.E8.m1.6.6.2.3.cmml"><mi id="S3.E8.m1.5.5.1.1" xref="S3.E8.m1.5.5.1.1.cmml">z</mi><mo id="S3.E8.m1.6.6.2.4.1" xref="S3.E8.m1.6.6.2.3.cmml">,</mo><mi id="S3.E8.m1.6.6.2.2" xref="S3.E8.m1.6.6.2.2.cmml">t</mi></mrow></msubsup></mrow><mo id="S3.E8.m1.7.7.1.1.1.3" stretchy="false" xref="S3.E8.m1.7.7.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E8.m1.7b"><apply id="S3.E8.m1.7.7.cmml" xref="S3.E8.m1.7.7"><eq id="S3.E8.m1.7.7.2.cmml" xref="S3.E8.m1.7.7.2"></eq><apply id="S3.E8.m1.7.7.3.cmml" xref="S3.E8.m1.7.7.3"><csymbol cd="ambiguous" id="S3.E8.m1.7.7.3.1.cmml" xref="S3.E8.m1.7.7.3">subscript</csymbol><ci id="S3.E8.m1.7.7.3.2.cmml" xref="S3.E8.m1.7.7.3.2">ℒ</ci><ci id="S3.E8.m1.7.7.3.3a.cmml" xref="S3.E8.m1.7.7.3.3"><mtext id="S3.E8.m1.7.7.3.3.cmml" mathsize="70%" xref="S3.E8.m1.7.7.3.3">NCE</mtext></ci></apply><apply id="S3.E8.m1.7.7.1.cmml" xref="S3.E8.m1.7.7.1"><times id="S3.E8.m1.7.7.1.2.cmml" xref="S3.E8.m1.7.7.1.2"></times><ci id="S3.E8.m1.7.7.1.3.cmml" xref="S3.E8.m1.7.7.1.3">𝛼</ci><apply id="S3.E8.m1.7.7.1.1.1.1.cmml" xref="S3.E8.m1.7.7.1.1.1"><plus id="S3.E8.m1.7.7.1.1.1.1.1.cmml" xref="S3.E8.m1.7.7.1.1.1.1.1"></plus><apply id="S3.E8.m1.7.7.1.1.1.1.2.cmml" xref="S3.E8.m1.7.7.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E8.m1.7.7.1.1.1.1.2.1.cmml" xref="S3.E8.m1.7.7.1.1.1.1.2">superscript</csymbol><apply id="S3.E8.m1.7.7.1.1.1.1.2.2.cmml" xref="S3.E8.m1.7.7.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E8.m1.7.7.1.1.1.1.2.2.1.cmml" xref="S3.E8.m1.7.7.1.1.1.1.2">subscript</csymbol><ci id="S3.E8.m1.7.7.1.1.1.1.2.2.2.cmml" xref="S3.E8.m1.7.7.1.1.1.1.2.2.2">ℒ</ci><ci id="S3.E8.m1.7.7.1.1.1.1.2.2.3a.cmml" xref="S3.E8.m1.7.7.1.1.1.1.2.2.3"><mtext id="S3.E8.m1.7.7.1.1.1.1.2.2.3.cmml" mathsize="70%" xref="S3.E8.m1.7.7.1.1.1.1.2.2.3">NCE</mtext></ci></apply><list id="S3.E8.m1.2.2.2.3.cmml" xref="S3.E8.m1.2.2.2.4"><ci id="S3.E8.m1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1">𝑧</ci><ci id="S3.E8.m1.2.2.2.2.cmml" xref="S3.E8.m1.2.2.2.2">𝑣</ci></list></apply><apply id="S3.E8.m1.7.7.1.1.1.1.3.cmml" xref="S3.E8.m1.7.7.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E8.m1.7.7.1.1.1.1.3.1.cmml" xref="S3.E8.m1.7.7.1.1.1.1.3">superscript</csymbol><apply id="S3.E8.m1.7.7.1.1.1.1.3.2.cmml" xref="S3.E8.m1.7.7.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E8.m1.7.7.1.1.1.1.3.2.1.cmml" xref="S3.E8.m1.7.7.1.1.1.1.3">subscript</csymbol><ci id="S3.E8.m1.7.7.1.1.1.1.3.2.2.cmml" xref="S3.E8.m1.7.7.1.1.1.1.3.2.2">ℒ</ci><ci id="S3.E8.m1.7.7.1.1.1.1.3.2.3a.cmml" xref="S3.E8.m1.7.7.1.1.1.1.3.2.3"><mtext id="S3.E8.m1.7.7.1.1.1.1.3.2.3.cmml" mathsize="70%" xref="S3.E8.m1.7.7.1.1.1.1.3.2.3">NCE</mtext></ci></apply><list id="S3.E8.m1.4.4.2.3.cmml" xref="S3.E8.m1.4.4.2.4"><ci id="S3.E8.m1.3.3.1.1.cmml" xref="S3.E8.m1.3.3.1.1">𝑧</ci><ci id="S3.E8.m1.4.4.2.2.cmml" xref="S3.E8.m1.4.4.2.2">𝑎</ci></list></apply><apply id="S3.E8.m1.7.7.1.1.1.1.4.cmml" xref="S3.E8.m1.7.7.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E8.m1.7.7.1.1.1.1.4.1.cmml" xref="S3.E8.m1.7.7.1.1.1.1.4">superscript</csymbol><apply id="S3.E8.m1.7.7.1.1.1.1.4.2.cmml" xref="S3.E8.m1.7.7.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E8.m1.7.7.1.1.1.1.4.2.1.cmml" xref="S3.E8.m1.7.7.1.1.1.1.4">subscript</csymbol><ci id="S3.E8.m1.7.7.1.1.1.1.4.2.2.cmml" xref="S3.E8.m1.7.7.1.1.1.1.4.2.2">ℒ</ci><ci id="S3.E8.m1.7.7.1.1.1.1.4.2.3a.cmml" xref="S3.E8.m1.7.7.1.1.1.1.4.2.3"><mtext id="S3.E8.m1.7.7.1.1.1.1.4.2.3.cmml" mathsize="70%" xref="S3.E8.m1.7.7.1.1.1.1.4.2.3">NCE</mtext></ci></apply><list id="S3.E8.m1.6.6.2.3.cmml" xref="S3.E8.m1.6.6.2.4"><ci id="S3.E8.m1.5.5.1.1.cmml" xref="S3.E8.m1.5.5.1.1">𝑧</ci><ci id="S3.E8.m1.6.6.2.2.cmml" xref="S3.E8.m1.6.6.2.2">𝑡</ci></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E8.m1.7c">\mathcal{L}_{\text{NCE}}=\alpha(\mathcal{L}_{\text{NCE}}^{z,v}+\mathcal{L}_{\text{NCE}}^{z,a}+\mathcal{L}_{\text{NCE}}^{z,t})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p3.12">where <math alttext="\alpha" class="ltx_Math" display="inline" id="S3.SS3.p3.12.m1.1"><semantics id="S3.SS3.p3.12.m1.1a"><mi id="S3.SS3.p3.12.m1.1.1" xref="S3.SS3.p3.12.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.12.m1.1b"><ci id="S3.SS3.p3.12.m1.1.1.cmml" xref="S3.SS3.p3.12.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.12.m1.1c">\alpha</annotation></semantics></math> is a hyper-parameter that controls the impact of MI-Max.</p>
</div>
<div class="ltx_para" id="S3.SS3.p4">
<p class="ltx_p" id="S3.SS3.p4.1">By minimizing <math alttext="\mathcal{L}_{\text{NCE}}" class="ltx_Math" display="inline" id="S3.SS3.p4.1.m1.1"><semantics id="S3.SS3.p4.1.m1.1a"><msub id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p4.1.m1.1.1.2" xref="S3.SS3.p4.1.m1.1.1.2.cmml">ℒ</mi><mtext id="S3.SS3.p4.1.m1.1.1.3" xref="S3.SS3.p4.1.m1.1.1.3a.cmml">NCE</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b"><apply id="S3.SS3.p4.1.m1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p4.1.m1.1.1.2.cmml" xref="S3.SS3.p4.1.m1.1.1.2">ℒ</ci><ci id="S3.SS3.p4.1.m1.1.1.3a.cmml" xref="S3.SS3.p4.1.m1.1.1.3"><mtext id="S3.SS3.p4.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS3.p4.1.m1.1.1.3">NCE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">\mathcal{L}_{\text{NCE}}</annotation></semantics></math>, on the one hand, we maximize the lower bound of the mutual information between fusion results and unimodal inputs; on the other hand, we encourage fusion results to reversely predict unimodal inputs as well as possible, which prompts retaining of representative and key information from different modalities in fusion results.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.6">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.6.7.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S3.T1.6.7.1.1" rowspan="2" style="padding-left:7.0pt;padding-right:7.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.6.7.1.1.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="5" id="S3.T1.6.7.1.2" style="padding-left:7.0pt;padding-right:7.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.6.7.1.2.1">MOSI</span></th>
</tr>
<tr class="ltx_tr" id="S3.T1.5.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T1.1.1.1" style="padding-left:7.0pt;padding-right:7.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1">MAE(<math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T1.1.1.1.1.m1.1"><semantics id="S3.T1.1.1.1.1.m1.1a"><mo id="S3.T1.1.1.1.1.m1.1.1" stretchy="false" xref="S3.T1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.1.m1.1b"><ci id="S3.T1.1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T1.2.2.2" style="padding-left:7.0pt;padding-right:7.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.2.2.2.1">Corr(<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T1.2.2.2.1.m1.1"><semantics id="S3.T1.2.2.2.1.m1.1a"><mo id="S3.T1.2.2.2.1.m1.1.1" stretchy="false" xref="S3.T1.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.2.1.m1.1b"><ci id="S3.T1.2.2.2.1.m1.1.1.cmml" xref="S3.T1.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.2.1.m1.1c">\uparrow</annotation></semantics></math>)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T1.3.3.3" style="padding-left:7.0pt;padding-right:7.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.3.3.3.1">Acc-7(<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T1.3.3.3.1.m1.1"><semantics id="S3.T1.3.3.3.1.m1.1a"><mo id="S3.T1.3.3.3.1.m1.1.1" stretchy="false" xref="S3.T1.3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.3.1.m1.1b"><ci id="S3.T1.3.3.3.1.m1.1.1.cmml" xref="S3.T1.3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.3.1.m1.1c">\uparrow</annotation></semantics></math>)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T1.4.4.4" style="padding-left:7.0pt;padding-right:7.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.4.4.4.1">Acc-2(<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T1.4.4.4.1.m1.1"><semantics id="S3.T1.4.4.4.1.m1.1a"><mo id="S3.T1.4.4.4.1.m1.1.1" stretchy="false" xref="S3.T1.4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.4.1.m1.1b"><ci id="S3.T1.4.4.4.1.m1.1.1.cmml" xref="S3.T1.4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.4.1.m1.1c">\uparrow</annotation></semantics></math>)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T1.5.5.5" style="padding-left:7.0pt;padding-right:7.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.5.5.5.1">F1(<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T1.5.5.5.1.m1.1"><semantics id="S3.T1.5.5.5.1.m1.1a"><mo id="S3.T1.5.5.5.1.m1.1.1" stretchy="false" xref="S3.T1.5.5.5.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.5.1.m1.1b"><ci id="S3.T1.5.5.5.1.m1.1.1.cmml" xref="S3.T1.5.5.5.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.5.1.m1.1c">\uparrow</annotation></semantics></math>)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.6.8.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T1.6.8.1.1" style="padding-left:7.0pt;padding-right:7.0pt;">MulT <cite class="ltx_cite ltx_citemacro_citep">(Tsai et al., <a class="ltx_ref" href="#bib.bib27" title="">2019</a>)</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.6.8.1.2" style="padding-left:7.0pt;padding-right:7.0pt;">0.871</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.6.8.1.3" style="padding-left:7.0pt;padding-right:7.0pt;">0.698</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.6.8.1.4" style="padding-left:7.0pt;padding-right:7.0pt;">40.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.6.8.1.5" style="padding-left:7.0pt;padding-right:7.0pt;">- / 83.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.6.8.1.6" style="padding-left:7.0pt;padding-right:7.0pt;">- / 82.8</td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.9.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T1.6.9.2.1" style="padding-left:7.0pt;padding-right:7.0pt;">TFN <cite class="ltx_cite ltx_citemacro_citep">(Zadeh et al., <a class="ltx_ref" href="#bib.bib34" title="">2017</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S3.T1.6.9.2.2" style="padding-left:7.0pt;padding-right:7.0pt;">0.901</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.9.2.3" style="padding-left:7.0pt;padding-right:7.0pt;">0.698</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.9.2.4" style="padding-left:7.0pt;padding-right:7.0pt;">34.9</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.9.2.5" style="padding-left:7.0pt;padding-right:7.0pt;">- / 80.8</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.9.2.6" style="padding-left:7.0pt;padding-right:7.0pt;">- / 80.7</td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.10.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T1.6.10.3.1" style="padding-left:7.0pt;padding-right:7.0pt;">LMF <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="#bib.bib15" title="">2018b</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S3.T1.6.10.3.2" style="padding-left:7.0pt;padding-right:7.0pt;">0.917</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.10.3.3" style="padding-left:7.0pt;padding-right:7.0pt;">0.695</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.10.3.4" style="padding-left:7.0pt;padding-right:7.0pt;">33.2</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.10.3.5" style="padding-left:7.0pt;padding-right:7.0pt;">- / 82.5</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.10.3.6" style="padding-left:7.0pt;padding-right:7.0pt;">- / 82.4</td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.11.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T1.6.11.4.1" style="padding-left:7.0pt;padding-right:7.0pt;">MFM <cite class="ltx_cite ltx_citemacro_citep">(Tsai et al., <a class="ltx_ref" href="#bib.bib28" title="">2018</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S3.T1.6.11.4.2" style="padding-left:7.0pt;padding-right:7.0pt;">0.877</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.11.4.3" style="padding-left:7.0pt;padding-right:7.0pt;">0.706</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.11.4.4" style="padding-left:7.0pt;padding-right:7.0pt;">35.4</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.11.4.5" style="padding-left:7.0pt;padding-right:7.0pt;">- / 81.7</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.11.4.6" style="padding-left:7.0pt;padding-right:7.0pt;">- / 81.6</td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.12.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T1.6.12.5.1" style="padding-left:7.0pt;padding-right:7.0pt;">ICCN <cite class="ltx_cite ltx_citemacro_citep">(Sun et al., <a class="ltx_ref" href="#bib.bib26" title="">2020</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S3.T1.6.12.5.2" style="padding-left:7.0pt;padding-right:7.0pt;">0.860</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.12.5.3" style="padding-left:7.0pt;padding-right:7.0pt;">0.710</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.12.5.4" style="padding-left:7.0pt;padding-right:7.0pt;">39.0</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.12.5.5" style="padding-left:7.0pt;padding-right:7.0pt;">- / 83.0</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.12.5.6" style="padding-left:7.0pt;padding-right:7.0pt;">- / 83.0</td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.13.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T1.6.13.6.1" style="padding-left:7.0pt;padding-right:7.0pt;">MISA <cite class="ltx_cite ltx_citemacro_citep">(Hazarika et al., <a class="ltx_ref" href="#bib.bib8" title="">2020</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S3.T1.6.13.6.2" style="padding-left:7.0pt;padding-right:7.0pt;">0.783</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.13.6.3" style="padding-left:7.0pt;padding-right:7.0pt;">0.761</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.13.6.4" style="padding-left:7.0pt;padding-right:7.0pt;">42.3</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.13.6.5" style="padding-left:7.0pt;padding-right:7.0pt;">81.8 / 83.4</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.13.6.6" style="padding-left:7.0pt;padding-right:7.0pt;">81.7 / 83.6</td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.14.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T1.6.14.7.1" style="padding-left:7.0pt;padding-right:7.0pt;">Self-MM <cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a class="ltx_ref" href="#bib.bib33" title="">2021b</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S3.T1.6.14.7.2" style="padding-left:7.0pt;padding-right:7.0pt;">0.712</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.14.7.3" style="padding-left:7.0pt;padding-right:7.0pt;">0.795</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.14.7.4" style="padding-left:7.0pt;padding-right:7.0pt;">45.8</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.14.7.5" style="padding-left:7.0pt;padding-right:7.0pt;">82.5 / 84.8</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.14.7.6" style="padding-left:7.0pt;padding-right:7.0pt;">82.7 / 84.9</td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T1.6.6.1" style="padding-left:7.0pt;padding-right:7.0pt;">MMIM<sup class="ltx_sup" id="S3.T1.6.6.1.1"><span class="ltx_text ltx_font_italic" id="S3.T1.6.6.1.1.1">†</span></sup> <cite class="ltx_cite ltx_citemacro_citep">(Han et al., <a class="ltx_ref" href="#bib.bib6" title="">2021</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S3.T1.6.6.2" style="padding-left:7.0pt;padding-right:7.0pt;">0.700</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.6.3" style="padding-left:7.0pt;padding-right:7.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.6.6.3.1">0.800</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.6.4" style="padding-left:7.0pt;padding-right:7.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.6.6.4.1">46.7</span></td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.6.5" style="padding-left:7.0pt;padding-right:7.0pt;">84.2 / 86.1</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.6.6" style="padding-left:7.0pt;padding-right:7.0pt;">84.0 / 86.0</td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.15.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" id="S3.T1.6.15.8.1" style="padding-left:7.0pt;padding-right:7.0pt;">DBF</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.6.15.8.2" style="padding-left:7.0pt;padding-right:7.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.6.15.8.2.1">0.693</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.6.15.8.3" style="padding-left:7.0pt;padding-right:7.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.6.15.8.3.1">0.801</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.6.15.8.4" style="padding-left:7.0pt;padding-right:7.0pt;">44.8</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.6.15.8.5" style="padding-left:7.0pt;padding-right:7.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.6.15.8.5.1">85.1 / 86.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.6.15.8.6" style="padding-left:7.0pt;padding-right:7.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T1.6.15.8.6.1">85.1 / 86.9</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Results of multimodal sentiment analysis on MOSI. <math alttext="{\dagger}" class="ltx_Math" display="inline" id="S3.T1.8.m1.1"><semantics id="S3.T1.8.m1.1b"><mo id="S3.T1.8.m1.1.1" xref="S3.T1.8.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S3.T1.8.m1.1c"><ci id="S3.T1.8.m1.1.1.cmml" xref="S3.T1.8.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.8.m1.1d">{\dagger}</annotation></semantics></math> indicates the previous state-of-the-art model.</figcaption>
</figure>
<figure class="ltx_table" id="S3.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T2.6">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T2.6.7.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S3.T2.6.7.1.1" rowspan="2" style="padding-left:7.0pt;padding-right:7.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.6.7.1.1.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="5" id="S3.T2.6.7.1.2" style="padding-left:7.0pt;padding-right:7.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.6.7.1.2.1">MOSEI</span></th>
</tr>
<tr class="ltx_tr" id="S3.T2.5.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T2.1.1.1" style="padding-left:7.0pt;padding-right:7.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.1.1.1.1">MAE(<math alttext="\downarrow" class="ltx_Math" display="inline" id="S3.T2.1.1.1.1.m1.1"><semantics id="S3.T2.1.1.1.1.m1.1a"><mo id="S3.T2.1.1.1.1.m1.1.1" stretchy="false" xref="S3.T2.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.1.m1.1b"><ci id="S3.T2.1.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T2.2.2.2" style="padding-left:7.0pt;padding-right:7.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.2.2.2.1">Corr(<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T2.2.2.2.1.m1.1"><semantics id="S3.T2.2.2.2.1.m1.1a"><mo id="S3.T2.2.2.2.1.m1.1.1" stretchy="false" xref="S3.T2.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.2.2.2.1.m1.1b"><ci id="S3.T2.2.2.2.1.m1.1.1.cmml" xref="S3.T2.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.2.2.1.m1.1c">\uparrow</annotation></semantics></math>)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T2.3.3.3" style="padding-left:7.0pt;padding-right:7.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.3.3.3.1">Acc-7(<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T2.3.3.3.1.m1.1"><semantics id="S3.T2.3.3.3.1.m1.1a"><mo id="S3.T2.3.3.3.1.m1.1.1" stretchy="false" xref="S3.T2.3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.3.3.3.1.m1.1b"><ci id="S3.T2.3.3.3.1.m1.1.1.cmml" xref="S3.T2.3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.3.3.1.m1.1c">\uparrow</annotation></semantics></math>)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T2.4.4.4" style="padding-left:7.0pt;padding-right:7.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.4.4.4.1">Acc-2(<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T2.4.4.4.1.m1.1"><semantics id="S3.T2.4.4.4.1.m1.1a"><mo id="S3.T2.4.4.4.1.m1.1.1" stretchy="false" xref="S3.T2.4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.4.4.4.1.m1.1b"><ci id="S3.T2.4.4.4.1.m1.1.1.cmml" xref="S3.T2.4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.4.4.4.1.m1.1c">\uparrow</annotation></semantics></math>)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S3.T2.5.5.5" style="padding-left:7.0pt;padding-right:7.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.5.5.5.1">F1(<math alttext="\uparrow" class="ltx_Math" display="inline" id="S3.T2.5.5.5.1.m1.1"><semantics id="S3.T2.5.5.5.1.m1.1a"><mo id="S3.T2.5.5.5.1.m1.1.1" stretchy="false" xref="S3.T2.5.5.5.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S3.T2.5.5.5.1.m1.1b"><ci id="S3.T2.5.5.5.1.m1.1.1.cmml" xref="S3.T2.5.5.5.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.5.5.5.1.m1.1c">\uparrow</annotation></semantics></math>)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.6.8.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S3.T2.6.8.1.1" style="padding-left:7.0pt;padding-right:7.0pt;">MulT <cite class="ltx_cite ltx_citemacro_citep">(Tsai et al., <a class="ltx_ref" href="#bib.bib27" title="">2019</a>)</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.6.8.1.2" style="padding-left:7.0pt;padding-right:7.0pt;">0.580</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.6.8.1.3" style="padding-left:7.0pt;padding-right:7.0pt;">0.703</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.6.8.1.4" style="padding-left:7.0pt;padding-right:7.0pt;">51.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.6.8.1.5" style="padding-left:7.0pt;padding-right:7.0pt;">- / 82.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.6.8.1.6" style="padding-left:7.0pt;padding-right:7.0pt;">- / 82.5</td>
</tr>
<tr class="ltx_tr" id="S3.T2.6.9.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T2.6.9.2.1" style="padding-left:7.0pt;padding-right:7.0pt;">TFN <cite class="ltx_cite ltx_citemacro_citep">(Zadeh et al., <a class="ltx_ref" href="#bib.bib34" title="">2017</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S3.T2.6.9.2.2" style="padding-left:7.0pt;padding-right:7.0pt;">0.593</td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.9.2.3" style="padding-left:7.0pt;padding-right:7.0pt;">0.700</td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.9.2.4" style="padding-left:7.0pt;padding-right:7.0pt;">50.2</td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.9.2.5" style="padding-left:7.0pt;padding-right:7.0pt;">- / 82.1</td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.9.2.6" style="padding-left:7.0pt;padding-right:7.0pt;">- / 82.5</td>
</tr>
<tr class="ltx_tr" id="S3.T2.6.10.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T2.6.10.3.1" style="padding-left:7.0pt;padding-right:7.0pt;">LMF <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="#bib.bib15" title="">2018b</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S3.T2.6.10.3.2" style="padding-left:7.0pt;padding-right:7.0pt;">0.677</td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.10.3.3" style="padding-left:7.0pt;padding-right:7.0pt;">0.695</td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.10.3.4" style="padding-left:7.0pt;padding-right:7.0pt;">48.0</td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.10.3.5" style="padding-left:7.0pt;padding-right:7.0pt;">- / 82.1</td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.10.3.6" style="padding-left:7.0pt;padding-right:7.0pt;">- / 82.0</td>
</tr>
<tr class="ltx_tr" id="S3.T2.6.11.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T2.6.11.4.1" style="padding-left:7.0pt;padding-right:7.0pt;">MFM <cite class="ltx_cite ltx_citemacro_citep">(Tsai et al., <a class="ltx_ref" href="#bib.bib28" title="">2018</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S3.T2.6.11.4.2" style="padding-left:7.0pt;padding-right:7.0pt;">0.717</td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.11.4.3" style="padding-left:7.0pt;padding-right:7.0pt;">0.706</td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.11.4.4" style="padding-left:7.0pt;padding-right:7.0pt;">51.3</td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.11.4.5" style="padding-left:7.0pt;padding-right:7.0pt;">- / 84.3</td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.11.4.6" style="padding-left:7.0pt;padding-right:7.0pt;">- / 84.4</td>
</tr>
<tr class="ltx_tr" id="S3.T2.6.12.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T2.6.12.5.1" style="padding-left:7.0pt;padding-right:7.0pt;">ICCN <cite class="ltx_cite ltx_citemacro_citep">(Sun et al., <a class="ltx_ref" href="#bib.bib26" title="">2020</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S3.T2.6.12.5.2" style="padding-left:7.0pt;padding-right:7.0pt;">0.565</td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.12.5.3" style="padding-left:7.0pt;padding-right:7.0pt;">0.713</td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.12.5.4" style="padding-left:7.0pt;padding-right:7.0pt;">51.6</td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.12.5.5" style="padding-left:7.0pt;padding-right:7.0pt;">- / 84.2</td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.12.5.6" style="padding-left:7.0pt;padding-right:7.0pt;">- / 84.2</td>
</tr>
<tr class="ltx_tr" id="S3.T2.6.13.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T2.6.13.6.1" style="padding-left:7.0pt;padding-right:7.0pt;">MISA <cite class="ltx_cite ltx_citemacro_citep">(Hazarika et al., <a class="ltx_ref" href="#bib.bib8" title="">2020</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S3.T2.6.13.6.2" style="padding-left:7.0pt;padding-right:7.0pt;">0.555</td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.13.6.3" style="padding-left:7.0pt;padding-right:7.0pt;">0.756</td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.13.6.4" style="padding-left:7.0pt;padding-right:7.0pt;">52.2</td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.13.6.5" style="padding-left:7.0pt;padding-right:7.0pt;">83.8 / 85.3</td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.13.6.6" style="padding-left:7.0pt;padding-right:7.0pt;">83.6 / 85.5</td>
</tr>
<tr class="ltx_tr" id="S3.T2.6.14.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T2.6.14.7.1" style="padding-left:7.0pt;padding-right:7.0pt;">Self-MM <cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a class="ltx_ref" href="#bib.bib33" title="">2021b</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S3.T2.6.14.7.2" style="padding-left:7.0pt;padding-right:7.0pt;">0.529</td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.14.7.3" style="padding-left:7.0pt;padding-right:7.0pt;">0.767</td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.14.7.4" style="padding-left:7.0pt;padding-right:7.0pt;">53.5</td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.14.7.5" style="padding-left:7.0pt;padding-right:7.0pt;">82.7 / 85.0</td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.14.7.6" style="padding-left:7.0pt;padding-right:7.0pt;">83.0 / 84.9</td>
</tr>
<tr class="ltx_tr" id="S3.T2.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S3.T2.6.6.1" style="padding-left:7.0pt;padding-right:7.0pt;">MMIM<sup class="ltx_sup" id="S3.T2.6.6.1.1"><span class="ltx_text ltx_font_italic" id="S3.T2.6.6.1.1.1">†</span></sup> <cite class="ltx_cite ltx_citemacro_citep">(Han et al., <a class="ltx_ref" href="#bib.bib6" title="">2021</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S3.T2.6.6.2" style="padding-left:7.0pt;padding-right:7.0pt;">0.526</td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.6.3" style="padding-left:7.0pt;padding-right:7.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.6.6.3.1">0.772</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.6.4" style="padding-left:7.0pt;padding-right:7.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.6.6.4.1">54.2</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.6.5" style="padding-left:7.0pt;padding-right:7.0pt;">82.2 / 86.0</td>
<td class="ltx_td ltx_align_center" id="S3.T2.6.6.6" style="padding-left:7.0pt;padding-right:7.0pt;">82.7 / 85.9</td>
</tr>
<tr class="ltx_tr" id="S3.T2.6.15.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" id="S3.T2.6.15.8.1" style="padding-left:7.0pt;padding-right:7.0pt;">DBF</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T2.6.15.8.2" style="padding-left:7.0pt;padding-right:7.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.6.15.8.2.1">0.523</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T2.6.15.8.3" style="padding-left:7.0pt;padding-right:7.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.6.15.8.3.1">0.772</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T2.6.15.8.4" style="padding-left:7.0pt;padding-right:7.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.6.15.8.4.1">54.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T2.6.15.8.5" style="padding-left:7.0pt;padding-right:7.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.6.15.8.5.1">84.3 / 86.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T2.6.15.8.6" style="padding-left:7.0pt;padding-right:7.0pt;"><span class="ltx_text ltx_font_bold" id="S3.T2.6.15.8.6.1">84.8 / 86.2</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Results of multimodal sentiment analysis on MOSEI. <math alttext="{\dagger}" class="ltx_Math" display="inline" id="S3.T2.8.m1.1"><semantics id="S3.T2.8.m1.1b"><mo id="S3.T2.8.m1.1.1" xref="S3.T2.8.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S3.T2.8.m1.1c"><ci id="S3.T2.8.m1.1.1.cmml" xref="S3.T2.8.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.8.m1.1d">{\dagger}</annotation></semantics></math> indicates the previous state-of-the-art model. </figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Tasks, Datasets, and Metrics</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">We evaluate fusion results of DBF on two video multimodal tasks: video multimodal sentiment analysis and video multimodal summarization.</p>
</div>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Video Multimodal Sentiment Analysis</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.1">Video multimodal sentiment analysis is a regression task that aims to collect and tackle data from multiple resources (text, vision and acoustic) to comprehend varied human emotions.
We do this task on MOSI <cite class="ltx_cite ltx_citemacro_citep">(Zadeh et al., <a class="ltx_ref" href="#bib.bib36" title="">2016</a>)</cite> and MOSEI <cite class="ltx_cite ltx_citemacro_citep">(Zadeh et al., <a class="ltx_ref" href="#bib.bib37" title="">2018b</a>)</cite> datasets.
The MOSI dataset contains 2198 subjective utterance-video segments, which are manually annotated with a continuous opinion score between [-3, 3], where -3/+3 represents strongly negative/positive sentiments.
The MOSEI dataset is an improvement over MOSI, which contains 23453 annotated video segments (utterances), from 5000 videos, 1000 distinct speakers and 250 different topics.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS0.Px1.p2">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p2.1">Following <cite class="ltx_cite ltx_citemacro_citep">(Hazarika et al., <a class="ltx_ref" href="#bib.bib8" title="">2020</a>)</cite>, we use the same metric set to evaluate sentiment intensity predictions:
MAE (mean absolute error), which is the average of absolute difference value between predictions and labels;
Corr (Pearson correlation) that measures the degree of prediction skew;
Acc-7 (seven-class classification accuracy) ranging from -3 to 3;
Acc-2 (binary classification accuracy) and F1 score computed for positive/negative and non-negative/negative classification results.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Video Multimodal Summarization</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1">The summary task aims to generate abstractive summarization with videos and their corresponding transcripts.
We set How2 dataset <cite class="ltx_cite ltx_citemacro_citep">(Sanabria et al., <a class="ltx_ref" href="#bib.bib23" title="">2018</a>)</cite> as benchmark for this task, which is a large-scale dataset consists of 79,114 short instructional videos, and each video is accompanied by a human-generated transcript and a short text summary.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS0.Px2.p2">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p2.1">Following <cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a class="ltx_ref" href="#bib.bib32" title="">2021a</a>)</cite>, to evaluate summarization, we use metrics as follows:
ROUGE <cite class="ltx_cite ltx_citemacro_citep">(Lin and Hovy, <a class="ltx_ref" href="#bib.bib12" title="">2003</a>)</cite> (ROUGE-1, 2, L) and BLEU <cite class="ltx_cite ltx_citemacro_citep">(Papineni et al., <a class="ltx_ref" href="#bib.bib20" title="">2002</a>)</cite> (BLEU-1, 2, 3, 4), which calculate the recall and precision of n-gram overlaps, respectively;
METEOR <cite class="ltx_cite ltx_citemacro_citep">(Denkowski and Lavie, <a class="ltx_ref" href="#bib.bib3" title="">2011</a>)</cite>, which evaluates matching degree of word stems, synonyms and paraphrases;
CIDEr <cite class="ltx_cite ltx_citemacro_citep">(Vedantam et al., <a class="ltx_ref" href="#bib.bib30" title="">2015</a>)</cite> is an image captioning metric to compute the cosine similarity between TF-IDF weighted n-grams.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Experimental Settings</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">For sentiment analysis task, we use BERT-base <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al., <a class="ltx_ref" href="#bib.bib4" title="">2018</a>)</cite> to encode text input and extract the [CLS] embedding from the last layer.
For acoustic and vision, we use COVAREP <cite class="ltx_cite ltx_citemacro_citep">(Degottex et al., <a class="ltx_ref" href="#bib.bib2" title="">2014</a>)</cite> and Facet <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://imotions.com/platform/</span></span></span> to extract audio and facial expression features.
The visual feature dimensions are 47 for MOSI, 35 for MOSEI, and the audio feature dimensions are 74 for both MOSI and MOSEI.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">For summarization, we use BART <cite class="ltx_cite ltx_citemacro_citep">(Lewis et al., <a class="ltx_ref" href="#bib.bib10" title="">2019</a>)</cite> as the feature extractor and inject visual information in the last layer of the BART encoder.
For vision, a 2048-dimensional feature representation is extracted for every 16 non-overlapping frames using a 3D ResNeXt-101 model <cite class="ltx_cite ltx_citemacro_citep">(Hara et al., <a class="ltx_ref" href="#bib.bib7" title="">2018</a>)</cite>, which is pre-trained on the Kinetics dataset <cite class="ltx_cite ltx_citemacro_citep">(Kay et al., <a class="ltx_ref" href="#bib.bib9" title="">2017</a>)</cite>.
Details of the hyper-parameters are given in Appendix <a class="ltx_ref" href="#A1" title="Appendix A Hyper-parameters ‣ Denoising Bottleneck with Mutual Information Maximization for Video Multimodal Fusion"><span class="ltx_text ltx_ref_tag">A</span></a>.
For frameworks and hardware, we use the deep learning framework PyTorch <cite class="ltx_cite ltx_citemacro_citep">(Paszke et al., <a class="ltx_ref" href="#bib.bib21" title="">2017</a>)</cite> and Huggingface <span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://huggingface.co/</span></span></span> to implement our code. We use a single Nvidia GeForce A40 GPU for sentiment analysis experiments and two for summarization.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Overall Results</h3>
<figure class="ltx_table" id="S4.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T3.1.2.1.1" rowspan="2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.2.1.1.1">Method</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="9" id="S4.T3.1.2.1.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.2.1.2.1">How2</span></th>
</tr>
<tr class="ltx_tr" id="S4.T3.1.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.1.3.2.1" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.3.2.1.1">R-1</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.1.3.2.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.3.2.2.1">R-2</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.1.3.2.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.3.2.3.1">R-L</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.1.3.2.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.3.2.4.1">B-1</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.1.3.2.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.3.2.5.1">B-2</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.1.3.2.6" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.3.2.6.1">B-3</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.1.3.2.7" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.3.2.7.1">B-4</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.1.3.2.8" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.3.2.8.1">METEOR</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T3.1.3.2.9" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.3.2.9.1">CIDEr</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.1.4.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.1.4.1.1" style="padding-left:4.0pt;padding-right:4.0pt;">HA (RNN) <cite class="ltx_cite ltx_citemacro_citep">(Palaskar et al., <a class="ltx_ref" href="#bib.bib19" title="">2019</a>)</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.4.1.2" style="padding-left:4.0pt;padding-right:4.0pt;">60.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.4.1.3" style="padding-left:4.0pt;padding-right:4.0pt;">42.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.4.1.4" style="padding-left:4.0pt;padding-right:4.0pt;">55.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.4.1.5" style="padding-left:4.0pt;padding-right:4.0pt;">57.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.4.1.6" style="padding-left:4.0pt;padding-right:4.0pt;">47.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.4.1.7" style="padding-left:4.0pt;padding-right:4.0pt;">41.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.4.1.8" style="padding-left:4.0pt;padding-right:4.0pt;">37.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.4.1.9" style="padding-left:4.0pt;padding-right:4.0pt;">28.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.4.1.10" style="padding-left:4.0pt;padding-right:4.0pt;">2.48</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.5.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.1.5.2.1" style="padding-left:4.0pt;padding-right:4.0pt;">HA (TF) <cite class="ltx_cite ltx_citemacro_citep">(Palaskar et al., <a class="ltx_ref" href="#bib.bib19" title="">2019</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.2.2" style="padding-left:4.0pt;padding-right:4.0pt;">60.2</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.2.3" style="padding-left:4.0pt;padding-right:4.0pt;">43.1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.2.4" style="padding-left:4.0pt;padding-right:4.0pt;">55.9</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.2.5" style="padding-left:4.0pt;padding-right:4.0pt;">58.6</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.2.6" style="padding-left:4.0pt;padding-right:4.0pt;">48.3</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.2.7" style="padding-left:4.0pt;padding-right:4.0pt;">43.3</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.2.8" style="padding-left:4.0pt;padding-right:4.0pt;">38.1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.2.9" style="padding-left:4.0pt;padding-right:4.0pt;">28.9</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.2.10" style="padding-left:4.0pt;padding-right:4.0pt;">2.51</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.6.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.1.6.3.1" style="padding-left:4.0pt;padding-right:4.0pt;">MFFG (RNN) <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="#bib.bib13" title="">2020</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.3.2" style="padding-left:4.0pt;padding-right:4.0pt;">62.3</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.3.3" style="padding-left:4.0pt;padding-right:4.0pt;">46.1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.3.4" style="padding-left:4.0pt;padding-right:4.0pt;">58.2</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.3.5" style="padding-left:4.0pt;padding-right:4.0pt;">59.1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.3.6" style="padding-left:4.0pt;padding-right:4.0pt;">50.4</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.3.7" style="padding-left:4.0pt;padding-right:4.0pt;">45.1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.3.8" style="padding-left:4.0pt;padding-right:4.0pt;">41.1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.3.9" style="padding-left:4.0pt;padding-right:4.0pt;">30.1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.3.10" style="padding-left:4.0pt;padding-right:4.0pt;">2.69</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.7.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.1.7.4.1" style="padding-left:4.0pt;padding-right:4.0pt;">MFFG (TF) <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="#bib.bib13" title="">2020</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T3.1.7.4.2" style="padding-left:4.0pt;padding-right:4.0pt;">61.6</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.7.4.3" style="padding-left:4.0pt;padding-right:4.0pt;">45.1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.7.4.4" style="padding-left:4.0pt;padding-right:4.0pt;">57.4</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.7.4.5" style="padding-left:4.0pt;padding-right:4.0pt;">60.0</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.7.4.6" style="padding-left:4.0pt;padding-right:4.0pt;">50.9</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.7.4.7" style="padding-left:4.0pt;padding-right:4.0pt;">45.3</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.7.4.8" style="padding-left:4.0pt;padding-right:4.0pt;">41.3</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.7.4.9" style="padding-left:4.0pt;padding-right:4.0pt;">29.9</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.7.4.10" style="padding-left:4.0pt;padding-right:4.0pt;">2.67</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.1.1.1" style="padding-left:4.0pt;padding-right:4.0pt;">VG-GPLMs<sup class="ltx_sup" id="S4.T3.1.1.1.1"><span class="ltx_text ltx_font_italic" id="S4.T3.1.1.1.1.1">†</span></sup> <cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a class="ltx_ref" href="#bib.bib32" title="">2021a</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.2" style="padding-left:4.0pt;padding-right:4.0pt;">68.0</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.3" style="padding-left:4.0pt;padding-right:4.0pt;">51.4</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4" style="padding-left:4.0pt;padding-right:4.0pt;">63.3</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5" style="padding-left:4.0pt;padding-right:4.0pt;">65.2</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.6" style="padding-left:4.0pt;padding-right:4.0pt;">56.3</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.7" style="padding-left:4.0pt;padding-right:4.0pt;">50.4</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.8" style="padding-left:4.0pt;padding-right:4.0pt;">46.0</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.9" style="padding-left:4.0pt;padding-right:4.0pt;">34.0</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.10" style="padding-left:4.0pt;padding-right:4.0pt;">3.28</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.8.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" id="S4.T3.1.8.5.1" style="padding-left:4.0pt;padding-right:4.0pt;">DBF</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.1.8.5.2" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.8.5.2.1">70.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.1.8.5.3" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.8.5.3.1">54.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.1.8.5.4" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.8.5.4.1">66.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.1.8.5.5" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.8.5.5.1">67.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.1.8.5.6" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.8.5.6.1">58.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.1.8.5.7" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.8.5.7.1">53.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.1.8.5.8" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.8.5.8.1">49.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.1.8.5.9" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.8.5.9.1">35.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.1.8.5.10" style="padding-left:4.0pt;padding-right:4.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T3.1.8.5.10.1">3.56</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Results of multimodal summarization task on How2. The <math alttext="{\dagger}" class="ltx_Math" display="inline" id="S4.T3.3.m1.1"><semantics id="S4.T3.3.m1.1b"><mo id="S4.T3.3.m1.1.1" xref="S4.T3.3.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S4.T3.3.m1.1c"><ci id="S4.T3.3.m1.1.1.cmml" xref="S4.T3.3.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.m1.1d">{\dagger}</annotation></semantics></math> indicates the previous state-of-the-art model. We denote ROUGE and BLEU by R and B respectively.</figcaption>
</figure>
<figure class="ltx_table" id="S4.T4">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T4.7">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.7.8.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T4.7.8.1.1" rowspan="2" style="padding-left:15.0pt;padding-right:15.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.7.8.1.1.1">Model</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" id="S4.T4.7.8.1.2" style="padding-left:15.0pt;padding-right:15.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.7.8.1.2.1">MOSI</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.T4.7.8.1.3" style="padding-left:15.0pt;padding-right:15.0pt;">
<span class="ltx_text ltx_font_bold" id="S4.T4.7.8.1.3.1">MOSEI</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.4.4">
<td class="ltx_td ltx_align_center" id="S4.T4.1.1.1" style="padding-left:15.0pt;padding-right:15.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.1.1.1.1">MAE (<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T4.1.1.1.1.m1.1"><semantics id="S4.T4.1.1.1.1.m1.1a"><mo id="S4.T4.1.1.1.1.m1.1.1" stretchy="false" xref="S4.T4.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.1.m1.1b"><ci id="S4.T4.1.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.2.2.2" style="padding-left:15.0pt;padding-right:15.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.2.2.2.1">F1 (<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T4.2.2.2.1.m1.1"><semantics id="S4.T4.2.2.2.1.m1.1a"><mo id="S4.T4.2.2.2.1.m1.1.1" stretchy="false" xref="S4.T4.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T4.2.2.2.1.m1.1b"><ci id="S4.T4.2.2.2.1.m1.1.1.cmml" xref="S4.T4.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.2.2.1.m1.1c">\uparrow</annotation></semantics></math>)</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.3.3" style="padding-left:15.0pt;padding-right:15.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.3.3.3.1">MAE (<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T4.3.3.3.1.m1.1"><semantics id="S4.T4.3.3.3.1.m1.1a"><mo id="S4.T4.3.3.3.1.m1.1.1" stretchy="false" xref="S4.T4.3.3.3.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T4.3.3.3.1.m1.1b"><ci id="S4.T4.3.3.3.1.m1.1.1.cmml" xref="S4.T4.3.3.3.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.3.3.1.m1.1c">\downarrow</annotation></semantics></math>)</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.4.4.4" style="padding-left:15.0pt;padding-right:15.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.4.4.4.1">F1 (<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T4.4.4.4.1.m1.1"><semantics id="S4.T4.4.4.4.1.m1.1a"><mo id="S4.T4.4.4.4.1.m1.1.1" stretchy="false" xref="S4.T4.4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T4.4.4.4.1.m1.1b"><ci id="S4.T4.4.4.4.1.m1.1.1.cmml" xref="S4.T4.4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.4.4.4.1.m1.1c">\uparrow</annotation></semantics></math>)</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.7.9.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T4.7.9.2.1" style="padding-left:15.0pt;padding-right:15.0pt;">1) Ours</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.7.9.2.2" style="padding-left:15.0pt;padding-right:15.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.7.9.2.2.1">0.693</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.7.9.2.3" style="padding-left:15.0pt;padding-right:15.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.7.9.2.3.1">85.07 / 86.88</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.7.9.2.4" style="padding-left:15.0pt;padding-right:15.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.7.9.2.4.1">0.523</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.7.9.2.5" style="padding-left:15.0pt;padding-right:15.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T4.7.9.2.5.1">84.78 / 86.19</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.7.10.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.7.10.3.1" style="padding-left:15.0pt;padding-right:15.0pt;">2) (-) MI-Max</th>
<td class="ltx_td ltx_align_center" id="S4.T4.7.10.3.2" style="padding-left:15.0pt;padding-right:15.0pt;">0.697</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.7.10.3.3" style="padding-left:15.0pt;padding-right:15.0pt;">83.08 / 85.28</td>
<td class="ltx_td ltx_align_center" id="S4.T4.7.10.3.4" style="padding-left:15.0pt;padding-right:15.0pt;">0.536</td>
<td class="ltx_td ltx_align_center" id="S4.T4.7.10.3.5" style="padding-left:15.0pt;padding-right:15.0pt;">80.94 / 85.58</td>
</tr>
<tr class="ltx_tr" id="S4.T4.7.11.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.7.11.4.1" style="padding-left:15.0pt;padding-right:15.0pt;">3) (-) bottleneck</th>
<td class="ltx_td ltx_align_center" id="S4.T4.7.11.4.2" style="padding-left:15.0pt;padding-right:15.0pt;">0.750</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.7.11.4.3" style="padding-left:15.0pt;padding-right:15.0pt;">82.84 / 83.63</td>
<td class="ltx_td ltx_align_center" id="S4.T4.7.11.4.4" style="padding-left:15.0pt;padding-right:15.0pt;">0.537</td>
<td class="ltx_td ltx_align_center" id="S4.T4.7.11.4.5" style="padding-left:15.0pt;padding-right:15.0pt;">77.52 / 83.81</td>
</tr>
<tr class="ltx_tr" id="S4.T4.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T4.5.5.1" style="padding-left:15.0pt;padding-right:15.0pt;">4) (-) Language <math alttext="l" class="ltx_Math" display="inline" id="S4.T4.5.5.1.m1.1"><semantics id="S4.T4.5.5.1.m1.1a"><mi id="S4.T4.5.5.1.m1.1.1" xref="S4.T4.5.5.1.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S4.T4.5.5.1.m1.1b"><ci id="S4.T4.5.5.1.m1.1.1.cmml" xref="S4.T4.5.5.1.m1.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.5.5.1.m1.1c">l</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.2" style="padding-left:15.0pt;padding-right:15.0pt;">1.391</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.5.5.3" style="padding-left:15.0pt;padding-right:15.0pt;">55.54 / 54.95</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.4" style="padding-left:15.0pt;padding-right:15.0pt;">0.817</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.5.5.5" style="padding-left:15.0pt;padding-right:15.0pt;">67.63 / 64.01</td>
</tr>
<tr class="ltx_tr" id="S4.T4.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.6.6.1" style="padding-left:15.0pt;padding-right:15.0pt;">5) (-) Visual <math alttext="v" class="ltx_Math" display="inline" id="S4.T4.6.6.1.m1.1"><semantics id="S4.T4.6.6.1.m1.1a"><mi id="S4.T4.6.6.1.m1.1.1" xref="S4.T4.6.6.1.m1.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S4.T4.6.6.1.m1.1b"><ci id="S4.T4.6.6.1.m1.1.1.cmml" xref="S4.T4.6.6.1.m1.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.6.6.1.m1.1c">v</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="S4.T4.6.6.2" style="padding-left:15.0pt;padding-right:15.0pt;">0.700</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.6.6.3" style="padding-left:15.0pt;padding-right:15.0pt;">82.78 / 84.33</td>
<td class="ltx_td ltx_align_center" id="S4.T4.6.6.4" style="padding-left:15.0pt;padding-right:15.0pt;">0.541</td>
<td class="ltx_td ltx_align_center" id="S4.T4.6.6.5" style="padding-left:15.0pt;padding-right:15.0pt;">78.42 / 84.05</td>
</tr>
<tr class="ltx_tr" id="S4.T4.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.7.7.1" style="padding-left:15.0pt;padding-right:15.0pt;">6) (-) Audio <math alttext="a" class="ltx_Math" display="inline" id="S4.T4.7.7.1.m1.1"><semantics id="S4.T4.7.7.1.m1.1a"><mi id="S4.T4.7.7.1.m1.1.1" xref="S4.T4.7.7.1.m1.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S4.T4.7.7.1.m1.1b"><ci id="S4.T4.7.7.1.m1.1.1.cmml" xref="S4.T4.7.7.1.m1.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.7.7.1.m1.1c">a</annotation></semantics></math>
</th>
<td class="ltx_td ltx_align_center" id="S4.T4.7.7.2" style="padding-left:15.0pt;padding-right:15.0pt;">0.720</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T4.7.7.3" style="padding-left:15.0pt;padding-right:15.0pt;">83.02 / 85.86</td>
<td class="ltx_td ltx_align_center" id="S4.T4.7.7.4" style="padding-left:15.0pt;padding-right:15.0pt;">0.536</td>
<td class="ltx_td ltx_align_center" id="S4.T4.7.7.5" style="padding-left:15.0pt;padding-right:15.0pt;">80.22 / 85.02</td>
</tr>
<tr class="ltx_tr" id="S4.T4.7.12.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T4.7.12.5.1" style="padding-left:15.0pt;padding-right:15.0pt;">7) Visual-based</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.7.12.5.2" style="padding-left:15.0pt;padding-right:15.0pt;">1.372</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T4.7.12.5.3" style="padding-left:15.0pt;padding-right:15.0pt;">57.06 / 57.83</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.7.12.5.4" style="padding-left:15.0pt;padding-right:15.0pt;">0.536</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.7.12.5.5" style="padding-left:15.0pt;padding-right:15.0pt;">83.41 / 85.47</td>
</tr>
<tr class="ltx_tr" id="S4.T4.7.13.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T4.7.13.6.1" style="padding-left:15.0pt;padding-right:15.0pt;">8) Audio-based</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.7.13.6.2" style="padding-left:15.0pt;padding-right:15.0pt;">1.194</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T4.7.13.6.3" style="padding-left:15.0pt;padding-right:15.0pt;">67.95 / 70.49</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.7.13.6.4" style="padding-left:15.0pt;padding-right:15.0pt;">0.537</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.7.13.6.5" style="padding-left:15.0pt;padding-right:15.0pt;">83.80 / 85.76</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Results of ablation study. (-) represents removal for the mentioned factors.
Model 1 represents the best performing model in each dataset; Model 2,3 presents the effect of MI module and bottleneck module; Model 4,5,6 depicts the effect of individual modalities; Model 7,8 presents the variants of our model as defined in Section <a class="ltx_ref" href="#S4.SS4" title="4.4 Ablation Study ‣ 4 Experiments ‣ Denoising Bottleneck with Mutual Information Maximization for Video Multimodal Fusion"><span class="ltx_text ltx_ref_tag">4.4</span></a>.</figcaption>
</figure>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="201" id="S4.F3.g1" src="./media/x3.png" width="368"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Comparison of Grad-CAM visualizations of baseline method VG-GPLMs <cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a class="ltx_ref" href="#bib.bib32" title="">2021a</a>)</cite> (top) and DBF (bottom).
In contrast to even attention to different frames of the baseline method, DBF ignores redundancy and noise in consecutive frames and highly focuses on the key information (<em class="ltx_emph ltx_font_italic" id="S4.F3.2.1">pouring wine</em> in this example) in a particular frame. </figcaption>
</figure>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">We compare performance against DBF by considering various baselines as below:
For multimodal sentiment analysis, we compare with
MulT <cite class="ltx_cite ltx_citemacro_citep">(Tsai et al., <a class="ltx_ref" href="#bib.bib27" title="">2019</a>)</cite>,
TFN <cite class="ltx_cite ltx_citemacro_citep">(Zadeh et al., <a class="ltx_ref" href="#bib.bib34" title="">2017</a>)</cite>,
LMF <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="#bib.bib15" title="">2018b</a>)</cite>,
MFM <cite class="ltx_cite ltx_citemacro_citep">(Tsai et al., <a class="ltx_ref" href="#bib.bib28" title="">2018</a>)</cite>,
ICCN <cite class="ltx_cite ltx_citemacro_citep">(Sun et al., <a class="ltx_ref" href="#bib.bib26" title="">2020</a>)</cite>,
MISA <cite class="ltx_cite ltx_citemacro_citep">(Hazarika et al., <a class="ltx_ref" href="#bib.bib8" title="">2020</a>)</cite>,
Self-MM <cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a class="ltx_ref" href="#bib.bib33" title="">2021b</a>)</cite> and
MMIM <cite class="ltx_cite ltx_citemacro_citep">(Han et al., <a class="ltx_ref" href="#bib.bib6" title="">2021</a>)</cite>.
For multimodal summarization, we compare with
HA <cite class="ltx_cite ltx_citemacro_citep">(Palaskar et al., <a class="ltx_ref" href="#bib.bib19" title="">2019</a>)</cite>
MFFG <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="#bib.bib13" title="">2020</a>)</cite>
VG-GPLMs <cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a class="ltx_ref" href="#bib.bib32" title="">2021a</a>)</cite>.
Details of baselines are in Appendix <a class="ltx_ref" href="#A2" title="Appendix B Baselines ‣ Denoising Bottleneck with Mutual Information Maximization for Video Multimodal Fusion"><span class="ltx_text ltx_ref_tag">B</span></a>.
The comparative results for sentiment analysis are presented in Table <a class="ltx_ref" href="#S3.T1" title="Table 1 ‣ 3.3 Fusion Mutual Information Maximization ‣ 3 Methodology ‣ Denoising Bottleneck with Mutual Information Maximization for Video Multimodal Fusion"><span class="ltx_text ltx_ref_tag">1</span></a> (MOSI) and Table <a class="ltx_ref" href="#S3.T2" title="Table 2 ‣ 3.3 Fusion Mutual Information Maximization ‣ 3 Methodology ‣ Denoising Bottleneck with Mutual Information Maximization for Video Multimodal Fusion"><span class="ltx_text ltx_ref_tag">2</span></a> (MOSEI).
Results for summarization are presented in Table <a class="ltx_ref" href="#S4.T3" title="Table 3 ‣ 4.3 Overall Results ‣ 4 Experiments ‣ Denoising Bottleneck with Mutual Information Maximization for Video Multimodal Fusion"><span class="ltx_text ltx_ref_tag">3</span></a> (How2).</p>
</div>
<div class="ltx_para" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">We find that DBF yields better or comparable results to state-of-the-art methods.
To elaborate, DBF significantly outperforms state-of-the-art in all metrics on How2 and in most of metrics on MOSI and MOSEI.
For other metrics, DBF achieves very closed performance to state-of-the-art.
These outcomes preliminarily demonstrate the efficacy of our method in video multimodal fusion.</p>
</div>
<div class="ltx_para" id="S4.SS3.p3">
<p class="ltx_p" id="S4.SS3.p3.1">From the results, we can observe that our model achieves more significant performance improvement on summary task than sentiment analysis.
There could be two reasons for this: 1) the size of two datasets is small, yet DBF requires a sufficient amount of data to learn noise and redundancy patterns for this type of video.
2) Visual features are extracted by Facet on sentiment analysis task and more 3D ResNeXt-101 on summary task respectively.
Compared to sentiment analysis task, summary task employ a more advanced visual extractor and DBF is heavily influenced by the quality of visual features.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Ablation Study</h3>
<section class="ltx_paragraph" id="S4.SS4.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Effect of Fusion Bottleneck and MI-Max</h4>
<div class="ltx_para" id="S4.SS4.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS4.SSS0.Px1.p1.1">As shown in Table <a class="ltx_ref" href="#S4.T4" title="Table 4 ‣ 4.3 Overall Results ‣ 4 Experiments ‣ Denoising Bottleneck with Mutual Information Maximization for Video Multimodal Fusion"><span class="ltx_text ltx_ref_tag">4</span></a>, we first remove respectively MI-Max module and exchange fusion bottleneck module with vanilla fusion methods to observe the effects on performance.
We observe that fusion bottleneck and MI-Max both help better fusion results, and the combination of them further improves performance, which reflects the necessity of removing noise while maintaining representative information.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS4.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Effect of Modalities</h4>
<div class="ltx_para" id="S4.SS4.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS4.SSS0.Px2.p1.1">Then we remove one modality at a time to observe the effect on performance.
Firstly, we observe that the multimodal combination provides the best performance, indicating that our model can learn complementary information from different modalities.
Next, we observe that the performance drops sharply when the language modality is removed.
This may be due to the fact that text has higher information density compared to redundant audio and visual modalities.
It verifies two things: 1) It is critical to remove noise and redundancy to increase information density of visual and audio modalities when doing fusion. 2) Text-centric fusion results may help improve performance on multimodal summary and sentiment analysis tasks.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS4.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Effect of Center Modality</h4>
<div class="ltx_para" id="S4.SS4.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS4.SSS0.Px3.p1.1">As mentioned above, text-centric fusion results tend to perform better as low information intensity and high redundancy in other modalities. Thus, we evaluate fusion results based on acoustic and vision modality respectively on downstream tasks.
We observe an obvious decline in performance when audio or visual modality is used as the central modality.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Case Study</h3>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.1">In this section,
we first calculate standard deviation and normalized entropy over visual attention scores in the Grad-CAM heatmaps <cite class="ltx_cite ltx_citemacro_citep">(Selvaraju et al., <a class="ltx_ref" href="#bib.bib24" title="">2017</a>)</cite> for DBF and baseline method VG-GPLMs <cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a class="ltx_ref" href="#bib.bib32" title="">2021a</a>)</cite> respectively.
These two metrics show the sharpness of visual attention scores, indicating whether the model focuses more on key frames and ignores redundant content.
Then, we compute visualizations on Grad-CAM heatmaps acquired before to show the ability of DBF to filter out redundancy and preserve key information.</p>
</div>
<section class="ltx_paragraph" id="S4.SS5.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Statistics of Visualization Results</h4>
<div class="ltx_para" id="S4.SS5.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS5.SSS0.Px1.p1.1">Grad-CAM is a visualization method of images, it obtains visualization heatmaps by calculating weights and gradients during backpropagation, and in this paper we extend Grad-CAM to videos.
Further, to quantify this sharpness of visual attention, we calculate standard deviation and normalized entropy on Grad-CAM heatmaps over the test split on How2 dataset.
For results, DBF gets 0.830, 0.008, baseline gets 0.404, 0.062 in deviation and normalized entropy respectively.
DBF holds a higher deviation and lower entropy, which indicates sharper visual attention maps to discriminate redundancy and key frames.
</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS5.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Visualization Example</h4>
<div class="ltx_para" id="S4.SS5.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS5.SSS0.Px2.p1.1">Figure <a class="ltx_ref" href="#S4.F3" title="Figure 3 ‣ 4.3 Overall Results ‣ 4 Experiments ‣ Denoising Bottleneck with Mutual Information Maximization for Video Multimodal Fusion"><span class="ltx_text ltx_ref_tag">3</span></a> provides Grad-CAM visualizations of DBF and baseline method.
As we can see, DBF has more sharp attention over continuous frames and ignores redundancy while preserving critical information in visual inputs.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this paper, we propose a denoising video multimodal fusion system DBF which contains a fusion bottleneck to filter out redundancy with noise,
a mutual information module to preserve key information in fusion results.
Our model alleviates redundancy and nosie problem in video multimodal fusion and makes full use of all representative information in redundant modalities (vision and acoustic).
In the experiments, we show that our model significantly and consistently outperforms state-of-the-art video multimodal models.
In addition, we demonstrate that DBF can appropriately select necessary contents and neglect redundancy in video by comprehensive ablation and visualization studies.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">In the future, we will explore the following directions:
(1) We will try to extend the proposed DBF model to more multimodal fusion tasks such as humor detection.
(2) We will incorporate vision-text pretraining backbones into our DBF model to further improve its performance.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Limitations</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">First, limited by the category of video multimodal fusion tasks, we do not perform experiments on more tasks to better validate the effectiveness of our method, and we hope to extend our model to more various and complete benchmarks in future work.
Secondly, as shown in Section <a class="ltx_ref" href="#S4.SS3" title="4.3 Overall Results ‣ 4 Experiments ‣ Denoising Bottleneck with Mutual Information Maximization for Video Multimodal Fusion"><span class="ltx_text ltx_ref_tag">4.3</span></a>, our model achieves relatively slight performance improvement on sentiment analysis task.
For reasons, our model may be dependent on the scale of datasets to learn noise and redundancy patterns in video, which needs to be further improved and studied.</p>
</div>
</section>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_title_section">Acknowledgement</h2>
<div class="ltx_para" id="Sx2.p1">
<p class="ltx_p" id="Sx2.p1.1">This paper is supported by the National Key Research and Development Program of China 2020AAA0106700 and NSFC project U19A2065.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Belghazi et al. (2018)</span>
<span class="ltx_bibblock">
Mohamed Ishmael Belghazi, Aristide Baratin, Sai Rajeswar, Sherjil Ozair, Yoshua
Bengio, Aaron Courville, and R Devon Hjelm. 2018.

</span>
<span class="ltx_bibblock">Mine: mutual information neural estimation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:1801.04062</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Degottex et al. (2014)</span>
<span class="ltx_bibblock">
Gilles Degottex, John Kane, Thomas Drugman, Tuomo Raitio, and Stefan Scherer.
2014.

</span>
<span class="ltx_bibblock">Covarep—a collaborative voice analysis repository for speech
technologies.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">2014 ieee international conference on acoustics, speech and
signal processing (icassp)</em>, pages 960–964. IEEE.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Denkowski and Lavie (2011)</span>
<span class="ltx_bibblock">
Michael Denkowski and Alon Lavie. 2011.

</span>
<span class="ltx_bibblock">Meteor 1.3: Automatic metric for reliable optimization and evaluation
of machine translation systems.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Proceedings of the sixth workshop on statistical machine
translation</em>, pages 85–91.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al. (2018)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional transformers for language
understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:1810.04805</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gutmann and Hyvärinen (2010)</span>
<span class="ltx_bibblock">
Michael Gutmann and Aapo Hyvärinen. 2010.

</span>
<span class="ltx_bibblock">Noise-contrastive estimation: A new estimation principle for
unnormalized statistical models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the thirteenth international conference on
artificial intelligence and statistics</em>, pages 297–304. JMLR Workshop and
Conference Proceedings.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et al. (2021)</span>
<span class="ltx_bibblock">
Wei Han, Hui Chen, and Soujanya Poria. 2021.

</span>
<span class="ltx_bibblock">Improving multimodal fusion with hierarchical mutual information
maximization for multimodal sentiment analysis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:2109.00412</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hara et al. (2018)</span>
<span class="ltx_bibblock">
Kensho Hara, Hirokatsu Kataoka, and Yutaka Satoh. 2018.

</span>
<span class="ltx_bibblock">Can spatiotemporal 3d cnns retrace the history of 2d cnns and
imagenet?

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of the IEEE conference on Computer Vision and
Pattern Recognition</em>, pages 6546–6555.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hazarika et al. (2020)</span>
<span class="ltx_bibblock">
Devamanyu Hazarika, Roger Zimmermann, and Soujanya Poria. 2020.

</span>
<span class="ltx_bibblock">Misa: Modality-invariant and-specific representations for multimodal
sentiment analysis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Proceedings of the 28th ACM international conference on
multimedia</em>, pages 1122–1131.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kay et al. (2017)</span>
<span class="ltx_bibblock">
Will Kay, Joao Carreira, Karen Simonyan, Brian Zhang, Chloe Hillier, Sudheendra
Vijayanarasimhan, Fabio Viola, Tim Green, Trevor Back, Paul Natsev, et al.
2017.

</span>
<span class="ltx_bibblock">The kinetics human action video dataset.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:1705.06950</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et al. (2019)</span>
<span class="ltx_bibblock">
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed,
Omer Levy, Ves Stoyanov, and Luke Zettlemoyer. 2019.

</span>
<span class="ltx_bibblock">Bart: Denoising sequence-to-sequence pre-training for natural
language generation, translation, and comprehension.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:1910.13461</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2017)</span>
<span class="ltx_bibblock">
Haoran Li, Junnan Zhu, Cong Ma, Jiajun Zhang, and Chengqing Zong. 2017.

</span>
<span class="ltx_bibblock">Multi-modal summarization for asynchronous collection of text, image,
audio and video.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Proceedings of the 2017 Conference on Empirical Methods in
Natural Language Processing</em>, pages 1092–1102.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin and Hovy (2003)</span>
<span class="ltx_bibblock">
Chin-Yew Lin and Eduard Hovy. 2003.

</span>
<span class="ltx_bibblock">Automatic evaluation of summaries using n-gram co-occurrence
statistics.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the 2003 human language technology conference
of the North American chapter of the association for computational
linguistics</em>, pages 150–157.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2020)</span>
<span class="ltx_bibblock">
Nayu Liu, Xian Sun, Hongfeng Yu, Wenkai Zhang, and Guangluan Xu. 2020.

</span>
<span class="ltx_bibblock">Multistage fusion with forget gate for multimodal summarization in
open-domain videos.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>, pages 1834–1845.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2018a)</span>
<span class="ltx_bibblock">
Zhun Liu, Ying Shen, Varun Bharadhwaj Lakshminarasimhan, Paul Pu Liang, Amir
Zadeh, and Louis-Philippe Morency. 2018a.

</span>
<span class="ltx_bibblock">Efficient low-rank multimodal fusion with modality-specific factors.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:1806.00064</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2018b)</span>
<span class="ltx_bibblock">
Zhun Liu, Ying Shen, Varun Bharadhwaj Lakshminarasimhan, Paul Pu Liang, Amir
Zadeh, and Louis-Philippe Morency. 2018b.

</span>
<span class="ltx_bibblock">Efficient low-rank multimodal fusion with modality-specific factors.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">arXiv preprint arXiv:1806.00064</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo et al. (2021)</span>
<span class="ltx_bibblock">
Huaishao Luo, Lei Ji, Yanyong Huang, Bin Wang, Shenggong Ji, and Tianrui Li.
2021.

</span>
<span class="ltx_bibblock">Scalevlad: Improving multimodal sentiment analysis via multi-scale
fusion of locally descriptors.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">arXiv preprint arXiv:2112.01368</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nagrani et al. (2021)</span>
<span class="ltx_bibblock">
Arsha Nagrani, Shan Yang, Anurag Arnab, Aren Jansen, Cordelia Schmid, and Chen
Sun. 2021.

</span>
<span class="ltx_bibblock">Attention bottlenecks for multimodal fusion.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Advances in Neural Information Processing Systems</em>,
34:14200–14213.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oord et al. (2018)</span>
<span class="ltx_bibblock">
Aaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018.

</span>
<span class="ltx_bibblock">Representation learning with contrastive predictive coding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">arXiv preprint arXiv:1807.03748</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Palaskar et al. (2019)</span>
<span class="ltx_bibblock">
Shruti Palaskar, Jindrich Libovickỳ, Spandana Gella, and Florian Metze.
2019.

</span>
<span class="ltx_bibblock">Multimodal abstractive summarization for how2 videos.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:1906.07901</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papineni et al. (2002)</span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.

</span>
<span class="ltx_bibblock">Bleu: a method for automatic evaluation of machine translation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Proceedings of the 40th annual meeting of the Association
for Computational Linguistics</em>, pages 311–318.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Paszke et al. (2017)</span>
<span class="ltx_bibblock">
A. Paszke, S. Gross, S. Chintala, G. Chanan, E. Yang, Z. Devito, Z. Lin,
A. Desmaison, L. Antiga, and A. Lerer. 2017.

</span>
<span class="ltx_bibblock">Automatic differentiation in pytorch.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Poria et al. (2020)</span>
<span class="ltx_bibblock">
Soujanya Poria, Devamanyu Hazarika, Navonil Majumder, and Rada Mihalcea. 2020.

</span>
<span class="ltx_bibblock">Beneath the tip of the iceberg: Current challenges and new directions
in sentiment analysis research.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">IEEE Transactions on Affective Computing</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sanabria et al. (2018)</span>
<span class="ltx_bibblock">
Ramon Sanabria, Ozan Caglayan, Shruti Palaskar, Desmond Elliott, Loïc
Barrault, Lucia Specia, and Florian Metze. 2018.

</span>
<span class="ltx_bibblock">How2: a large-scale dataset for multimodal language understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:1811.00347</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Selvaraju et al. (2017)</span>
<span class="ltx_bibblock">
Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam,
Devi Parikh, and Dhruv Batra. 2017.

</span>
<span class="ltx_bibblock">Grad-cam: Visual explanations from deep networks via gradient-based
localization.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proceedings of the IEEE international conference on computer
vision</em>, pages 618–626.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2019)</span>
<span class="ltx_bibblock">
Chen Sun, Austin Myers, Carl Vondrick, Kevin Murphy, and Cordelia Schmid. 2019.

</span>
<span class="ltx_bibblock">Videobert: A joint model for video and language representation
learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Proceedings of the IEEE/CVF International Conference on
Computer Vision (ICCV)</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2020)</span>
<span class="ltx_bibblock">
Zhongkai Sun, Prathusha Sarma, William Sethares, and Yingyu Liang. 2020.

</span>
<span class="ltx_bibblock">Learning relationships between text, audio, and video via deep
canonical correlation for multimodal language analysis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Proceedings of the AAAI Conference on Artificial
Intelligence</em>, volume 34, pages 8992–8999.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tsai et al. (2019)</span>
<span class="ltx_bibblock">
Yao-Hung Hubert Tsai, Shaojie Bai, Paul Pu Liang, J Zico Kolter, Louis-Philippe
Morency, and Ruslan Salakhutdinov. 2019.

</span>
<span class="ltx_bibblock">Multimodal transformer for unaligned multimodal language sequences.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proceedings of the conference. Association for Computational
Linguistics. Meeting</em>, volume 2019, page 6558. NIH Public Access.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tsai et al. (2018)</span>
<span class="ltx_bibblock">
Yao-Hung Hubert Tsai, Paul Pu Liang, Amir Zadeh, Louis-Philippe Morency, and
Ruslan Salakhutdinov. 2018.

</span>
<span class="ltx_bibblock">Learning factorized multimodal representations.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">arXiv preprint arXiv:1806.06176</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al. (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Advances in neural information processing systems</em>, 30.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vedantam et al. (2015)</span>
<span class="ltx_bibblock">
Ramakrishna Vedantam, C Lawrence Zitnick, and Devi Parikh. 2015.

</span>
<span class="ltx_bibblock">Cider: Consensus-based image description evaluation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Proceedings of the IEEE conference on computer vision and
pattern recognition</em>, pages 4566–4575.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2021)</span>
<span class="ltx_bibblock">
Yang Wu, Zijie Lin, Yanyan Zhao, Bing Qin, and Li-Nan Zhu. 2021.

</span>
<span class="ltx_bibblock">A text-centered shared-private framework via cross-modal prediction
for multimodal sentiment analysis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Findings of the Association for Computational Linguistics:
ACL-IJCNLP 2021</em>, pages 4730–4738.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2021a)</span>
<span class="ltx_bibblock">
Tiezheng Yu, Wenliang Dai, Zihan Liu, and Pascale Fung. 2021a.

</span>
<span class="ltx_bibblock">Vision guided generative pre-trained language models for multimodal
abstractive summarization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">arXiv preprint arXiv:2109.02401</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2021b)</span>
<span class="ltx_bibblock">
Wenmeng Yu, Hua Xu, Ziqi Yuan, and Jiele Wu. 2021b.

</span>
<span class="ltx_bibblock">Learning modality-specific representations with self-supervised
multi-task learning for multimodal sentiment analysis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Proceedings of the AAAI Conference on Artificial
Intelligence</em>, volume 35, pages 10790–10797.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zadeh et al. (2017)</span>
<span class="ltx_bibblock">
Amir Zadeh, Minghai Chen, Soujanya Poria, Erik Cambria, and Louis-Philippe
Morency. 2017.

</span>
<span class="ltx_bibblock">Tensor fusion network for multimodal sentiment analysis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">arXiv preprint arXiv:1707.07250</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zadeh et al. (2018a)</span>
<span class="ltx_bibblock">
Amir Zadeh, Paul Pu Liang, Navonil Mazumder, Soujanya Poria, Erik Cambria, and
Louis-Philippe Morency. 2018a.

</span>
<span class="ltx_bibblock">Memory fusion network for multi-view sequential learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Proceedings of the AAAI conference on artificial
intelligence</em>, volume 32.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zadeh et al. (2016)</span>
<span class="ltx_bibblock">
Amir Zadeh, Rowan Zellers, Eli Pincus, and Louis-Philippe Morency. 2016.

</span>
<span class="ltx_bibblock">Mosi: multimodal corpus of sentiment intensity and subjectivity
analysis in online opinion videos.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">arXiv preprint arXiv:1606.06259</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zadeh et al. (2018b)</span>
<span class="ltx_bibblock">
AmirAli Bagher Zadeh, Paul Pu Liang, Soujanya Poria, Erik Cambria, and
Louis-Philippe Morency. 2018b.

</span>
<span class="ltx_bibblock">Multimodal language analysis in the wild: Cmu-mosei dataset and
interpretable dynamic fusion graph.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Proceedings of the 56th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)</em>, pages 2236–2246.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2019)</span>
<span class="ltx_bibblock">
Zhuosheng Zhang, Kehai Chen, Rui Wang, Masao Utiyama, Eiichiro Sumita, Zuchao
Li, and Hai Zhao. 2019.

</span>
<span class="ltx_bibblock">Neural machine translation with universal visual representation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">International Conference on Learning Representations</em>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="Ax1">
<h2 class="ltx_title ltx_title_appendix">Appendix</h2>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Hyper-parameters</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">We set hyper-parameters as shown in Table <a class="ltx_ref" href="#A1.T5" title="Table 5 ‣ Appendix A Hyper-parameters ‣ Denoising Bottleneck with Mutual Information Maximization for Video Multimodal Fusion"><span class="ltx_text ltx_ref_tag">5</span></a> for best performance.
For optimization, we utilize the Adam optimizer with warmup. The training duration of each model is governed by early-stopping strategy with a patience of 10 epochs.</p>
</div>
<figure class="ltx_table" id="A1.T5">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.T5.3">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T5.3.4.1">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_tt" id="A1.T5.3.4.1.1" style="padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T5.3.4.1.1.1">Hyper-Parameter</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" id="A1.T5.3.4.1.2" style="padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T5.3.4.1.2.1">MOSI</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" id="A1.T5.3.4.1.3" style="padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T5.3.4.1.3.1">MOSEI</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" id="A1.T5.3.4.1.4" style="padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T5.3.4.1.4.1">How2</span></td>
</tr>
<tr class="ltx_tr" id="A1.T5.3.5.2">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" id="A1.T5.3.5.2.1" style="padding-left:1.5pt;padding-right:1.5pt;">Batch size</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="A1.T5.3.5.2.2" style="padding-left:1.5pt;padding-right:1.5pt;">32</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="A1.T5.3.5.2.3" style="padding-left:1.5pt;padding-right:1.5pt;">96</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="A1.T5.3.5.2.4" style="padding-left:1.5pt;padding-right:1.5pt;">80</td>
</tr>
<tr class="ltx_tr" id="A1.T5.3.6.3">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="A1.T5.3.6.3.1" style="padding-left:1.5pt;padding-right:1.5pt;">Bottleneck length</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="A1.T5.3.6.3.2" style="padding-left:1.5pt;padding-right:1.5pt;">2</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="A1.T5.3.6.3.3" style="padding-left:1.5pt;padding-right:1.5pt;">4</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="A1.T5.3.6.3.4" style="padding-left:1.5pt;padding-right:1.5pt;">8</td>
</tr>
<tr class="ltx_tr" id="A1.T5.3.7.4">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="A1.T5.3.7.4.1" style="padding-left:1.5pt;padding-right:1.5pt;">Num of bottleneck layers</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="A1.T5.3.7.4.2" style="padding-left:1.5pt;padding-right:1.5pt;">4</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="A1.T5.3.7.4.3" style="padding-left:1.5pt;padding-right:1.5pt;">4</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="A1.T5.3.7.4.4" style="padding-left:1.5pt;padding-right:1.5pt;">4</td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.1">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="A1.T5.1.1.1" style="padding-left:1.5pt;padding-right:1.5pt;"><math alttext="\alpha" class="ltx_Math" display="inline" id="A1.T5.1.1.1.m1.1"><semantics id="A1.T5.1.1.1.m1.1a"><mi id="A1.T5.1.1.1.m1.1.1" xref="A1.T5.1.1.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="A1.T5.1.1.1.m1.1b"><ci id="A1.T5.1.1.1.m1.1.1.cmml" xref="A1.T5.1.1.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.1.1.1.m1.1c">\alpha</annotation></semantics></math></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="A1.T5.1.1.2" style="padding-left:1.5pt;padding-right:1.5pt;">0.05</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="A1.T5.1.1.3" style="padding-left:1.5pt;padding-right:1.5pt;">0.1</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="A1.T5.1.1.4" style="padding-left:1.5pt;padding-right:1.5pt;">0.1</td>
</tr>
<tr class="ltx_tr" id="A1.T5.2.2">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="A1.T5.2.2.1" style="padding-left:1.5pt;padding-right:1.5pt;">Learning rate <math alttext="\eta_{\text{DBF}}" class="ltx_Math" display="inline" id="A1.T5.2.2.1.m1.1"><semantics id="A1.T5.2.2.1.m1.1a"><msub id="A1.T5.2.2.1.m1.1.1" xref="A1.T5.2.2.1.m1.1.1.cmml"><mi id="A1.T5.2.2.1.m1.1.1.2" xref="A1.T5.2.2.1.m1.1.1.2.cmml">η</mi><mtext id="A1.T5.2.2.1.m1.1.1.3" xref="A1.T5.2.2.1.m1.1.1.3a.cmml">DBF</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.T5.2.2.1.m1.1b"><apply id="A1.T5.2.2.1.m1.1.1.cmml" xref="A1.T5.2.2.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T5.2.2.1.m1.1.1.1.cmml" xref="A1.T5.2.2.1.m1.1.1">subscript</csymbol><ci id="A1.T5.2.2.1.m1.1.1.2.cmml" xref="A1.T5.2.2.1.m1.1.1.2">𝜂</ci><ci id="A1.T5.2.2.1.m1.1.1.3a.cmml" xref="A1.T5.2.2.1.m1.1.1.3"><mtext id="A1.T5.2.2.1.m1.1.1.3.cmml" mathsize="70%" xref="A1.T5.2.2.1.m1.1.1.3">DBF</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.2.2.1.m1.1c">\eta_{\text{DBF}}</annotation></semantics></math>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="A1.T5.2.2.2" style="padding-left:1.5pt;padding-right:1.5pt;">2e-05</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="A1.T5.2.2.3" style="padding-left:1.5pt;padding-right:1.5pt;">2e-03</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="A1.T5.2.2.4" style="padding-left:1.5pt;padding-right:1.5pt;">3e-04</td>
</tr>
<tr class="ltx_tr" id="A1.T5.3.3">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" id="A1.T5.3.3.1" style="padding-left:1.5pt;padding-right:1.5pt;">Learning rate <math alttext="\eta_{\text{Backbone}}" class="ltx_Math" display="inline" id="A1.T5.3.3.1.m1.1"><semantics id="A1.T5.3.3.1.m1.1a"><msub id="A1.T5.3.3.1.m1.1.1" xref="A1.T5.3.3.1.m1.1.1.cmml"><mi id="A1.T5.3.3.1.m1.1.1.2" xref="A1.T5.3.3.1.m1.1.1.2.cmml">η</mi><mtext id="A1.T5.3.3.1.m1.1.1.3" xref="A1.T5.3.3.1.m1.1.1.3a.cmml">Backbone</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.T5.3.3.1.m1.1b"><apply id="A1.T5.3.3.1.m1.1.1.cmml" xref="A1.T5.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T5.3.3.1.m1.1.1.1.cmml" xref="A1.T5.3.3.1.m1.1.1">subscript</csymbol><ci id="A1.T5.3.3.1.m1.1.1.2.cmml" xref="A1.T5.3.3.1.m1.1.1.2">𝜂</ci><ci id="A1.T5.3.3.1.m1.1.1.3a.cmml" xref="A1.T5.3.3.1.m1.1.1.3"><mtext id="A1.T5.3.3.1.m1.1.1.3.cmml" mathsize="70%" xref="A1.T5.3.3.1.m1.1.1.3">Backbone</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.3.3.1.m1.1c">\eta_{\text{Backbone}}</annotation></semantics></math>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="A1.T5.3.3.2" style="padding-left:1.5pt;padding-right:1.5pt;">1e-04</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="A1.T5.3.3.3" style="padding-left:1.5pt;padding-right:1.5pt;">5e-05</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="A1.T5.3.3.4" style="padding-left:1.5pt;padding-right:1.5pt;">6e-05</td>
</tr>
<tr class="ltx_tr" id="A1.T5.3.8.5">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_bb" id="A1.T5.3.8.5.1" style="padding-left:1.5pt;padding-right:1.5pt;">Fusion size</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="A1.T5.3.8.5.2" style="padding-left:1.5pt;padding-right:1.5pt;">128</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="A1.T5.3.8.5.3" style="padding-left:1.5pt;padding-right:1.5pt;">128</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="A1.T5.3.8.5.4" style="padding-left:1.5pt;padding-right:1.5pt;">768</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Hyper-parameters for the best performance.
<math alttext="\eta_{\text{Backbone}}" class="ltx_Math" display="inline" id="A1.T5.6.m1.1"><semantics id="A1.T5.6.m1.1b"><msub id="A1.T5.6.m1.1.1" xref="A1.T5.6.m1.1.1.cmml"><mi id="A1.T5.6.m1.1.1.2" xref="A1.T5.6.m1.1.1.2.cmml">η</mi><mtext id="A1.T5.6.m1.1.1.3" xref="A1.T5.6.m1.1.1.3a.cmml">Backbone</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.T5.6.m1.1c"><apply id="A1.T5.6.m1.1.1.cmml" xref="A1.T5.6.m1.1.1"><csymbol cd="ambiguous" id="A1.T5.6.m1.1.1.1.cmml" xref="A1.T5.6.m1.1.1">subscript</csymbol><ci id="A1.T5.6.m1.1.1.2.cmml" xref="A1.T5.6.m1.1.1.2">𝜂</ci><ci id="A1.T5.6.m1.1.1.3a.cmml" xref="A1.T5.6.m1.1.1.3"><mtext id="A1.T5.6.m1.1.1.3.cmml" mathsize="70%" xref="A1.T5.6.m1.1.1.3">Backbone</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.6.m1.1d">\eta_{\text{Backbone}}</annotation></semantics></math> denotes the learning rate of parameters of the backbone pretrained model.
<math alttext="\eta_{\text{DBF}}" class="ltx_Math" display="inline" id="A1.T5.7.m2.1"><semantics id="A1.T5.7.m2.1b"><msub id="A1.T5.7.m2.1.1" xref="A1.T5.7.m2.1.1.cmml"><mi id="A1.T5.7.m2.1.1.2" xref="A1.T5.7.m2.1.1.2.cmml">η</mi><mtext id="A1.T5.7.m2.1.1.3" xref="A1.T5.7.m2.1.1.3a.cmml">DBF</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.T5.7.m2.1c"><apply id="A1.T5.7.m2.1.1.cmml" xref="A1.T5.7.m2.1.1"><csymbol cd="ambiguous" id="A1.T5.7.m2.1.1.1.cmml" xref="A1.T5.7.m2.1.1">subscript</csymbol><ci id="A1.T5.7.m2.1.1.2.cmml" xref="A1.T5.7.m2.1.1.2">𝜂</ci><ci id="A1.T5.7.m2.1.1.3a.cmml" xref="A1.T5.7.m2.1.1.3"><mtext id="A1.T5.7.m2.1.1.3.cmml" mathsize="70%" xref="A1.T5.7.m2.1.1.3">DBF</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.7.m2.1d">\eta_{\text{DBF}}</annotation></semantics></math> denotes the learning rate of new parameters introduced by our DBF model.
</figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Baselines</h2>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">For multimodal sentiment analysis:</p>
</div>
<section class="ltx_paragraph" id="A2.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">MulT <cite class="ltx_cite ltx_citemacro_citep">(Tsai et al., <a class="ltx_ref" href="#bib.bib27" title="">2019</a>)</cite> :</h4>
<div class="ltx_para" id="A2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="A2.SS0.SSS0.Px1.p1.1">a multimodal transformer architecture model with directional pairwise cross-attention, which translates one modality to another.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">TFN <cite class="ltx_cite ltx_citemacro_citep">(Zadeh et al., <a class="ltx_ref" href="#bib.bib34" title="">2017</a>)</cite>
</h4>
<div class="ltx_para" id="A2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="A2.SS0.SSS0.Px2.p1.1">based on tensor outer product to capture multiple-modal interactions.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">LMF <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="#bib.bib15" title="">2018b</a>)</cite> :</h4>
<div class="ltx_para" id="A2.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="A2.SS0.SSS0.Px3.p1.1">an advanced version of TFN model.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS0.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">MFM <cite class="ltx_cite ltx_citemacro_citep">(Tsai et al., <a class="ltx_ref" href="#bib.bib28" title="">2018</a>)</cite> :</h4>
<div class="ltx_para" id="A2.SS0.SSS0.Px4.p1">
<p class="ltx_p" id="A2.SS0.SSS0.Px4.p1.1">a model that factorizes representations into two sets of independent factors: multimodal discriminative and modality-specific generative factors.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS0.SSS0.Px5">
<h4 class="ltx_title ltx_title_paragraph">ICCN <cite class="ltx_cite ltx_citemacro_citep">(Sun et al., <a class="ltx_ref" href="#bib.bib26" title="">2020</a>)</cite> :</h4>
<div class="ltx_para" id="A2.SS0.SSS0.Px5.p1">
<p class="ltx_p" id="A2.SS0.SSS0.Px5.p1.1">an adversarial encoder-decoder classifier framework-based model to learn a modality-invariant embedding space.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS0.SSS0.Px6">
<h4 class="ltx_title ltx_title_paragraph">MISA <cite class="ltx_cite ltx_citemacro_citep">(Hazarika et al., <a class="ltx_ref" href="#bib.bib8" title="">2020</a>)</cite> </h4>
<div class="ltx_para" id="A2.SS0.SSS0.Px6.p1">
<p class="ltx_p" id="A2.SS0.SSS0.Px6.p1.1">projects each modality to two distinct subspaces.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS0.SSS0.Px7">
<h4 class="ltx_title ltx_title_paragraph">Self-MM <cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a class="ltx_ref" href="#bib.bib33" title="">2021b</a>)</cite> </h4>
<div class="ltx_para" id="A2.SS0.SSS0.Px7.p1">
<p class="ltx_p" id="A2.SS0.SSS0.Px7.p1.1">propose a label generation module based on the self-supervised learning strategy to acquire independent unimodal supervision.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS0.SSS0.Px8">
<h4 class="ltx_title ltx_title_paragraph">MMIM <cite class="ltx_cite ltx_citemacro_citep">(Han et al., <a class="ltx_ref" href="#bib.bib6" title="">2021</a>)</cite> </h4>
<div class="ltx_para" id="A2.SS0.SSS0.Px8.p1">
<p class="ltx_p" id="A2.SS0.SSS0.Px8.p1.1">hierarchically maximizes the mutual information in unimodal input pairs and between multimodal fusion result and unimodal input.</p>
</div>
<div class="ltx_para" id="A2.SS0.SSS0.Px8.p2">
<p class="ltx_p" id="A2.SS0.SSS0.Px8.p2.1">For multimodal summarization, We compare DBF with the following baselines:</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS0.SSS0.Px9">
<h4 class="ltx_title ltx_title_paragraph">HA <cite class="ltx_cite ltx_citemacro_citep">(Palaskar et al., <a class="ltx_ref" href="#bib.bib19" title="">2019</a>)</cite> :</h4>
<div class="ltx_para" id="A2.SS0.SSS0.Px9.p1">
<p class="ltx_p" id="A2.SS0.SSS0.Px9.p1.1">a sequence-to-sequence multimodal fusion model with hierarchical attention.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS0.SSS0.Px10">
<h4 class="ltx_title ltx_title_paragraph">MFFG <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="#bib.bib13" title="">2020</a>)</cite> :</h4>
<div class="ltx_para" id="A2.SS0.SSS0.Px10.p1">
<p class="ltx_p" id="A2.SS0.SSS0.Px10.p1.1">a multistage fusion network with the fusion forget gate module, which controls the flow of redundant information between multimodal long sequences via a forgetting module.</p>
</div>
</section>
<section class="ltx_paragraph" id="A2.SS0.SSS0.Px11">
<h4 class="ltx_title ltx_title_paragraph">VG-GPLMs <cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a class="ltx_ref" href="#bib.bib32" title="">2021a</a>)</cite> :</h4>
<div class="ltx_para" id="A2.SS0.SSS0.Px11.p1">
<p class="ltx_p" id="A2.SS0.SSS0.Px11.p1.1">a BART-based and vision guided model for multimodal summarization task, which use attention-based add-on layers to incorporate visual information.</p>
</div>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a class="ar5iv-nav-button ar5iv-nav-button-prev" href="/html/2305.14651">◄</a>
<a class="ar5iv-home-button" href="/"><img alt="ar5iv homepage" height="40" src="/assets/ar5iv.png"/></a>
<a class="ar5iv-text-button" href="/feeling_lucky">Feeling<br/>lucky?</a>
<a aria-hidden="true" href="/land_of_honey_and_milk" rel="nofollow" tabindex="-1"></a>
<a class="ar5iv-text-button ar5iv-severity-warning" href="/log/2305.14652">Conversion<br/>report</a>
<a class="ar5iv-text-button" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2305.14652" target="_blank">Report<br/>an issue</a>
<a class="ar5iv-text-button arxiv-ui-theme" href="https://arxiv.org/abs/2305.14652">View original<br/>on arXiv</a><a class="ar5iv-nav-button ar5iv-nav-button-next" href="/html/2305.14653">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>
<div class="ltx_page_logo">Generated  on Thu Feb 29 05:36:49 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/" target="_blank"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="NOT_FOUND"/></a>
</div></footer>
</div>
<script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
<script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
</body>
</html>
