@inproceedings{du-etal-2024-llms,
    title = "{LLM}s Assist {NLP} Researchers: Critique Paper (Meta-)Reviewing",
    author = "Du, Jiangshu  and
      Wang, Yibo  and
      Zhao, Wenting  and
      Deng, Zhongfen  and
      Liu, Shuaiqi  and
      Lou, Renze  and
      Zou, Henry Peng  and
      Narayanan Venkit, Pranav  and
      Zhang, Nan  and
      Srinath, Mukund  and
      Zhang, Haoran Ranran  and
      Gupta, Vipul  and
      Li, Yinghui  and
      Li, Tao  and
      Wang, Fei  and
      Liu, Qin  and
      Liu, Tianlin  and
      Gao, Pengzhi  and
      Xia, Congying  and
      Xing, Chen  and
      Jiayang, Cheng  and
      Wang, Zhaowei  and
      Su, Ying  and
      Shah, Raj Sanjay  and
      Guo, Ruohao  and
      Gu, Jing  and
      Li, Haoran  and
      Wei, Kangda  and
      Wang, Zihao  and
      Cheng, Lu  and
      Ranathunga, Surangika  and
      Fang, Meng  and
      Fu, Jie  and
      Liu, Fei  and
      Huang, Ruihong  and
      Blanco, Eduardo  and
      Cao, Yixin  and
      Zhang, Rui  and
      Yu, Philip S.  and
      Yin, Wenpeng",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.292/",
    doi = "10.18653/v1/2024.emnlp-main.292",
    pages = "5081--5099",
    abstract = "Claim: This work is not advocating the use of LLMs for paper (meta-)reviewing. Instead, wepresent a comparative analysis to identify and distinguish LLM activities from human activities. Two research goals: i) Enable better recognition of instances when someone implicitly uses LLMs for reviewing activities; ii) Increase community awareness that LLMs, and AI in general, are currently inadequate for performing tasks that require a high level of expertise and nuanced judgment.This work is motivated by two key trends. On one hand, large language models (LLMs) have shown remarkable versatility in various generative tasks such as writing, drawing, and question answering, significantly reducing the time required for many routine tasks. On the other hand, researchers, whose work is not only time-consuming but also highly expertise-demanding, face increasing challenges as they have to spend more time reading, writing, and reviewing papers. This raises the question: how can LLMs potentially assist researchers in alleviating their heavy workload?This study focuses on the topic of LLMs as NLP Researchers, particularly examining the effectiveness of LLMs in assisting paper (meta-)reviewing and its recognizability. To address this, we constructed the ReviewCritique dataset, which includes two types of information: (i) NLP papers (initial submissions rather than camera-ready) with both human-written and LLM-generated reviews, and (ii) each review comes with {\textquotedblleft}deficiency{\textquotedblright} labels and corresponding explanations for individual segments, annotated by experts. Using ReviewCritique, this study explores two threads of research questions: (i) {\textquotedblleft}LLMs as Reviewers{\textquotedblright}, how do reviews generated by LLMs compare with those written by humans in terms of quality and distinguishability? (ii) {\textquotedblleft}LLMs as Metareviewers{\textquotedblright}, how effectively can LLMs identify potential issues, such as Deficient or unprofessional review segments, within individual paper reviews? To our knowledge, this is the first work to provide such a comprehensive analysis."
}